{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-11T06:14:06.734107Z",
     "start_time": "2026-02-11T06:14:04.292631Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import sys\n",
    "import subprocess\n",
    "\n",
    "print(f\"Python: {sys.executable}\")\n",
    "\n",
    "# Uninstall NumPy 2.x\n",
    "print(\"Uninstalling NumPy 2.x...\")\n",
    "subprocess.run([sys.executable, \"-m\", \"pip\", \"uninstall\", \"-y\", \"numpy\"], check=True)\n",
    "\n",
    "# Install NumPy 1.26.4\n",
    "print(\"Installing NumPy 1.26.4...\")\n",
    "subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"numpy==1.26.4\"], check=True)\n",
    "\n",
    "print(\"\\n‚úÖ DONE! Now restart kernel: Kernel ‚Üí Restart Kernel\")"
   ],
   "id": "357da545f4ba0043",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: /Applications/Xcode.app/Contents/Developer/usr/bin/python3\n",
      "Uninstalling NumPy 2.x...\n",
      "Found existing installation: numpy 2.0.2\n",
      "Uninstalling numpy-2.0.2:\n",
      "  Successfully uninstalled numpy-2.0.2\n",
      "Installing NumPy 1.26.4...\n",
      "Defaulting to user installation because normal site-packages is not writeable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[33mWARNING: Ignoring invalid distribution -cipy (/Users/jiangshengbo/Library/Python/3.9/lib/python/site-packages)\u001B[0m\u001B[33m\n",
      "\u001B[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy==1.26.4\n",
      "  Using cached numpy-1.26.4-cp39-cp39-macosx_11_0_arm64.whl.metadata (61 kB)\n",
      "Using cached numpy-1.26.4-cp39-cp39-macosx_11_0_arm64.whl (14.0 MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[33mWARNING: Ignoring invalid distribution -cipy (/Users/jiangshengbo/Library/Python/3.9/lib/python/site-packages)\u001B[0m\u001B[33m\n",
      "\u001B[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing collected packages: numpy\n",
      "Successfully installed numpy-1.26.4\n",
      "\n",
      "‚úÖ DONE! Now restart kernel: Kernel ‚Üí Restart Kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[33m  WARNING: The script f2py is installed in '/Users/jiangshengbo/Library/Python/3.9/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001B[0m\u001B[33m\n",
      "\u001B[0m\u001B[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "chromadb 1.1.0 requires tenacity>=8.2.3, but you have tenacity 8.2.0 which is incompatible.\n",
      "great-expectations 0.17.0 requires pydantic<2.0,>=1.9.2, but you have pydantic 2.12.3 which is incompatible.\n",
      "opencv-python-headless 4.13.0.92 requires numpy>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\u001B[0m\u001B[31m\n",
      "\u001B[0m\u001B[33mWARNING: Ignoring invalid distribution -cipy (/Users/jiangshengbo/Library/Python/3.9/lib/python/site-packages)\u001B[0m\u001B[33m\n",
      "\u001B[0m"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-11T06:14:15.370624Z",
     "start_time": "2026-02-11T06:14:07.305627Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import sys\n",
    "import subprocess\n",
    "\n",
    "# Uninstall broken packages\n",
    "subprocess.run([sys.executable, \"-m\", \"pip\", \"uninstall\", \"-y\", \"scipy\", \"albumentations\", \"opencv-python\", \"opencv-python-headless\"])\n",
    "\n",
    "# Install in correct order\n",
    "subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"--no-cache-dir\", \"scipy>=1.7.0,<1.15.0\"])\n",
    "subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"--no-cache-dir\", \"opencv-python-headless>=4.5.0\"])\n",
    "subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"--no-cache-dir\", \"albumentations>=1.3.0\"])\n",
    "\n",
    "print(\"‚úÖ Done! Now restart the kernel: Kernel ‚Üí Restart Kernel\")"
   ],
   "id": "f314169c67b2a3a1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: scipy 1.13.1\n",
      "Uninstalling scipy-1.13.1:\n",
      "  Successfully uninstalled scipy-1.13.1\n",
      "Found existing installation: albumentations 2.0.8\n",
      "Uninstalling albumentations-2.0.8:\n",
      "  Successfully uninstalled albumentations-2.0.8\n",
      "Found existing installation: opencv-python-headless 4.13.0.92\n",
      "Uninstalling opencv-python-headless-4.13.0.92:\n",
      "  Successfully uninstalled opencv-python-headless-4.13.0.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[33mWARNING: Ignoring invalid distribution -cipy (/Users/jiangshengbo/Library/Python/3.9/lib/python/site-packages)\u001B[0m\u001B[33m\n",
      "\u001B[0m\u001B[33mWARNING: Skipping opencv-python as it is not installed.\u001B[0m\u001B[33m\n",
      "\u001B[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[33mWARNING: Ignoring invalid distribution -cipy (/Users/jiangshengbo/Library/Python/3.9/lib/python/site-packages)\u001B[0m\u001B[33m\n",
      "\u001B[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scipy<1.15.0,>=1.7.0\n",
      "  Downloading scipy-1.13.1-cp39-cp39-macosx_12_0_arm64.whl.metadata (60 kB)\n",
      "Requirement already satisfied: numpy<2.3,>=1.22.4 in /Users/jiangshengbo/Library/Python/3.9/lib/python/site-packages (from scipy<1.15.0,>=1.7.0) (1.26.4)\n",
      "Downloading scipy-1.13.1-cp39-cp39-macosx_12_0_arm64.whl (30.3 MB)\n",
      "\u001B[2K   \u001B[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m \u001B[32m30.3/30.3 MB\u001B[0m \u001B[31m60.9 MB/s\u001B[0m  \u001B[33m0:00:00\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n",
      "\u001B[?25h"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[33mWARNING: Ignoring invalid distribution -cipy (/Users/jiangshengbo/Library/Python/3.9/lib/python/site-packages)\u001B[0m\u001B[33m\n",
      "\u001B[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing collected packages: scipy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "great-expectations 0.17.0 requires pydantic<2.0,>=1.9.2, but you have pydantic 2.12.3 which is incompatible.\u001B[0m\u001B[31m\n",
      "\u001B[0m\u001B[33mWARNING: Ignoring invalid distribution -cipy (/Users/jiangshengbo/Library/Python/3.9/lib/python/site-packages)\u001B[0m\u001B[33m\n",
      "\u001B[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully installed scipy-1.13.1\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting opencv-python-headless>=4.5.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[33mWARNING: Ignoring invalid distribution -cipy (/Users/jiangshengbo/Library/Python/3.9/lib/python/site-packages)\u001B[0m\u001B[33m\n",
      "\u001B[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading opencv_python_headless-4.13.0.92-cp37-abi3-macosx_13_0_arm64.whl.metadata (19 kB)\n",
      "Collecting numpy>=2 (from opencv-python-headless>=4.5.0)\n",
      "  Downloading numpy-2.0.2-cp39-cp39-macosx_14_0_arm64.whl.metadata (60 kB)\n",
      "Downloading opencv_python_headless-4.13.0.92-cp37-abi3-macosx_13_0_arm64.whl (46.2 MB)\n",
      "\u001B[2K   \u001B[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m \u001B[32m46.2/46.2 MB\u001B[0m \u001B[31m39.3 MB/s\u001B[0m  \u001B[33m0:00:01\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n",
      "\u001B[?25hDownloading numpy-2.0.2-cp39-cp39-macosx_14_0_arm64.whl (5.3 MB)\n",
      "\u001B[2K   \u001B[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m \u001B[32m5.3/5.3 MB\u001B[0m \u001B[31m74.8 MB/s\u001B[0m  \u001B[33m0:00:00\u001B[0m\n",
      "\u001B[?25h"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[33mWARNING: Ignoring invalid distribution -cipy (/Users/jiangshengbo/Library/Python/3.9/lib/python/site-packages)\u001B[0m\u001B[33m\n",
      "\u001B[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing collected packages: numpy, opencv-python-headless\n",
      "\u001B[2K  Attempting uninstall: numpy\n",
      "\u001B[2K    Found existing installation: numpy 1.26.4\n",
      "\u001B[2K    Uninstalling numpy-1.26.4:\n",
      "\u001B[2K      Successfully uninstalled numpy-1.26.4\n",
      "\u001B[2K   \u001B[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m \u001B[32m0/2\u001B[0m [numpy]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[33m  WARNING: The scripts f2py and numpy-config are installed in '/Users/jiangshengbo/Library/Python/3.9/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001B[0m\u001B[33m\n",
      "\u001B[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[2K   \u001B[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m \u001B[32m2/2\u001B[0m [opencv-python-headless]v-python-headless]\n",
      "\u001B[1A\u001B[2KSuccessfully installed numpy-2.0.2 opencv-python-headless-4.13.0.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "chromadb 1.1.0 requires tenacity>=8.2.3, but you have tenacity 8.2.0 which is incompatible.\n",
      "great-expectations 0.17.0 requires pydantic<2.0,>=1.9.2, but you have pydantic 2.12.3 which is incompatible.\u001B[0m\u001B[31m\n",
      "\u001B[0m\u001B[33mWARNING: Ignoring invalid distribution -cipy (/Users/jiangshengbo/Library/Python/3.9/lib/python/site-packages)\u001B[0m\u001B[33m\n",
      "\u001B[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting albumentations>=1.3.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[33mWARNING: Ignoring invalid distribution -cipy (/Users/jiangshengbo/Library/Python/3.9/lib/python/site-packages)\u001B[0m\u001B[33m\n",
      "\u001B[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading albumentations-2.0.8-py3-none-any.whl.metadata (43 kB)\n",
      "Requirement already satisfied: numpy>=1.24.4 in /Users/jiangshengbo/Library/Python/3.9/lib/python/site-packages (from albumentations>=1.3.0) (2.0.2)\n",
      "Requirement already satisfied: scipy>=1.10.0 in /Users/jiangshengbo/Library/Python/3.9/lib/python/site-packages (from albumentations>=1.3.0) (1.13.1)\n",
      "Requirement already satisfied: PyYAML in /Users/jiangshengbo/Library/Python/3.9/lib/python/site-packages (from albumentations>=1.3.0) (6.0.2)\n",
      "Requirement already satisfied: typing-extensions>=4.9.0 in /Users/jiangshengbo/Library/Python/3.9/lib/python/site-packages (from albumentations>=1.3.0) (4.15.0)\n",
      "Requirement already satisfied: pydantic>=2.9.2 in /Users/jiangshengbo/Library/Python/3.9/lib/python/site-packages (from albumentations>=1.3.0) (2.12.3)\n",
      "Requirement already satisfied: albucore==0.0.24 in /Users/jiangshengbo/Library/Python/3.9/lib/python/site-packages (from albumentations>=1.3.0) (0.0.24)\n",
      "Requirement already satisfied: eval-type-backport in /Users/jiangshengbo/Library/Python/3.9/lib/python/site-packages (from albumentations>=1.3.0) (0.3.1)\n",
      "Requirement already satisfied: opencv-python-headless>=4.9.0.80 in /Users/jiangshengbo/Library/Python/3.9/lib/python/site-packages (from albumentations>=1.3.0) (4.13.0.92)\n",
      "Requirement already satisfied: stringzilla>=3.10.4 in /Users/jiangshengbo/Library/Python/3.9/lib/python/site-packages (from albucore==0.0.24->albumentations>=1.3.0) (4.6.0)\n",
      "Requirement already satisfied: simsimd>=5.9.2 in /Users/jiangshengbo/Library/Python/3.9/lib/python/site-packages (from albucore==0.0.24->albumentations>=1.3.0) (6.5.12)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/jiangshengbo/Library/Python/3.9/lib/python/site-packages (from pydantic>=2.9.2->albumentations>=1.3.0) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.4 in /Users/jiangshengbo/Library/Python/3.9/lib/python/site-packages (from pydantic>=2.9.2->albumentations>=1.3.0) (2.41.4)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /Users/jiangshengbo/Library/Python/3.9/lib/python/site-packages (from pydantic>=2.9.2->albumentations>=1.3.0) (0.4.2)\n",
      "Downloading albumentations-2.0.8-py3-none-any.whl (369 kB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[33mWARNING: Ignoring invalid distribution -cipy (/Users/jiangshengbo/Library/Python/3.9/lib/python/site-packages)\u001B[0m\u001B[33m\n",
      "\u001B[0m\u001B[33mWARNING: Ignoring invalid distribution -cipy (/Users/jiangshengbo/Library/Python/3.9/lib/python/site-packages)\u001B[0m\u001B[33m\n",
      "\u001B[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing collected packages: albumentations\n",
      "Successfully installed albumentations-2.0.8\n",
      "‚úÖ Done! Now restart the kernel: Kernel ‚Üí Restart Kernel\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-11T06:14:43.745320Z",
     "start_time": "2026-02-11T06:14:19.226770Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import subprocess\n",
    "import sys\n",
    "import os\n",
    "\n",
    "print(\"Installing dependencies for Sustainability AI Model (MacBook Local Training)...\")\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Install packages one by one with error handling\n",
    "def install_package(package_spec, description=\"\"):\n",
    "    \"\"\"Install a package with error handling.\"\"\"\n",
    "    try:\n",
    "        print(f\"Installing {description or package_spec}...\")\n",
    "        subprocess.check_call(\n",
    "            [sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"--upgrade\"] + package_spec.split(),\n",
    "            timeout=300  # 5 minute timeout per package\n",
    "        )\n",
    "        print(f\"  ‚úÖ {description or package_spec}\")\n",
    "        return True\n",
    "    except subprocess.TimeoutExpired:\n",
    "        print(f\"  ‚ö†Ô∏è  Timeout installing {description or package_spec}, skipping...\")\n",
    "        return False\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"  ‚ö†Ô∏è  Failed to install {description or package_spec}: {e}\")\n",
    "        return False\n",
    "\n",
    "# Upgrade pip first\n",
    "print(\"Upgrading pip...\")\n",
    "subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"--upgrade\", \"pip\"], timeout=60)\n",
    "\n",
    "# Install Kaggle API\n",
    "install_package(\"kaggle\", \"Kaggle API\")\n",
    "\n",
    "# Install core dependencies (Python 3.9 compatible versions)\n",
    "install_package(\"numpy>=1.19.0,<2.0\", \"NumPy\")\n",
    "install_package(\"scipy>=1.7.0,<1.15.0\", \"SciPy\")\n",
    "install_package(\"Pillow>=8.0.0\", \"Pillow\")\n",
    "install_package(\"pandas>=1.3.0\", \"Pandas\")\n",
    "install_package(\"scikit-learn>=1.0.0\", \"scikit-learn\")\n",
    "install_package(\"matplotlib>=3.4.0\", \"Matplotlib\")\n",
    "install_package(\"seaborn>=0.11.0\", \"Seaborn\")\n",
    "install_package(\"tqdm>=4.62.0\", \"tqdm\")\n",
    "\n",
    "# Install PyTorch with compatible torchvision version\n",
    "print(\"Checking PyTorch installation...\")\n",
    "try:\n",
    "    import torch\n",
    "    import torchvision\n",
    "    torch_version = torch.__version__\n",
    "    torchvision_version = torchvision.__version__\n",
    "    print(f\"  Current PyTorch: {torch_version}\")\n",
    "    print(f\"  Current torchvision: {torchvision_version}\")\n",
    "\n",
    "    # Check if versions are compatible\n",
    "    # PyTorch 2.x needs torchvision 0.15+\n",
    "    # PyTorch 1.x needs torchvision 0.x\n",
    "    torch_major = int(torch_version.split('.')[0])\n",
    "    tv_major = int(torchvision_version.split('.')[0])\n",
    "\n",
    "    if torch_major == 2 and tv_major == 0 and int(torchvision_version.split('.')[1]) < 15:\n",
    "        print(\"  ‚ö†Ô∏è  Version mismatch detected! Reinstalling compatible versions...\")\n",
    "        subprocess.run([sys.executable, \"-m\", \"pip\", \"uninstall\", \"-y\", \"torch\", \"torchvision\"], check=False)\n",
    "        install_package(\"torch==2.0.1 torchvision==0.15.2\", \"PyTorch 2.0.1 + torchvision 0.15.2\")\n",
    "    elif torch_major != tv_major:\n",
    "        print(\"  ‚ö†Ô∏è  Major version mismatch! Reinstalling compatible versions...\")\n",
    "        subprocess.run([sys.executable, \"-m\", \"pip\", \"uninstall\", \"-y\", \"torch\", \"torchvision\"], check=False)\n",
    "        install_package(\"torch==2.0.1 torchvision==0.15.2\", \"PyTorch 2.0.1 + torchvision 0.15.2\")\n",
    "    else:\n",
    "        print(\"  ‚úÖ PyTorch and torchvision versions are compatible\")\n",
    "\n",
    "except ImportError:\n",
    "    print(\"  Installing PyTorch and torchvision...\")\n",
    "    install_package(\"torch==2.0.1 torchvision==0.15.2\", \"PyTorch 2.0.1 + torchvision 0.15.2\")\n",
    "except AttributeError as e:\n",
    "    print(f\"  ‚ö†Ô∏è  Version compatibility issue detected: {e}\")\n",
    "    print(\"  Reinstalling compatible PyTorch and torchvision versions...\")\n",
    "    subprocess.run([sys.executable, \"-m\", \"pip\", \"uninstall\", \"-y\", \"torch\", \"torchvision\"], check=False)\n",
    "    install_package(\"torch==2.0.1 torchvision==0.15.2\", \"PyTorch 2.0.1 + torchvision 0.15.2\")\n",
    "\n",
    "# Install timm (Python 3.9 compatible)\n",
    "install_package(\"timm>=0.9.0\", \"timm\")\n",
    "\n",
    "# Install albumentations\n",
    "install_package(\"albumentations>=1.3.0\", \"Albumentations\")\n",
    "\n",
    "# Install other dependencies\n",
    "install_package(\"einops>=0.6.0\", \"einops\")\n",
    "install_package(\"wandb>=0.15.0\", \"Weights & Biases\")\n",
    "\n",
    "# Install PyTorch Geometric (simplified for Python 3.9)\n",
    "print(\"Installing PyTorch Geometric...\")\n",
    "install_package(\"torch-geometric\", \"PyTorch Geometric\")\n",
    "\n",
    "# Try to install torch-scatter and torch-sparse (optional, may fail on some systems)\n",
    "print(\"Installing optional PyG dependencies (may fail, that's OK)...\")\n",
    "try:\n",
    "    subprocess.run(\n",
    "        [sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"torch-scatter\", \"torch-sparse\"],\n",
    "        timeout=300,\n",
    "        check=False  # Don't fail if this doesn't work\n",
    "    )\n",
    "    print(\"  ‚úÖ torch-scatter and torch-sparse installed\")\n",
    "except:\n",
    "    print(\"  ‚ö†Ô∏è  torch-scatter/torch-sparse installation skipped (optional)\")\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"‚úÖ Core dependencies installed successfully!\")\n",
    "print(\"=\"*60)\n"
   ],
   "id": "f90b43bdd0cb863b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing dependencies for Sustainability AI Model (MacBook Local Training)...\n",
      "Python version: 3.9.6 (default, Dec  2 2025, 07:27:58) \n",
      "[Clang 17.0.0 (clang-1700.6.3.2)]\n",
      "============================================================\n",
      "Upgrading pip...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[33mWARNING: Ignoring invalid distribution -cipy (/Users/jiangshengbo/Library/Python/3.9/lib/python/site-packages)\u001B[0m\u001B[33m\n",
      "\u001B[0m\u001B[33mWARNING: Ignoring invalid distribution -cipy (/Users/jiangshengbo/Library/Python/3.9/lib/python/site-packages)\u001B[0m\u001B[33m\n",
      "\u001B[0m\u001B[33mWARNING: Ignoring invalid distribution -cipy (/Users/jiangshengbo/Library/Python/3.9/lib/python/site-packages)\u001B[0m\u001B[33m\n",
      "\u001B[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing Kaggle API...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[33mWARNING: Ignoring invalid distribution -cipy (/Users/jiangshengbo/Library/Python/3.9/lib/python/site-packages)\u001B[0m\u001B[33m\n",
      "\u001B[0m\u001B[33mWARNING: Ignoring invalid distribution -cipy (/Users/jiangshengbo/Library/Python/3.9/lib/python/site-packages)\u001B[0m\u001B[33m\n",
      "\u001B[0m\u001B[33mWARNING: Ignoring invalid distribution -cipy (/Users/jiangshengbo/Library/Python/3.9/lib/python/site-packages)\u001B[0m\u001B[33m\n",
      "\u001B[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úÖ Kaggle API\n",
      "Installing NumPy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[33mWARNING: Ignoring invalid distribution -cipy (/Users/jiangshengbo/Library/Python/3.9/lib/python/site-packages)\u001B[0m\u001B[33m\n",
      "\u001B[0m\u001B[33mWARNING: Ignoring invalid distribution -cipy (/Users/jiangshengbo/Library/Python/3.9/lib/python/site-packages)\u001B[0m\u001B[33m\n",
      "\u001B[0m\u001B[33m  WARNING: The script f2py is installed in '/Users/jiangshengbo/Library/Python/3.9/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001B[0m\u001B[33m\n",
      "\u001B[0m\u001B[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "chromadb 1.1.0 requires tenacity>=8.2.3, but you have tenacity 8.2.0 which is incompatible.\n",
      "great-expectations 0.17.0 requires pydantic<2.0,>=1.9.2, but you have pydantic 2.12.3 which is incompatible.\n",
      "opencv-python-headless 4.13.0.92 requires numpy>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\u001B[0m\u001B[31m\n",
      "\u001B[0m\u001B[33mWARNING: Ignoring invalid distribution -cipy (/Users/jiangshengbo/Library/Python/3.9/lib/python/site-packages)\u001B[0m\u001B[33m\n",
      "\u001B[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úÖ NumPy\n",
      "Installing SciPy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[33mWARNING: Ignoring invalid distribution -cipy (/Users/jiangshengbo/Library/Python/3.9/lib/python/site-packages)\u001B[0m\u001B[33m\n",
      "\u001B[0m\u001B[33mWARNING: Ignoring invalid distribution -cipy (/Users/jiangshengbo/Library/Python/3.9/lib/python/site-packages)\u001B[0m\u001B[33m\n",
      "\u001B[0m\u001B[33mWARNING: Ignoring invalid distribution -cipy (/Users/jiangshengbo/Library/Python/3.9/lib/python/site-packages)\u001B[0m\u001B[33m\n",
      "\u001B[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úÖ SciPy\n",
      "Installing Pillow...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[33mWARNING: Ignoring invalid distribution -cipy (/Users/jiangshengbo/Library/Python/3.9/lib/python/site-packages)\u001B[0m\u001B[33m\n",
      "\u001B[0m\u001B[33mWARNING: Ignoring invalid distribution -cipy (/Users/jiangshengbo/Library/Python/3.9/lib/python/site-packages)\u001B[0m\u001B[33m\n",
      "\u001B[0m\u001B[33mWARNING: Ignoring invalid distribution -cipy (/Users/jiangshengbo/Library/Python/3.9/lib/python/site-packages)\u001B[0m\u001B[33m\n",
      "\u001B[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úÖ Pillow\n",
      "Installing Pandas...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[33mWARNING: Ignoring invalid distribution -cipy (/Users/jiangshengbo/Library/Python/3.9/lib/python/site-packages)\u001B[0m\u001B[33m\n",
      "\u001B[0m\u001B[33mWARNING: Ignoring invalid distribution -cipy (/Users/jiangshengbo/Library/Python/3.9/lib/python/site-packages)\u001B[0m\u001B[33m\n",
      "\u001B[0m\u001B[33mWARNING: Ignoring invalid distribution -cipy (/Users/jiangshengbo/Library/Python/3.9/lib/python/site-packages)\u001B[0m\u001B[33m\n",
      "\u001B[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úÖ Pandas\n",
      "Installing scikit-learn...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[33mWARNING: Ignoring invalid distribution -cipy (/Users/jiangshengbo/Library/Python/3.9/lib/python/site-packages)\u001B[0m\u001B[33m\n",
      "\u001B[0m\u001B[33mWARNING: Ignoring invalid distribution -cipy (/Users/jiangshengbo/Library/Python/3.9/lib/python/site-packages)\u001B[0m\u001B[33m\n",
      "\u001B[0m\u001B[33mWARNING: Ignoring invalid distribution -cipy (/Users/jiangshengbo/Library/Python/3.9/lib/python/site-packages)\u001B[0m\u001B[33m\n",
      "\u001B[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úÖ scikit-learn\n",
      "Installing Matplotlib...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[33mWARNING: Ignoring invalid distribution -cipy (/Users/jiangshengbo/Library/Python/3.9/lib/python/site-packages)\u001B[0m\u001B[33m\n",
      "\u001B[0m\u001B[33mWARNING: Ignoring invalid distribution -cipy (/Users/jiangshengbo/Library/Python/3.9/lib/python/site-packages)\u001B[0m\u001B[33m\n",
      "\u001B[0m\u001B[33mWARNING: Ignoring invalid distribution -cipy (/Users/jiangshengbo/Library/Python/3.9/lib/python/site-packages)\u001B[0m\u001B[33m\n",
      "\u001B[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úÖ Matplotlib\n",
      "Installing Seaborn...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[33mWARNING: Ignoring invalid distribution -cipy (/Users/jiangshengbo/Library/Python/3.9/lib/python/site-packages)\u001B[0m\u001B[33m\n",
      "\u001B[0m\u001B[33mWARNING: Ignoring invalid distribution -cipy (/Users/jiangshengbo/Library/Python/3.9/lib/python/site-packages)\u001B[0m\u001B[33m\n",
      "\u001B[0m\u001B[33mWARNING: Ignoring invalid distribution -cipy (/Users/jiangshengbo/Library/Python/3.9/lib/python/site-packages)\u001B[0m\u001B[33m\n",
      "\u001B[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úÖ Seaborn\n",
      "Installing tqdm...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[33mWARNING: Ignoring invalid distribution -cipy (/Users/jiangshengbo/Library/Python/3.9/lib/python/site-packages)\u001B[0m\u001B[33m\n",
      "\u001B[0m\u001B[33mWARNING: Ignoring invalid distribution -cipy (/Users/jiangshengbo/Library/Python/3.9/lib/python/site-packages)\u001B[0m\u001B[33m\n",
      "\u001B[0m\u001B[33mWARNING: Ignoring invalid distribution -cipy (/Users/jiangshengbo/Library/Python/3.9/lib/python/site-packages)\u001B[0m\u001B[33m\n",
      "\u001B[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úÖ tqdm\n",
      "Checking PyTorch installation...\n",
      "  Current PyTorch: 2.0.1\n",
      "  Current torchvision: 0.15.2\n",
      "  ‚ö†Ô∏è  Major version mismatch! Reinstalling compatible versions...\n",
      "Found existing installation: torch 2.0.1\n",
      "Uninstalling torch-2.0.1:\n",
      "  Successfully uninstalled torch-2.0.1\n",
      "Found existing installation: torchvision 0.15.2\n",
      "Uninstalling torchvision-0.15.2:\n",
      "  Successfully uninstalled torchvision-0.15.2\n",
      "Installing PyTorch 2.0.1 + torchvision 0.15.2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[33mWARNING: Ignoring invalid distribution -cipy (/Users/jiangshengbo/Library/Python/3.9/lib/python/site-packages)\u001B[0m\u001B[33m\n",
      "\u001B[0m\u001B[33mWARNING: Ignoring invalid distribution -cipy (/Users/jiangshengbo/Library/Python/3.9/lib/python/site-packages)\u001B[0m\u001B[33m\n",
      "\u001B[0m\u001B[33m  WARNING: The scripts convert-caffe2-to-onnx, convert-onnx-to-caffe2 and torchrun are installed in '/Users/jiangshengbo/Library/Python/3.9/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001B[0m\u001B[33m\n",
      "\u001B[0m\u001B[33mWARNING: Ignoring invalid distribution -cipy (/Users/jiangshengbo/Library/Python/3.9/lib/python/site-packages)\u001B[0m\u001B[33m\n",
      "\u001B[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úÖ PyTorch 2.0.1 + torchvision 0.15.2\n",
      "Installing timm...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[33mWARNING: Ignoring invalid distribution -cipy (/Users/jiangshengbo/Library/Python/3.9/lib/python/site-packages)\u001B[0m\u001B[33m\n",
      "\u001B[0m\u001B[33mWARNING: Ignoring invalid distribution -cipy (/Users/jiangshengbo/Library/Python/3.9/lib/python/site-packages)\u001B[0m\u001B[33m\n",
      "\u001B[0m\u001B[33mWARNING: Ignoring invalid distribution -cipy (/Users/jiangshengbo/Library/Python/3.9/lib/python/site-packages)\u001B[0m\u001B[33m\n",
      "\u001B[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úÖ timm\n",
      "Installing Albumentations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[33mWARNING: Ignoring invalid distribution -cipy (/Users/jiangshengbo/Library/Python/3.9/lib/python/site-packages)\u001B[0m\u001B[33m\n",
      "\u001B[0m\u001B[33mWARNING: Ignoring invalid distribution -cipy (/Users/jiangshengbo/Library/Python/3.9/lib/python/site-packages)\u001B[0m\u001B[33m\n",
      "\u001B[0m\u001B[33m  WARNING: The scripts f2py and numpy-config are installed in '/Users/jiangshengbo/Library/Python/3.9/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001B[0m\u001B[33m\n",
      "\u001B[0m\u001B[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "chromadb 1.1.0 requires tenacity>=8.2.3, but you have tenacity 8.2.0 which is incompatible.\n",
      "great-expectations 0.17.0 requires pydantic<2.0,>=1.9.2, but you have pydantic 2.12.3 which is incompatible.\u001B[0m\u001B[31m\n",
      "\u001B[0m\u001B[33mWARNING: Ignoring invalid distribution -cipy (/Users/jiangshengbo/Library/Python/3.9/lib/python/site-packages)\u001B[0m\u001B[33m\n",
      "\u001B[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úÖ Albumentations\n",
      "Installing einops...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[33mWARNING: Ignoring invalid distribution -cipy (/Users/jiangshengbo/Library/Python/3.9/lib/python/site-packages)\u001B[0m\u001B[33m\n",
      "\u001B[0m\u001B[33mWARNING: Ignoring invalid distribution -cipy (/Users/jiangshengbo/Library/Python/3.9/lib/python/site-packages)\u001B[0m\u001B[33m\n",
      "\u001B[0m\u001B[33mWARNING: Ignoring invalid distribution -cipy (/Users/jiangshengbo/Library/Python/3.9/lib/python/site-packages)\u001B[0m\u001B[33m\n",
      "\u001B[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úÖ einops\n",
      "Installing Weights & Biases...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[33mWARNING: Ignoring invalid distribution -cipy (/Users/jiangshengbo/Library/Python/3.9/lib/python/site-packages)\u001B[0m\u001B[33m\n",
      "\u001B[0m\u001B[33mWARNING: Ignoring invalid distribution -cipy (/Users/jiangshengbo/Library/Python/3.9/lib/python/site-packages)\u001B[0m\u001B[33m\n",
      "\u001B[0m\u001B[33mWARNING: Ignoring invalid distribution -cipy (/Users/jiangshengbo/Library/Python/3.9/lib/python/site-packages)\u001B[0m\u001B[33m\n",
      "\u001B[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úÖ Weights & Biases\n",
      "Installing PyTorch Geometric...\n",
      "Installing PyTorch Geometric...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[33mWARNING: Ignoring invalid distribution -cipy (/Users/jiangshengbo/Library/Python/3.9/lib/python/site-packages)\u001B[0m\u001B[33m\n",
      "\u001B[0m\u001B[33mWARNING: Ignoring invalid distribution -cipy (/Users/jiangshengbo/Library/Python/3.9/lib/python/site-packages)\u001B[0m\u001B[33m\n",
      "\u001B[0m\u001B[33mWARNING: Ignoring invalid distribution -cipy (/Users/jiangshengbo/Library/Python/3.9/lib/python/site-packages)\u001B[0m\u001B[33m\n",
      "\u001B[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úÖ PyTorch Geometric\n",
      "Installing optional PyG dependencies (may fail, that's OK)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[33mWARNING: Ignoring invalid distribution -cipy (/Users/jiangshengbo/Library/Python/3.9/lib/python/site-packages)\u001B[0m\u001B[33m\n",
      "\u001B[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úÖ torch-scatter and torch-sparse installed\n",
      "============================================================\n",
      "‚úÖ Core dependencies installed successfully!\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  \u001B[1;31merror\u001B[0m: \u001B[1msubprocess-exited-with-error\u001B[0m\n",
      "  \n",
      "  \u001B[31m√ó\u001B[0m \u001B[32mGetting requirements to build wheel\u001B[0m did not run successfully.\n",
      "  \u001B[31m‚îÇ\u001B[0m exit code: \u001B[1;36m1\u001B[0m\n",
      "  \u001B[31m‚ï∞‚îÄ>\u001B[0m \u001B[31m[17 lines of output]\u001B[0m\n",
      "  \u001B[31m   \u001B[0m Traceback (most recent call last):\n",
      "  \u001B[31m   \u001B[0m   File \"/Users/jiangshengbo/Library/Python/3.9/lib/python/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\", line 389, in <module>\n",
      "  \u001B[31m   \u001B[0m     main()\n",
      "  \u001B[31m   \u001B[0m   File \"/Users/jiangshengbo/Library/Python/3.9/lib/python/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\", line 373, in main\n",
      "  \u001B[31m   \u001B[0m     json_out[\"return_val\"] = hook(**hook_input[\"kwargs\"])\n",
      "  \u001B[31m   \u001B[0m   File \"/Users/jiangshengbo/Library/Python/3.9/lib/python/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\", line 143, in get_requires_for_build_wheel\n",
      "  \u001B[31m   \u001B[0m     return hook(config_settings)\n",
      "  \u001B[31m   \u001B[0m   File \"/private/var/folders/y0/l9ns18ns5472mqrprmhhmsw00000gn/T/pip-build-env-817_0386/overlay/lib/python3.9/site-packages/setuptools/build_meta.py\", line 333, in get_requires_for_build_wheel\n",
      "  \u001B[31m   \u001B[0m     return self._get_build_requires(config_settings, requirements=[])\n",
      "  \u001B[31m   \u001B[0m   File \"/private/var/folders/y0/l9ns18ns5472mqrprmhhmsw00000gn/T/pip-build-env-817_0386/overlay/lib/python3.9/site-packages/setuptools/build_meta.py\", line 301, in _get_build_requires\n",
      "  \u001B[31m   \u001B[0m     self.run_setup()\n",
      "  \u001B[31m   \u001B[0m   File \"/private/var/folders/y0/l9ns18ns5472mqrprmhhmsw00000gn/T/pip-build-env-817_0386/overlay/lib/python3.9/site-packages/setuptools/build_meta.py\", line 520, in run_setup\n",
      "  \u001B[31m   \u001B[0m     super().run_setup(setup_script=setup_script)\n",
      "  \u001B[31m   \u001B[0m   File \"/private/var/folders/y0/l9ns18ns5472mqrprmhhmsw00000gn/T/pip-build-env-817_0386/overlay/lib/python3.9/site-packages/setuptools/build_meta.py\", line 317, in run_setup\n",
      "  \u001B[31m   \u001B[0m     exec(code, locals())\n",
      "  \u001B[31m   \u001B[0m   File \"<string>\", line 8, in <module>\n",
      "  \u001B[31m   \u001B[0m ModuleNotFoundError: No module named 'torch'\n",
      "  \u001B[31m   \u001B[0m \u001B[31m[end of output]\u001B[0m\n",
      "  \n",
      "  \u001B[1;35mnote\u001B[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001B[31mERROR: Failed to build 'torch-scatter' when getting requirements to build wheel\u001B[0m\u001B[31m\n",
      "\u001B[0m"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-11T06:14:43.826534Z",
     "start_time": "2026-02-11T06:14:43.749438Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# KAGGLE API SETUP AND DATASET DOWNLOAD\n",
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "import zipfile\n",
    "import shutil\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"üîë CONFIGURING KAGGLE API\")\n",
    "print(\"=\"*80)\n",
    "print()\n",
    "\n",
    "\n",
    "KAGGLE_USERNAME = \"michealjiang\"  # Your Kaggle username\n",
    "KAGGLE_KEY = \"92ce58a4cc3d98ed20dca81b8598123f\"  # Your Kaggle API key\n",
    "\n",
    "# Alternative: If you already have kaggle.json, we can read it\n",
    "kaggle_json_path = Path.home() / \".kaggle\" / \"kaggle.json\"\n",
    "if kaggle_json_path.exists():\n",
    "    print(\"üìÑ Found existing kaggle.json, loading credentials...\")\n",
    "    with open(kaggle_json_path, 'r') as f:\n",
    "        existing_creds = json.load(f)\n",
    "        KAGGLE_USERNAME = existing_creds.get(\"username\", KAGGLE_USERNAME)\n",
    "        KAGGLE_KEY = existing_creds.get(\"key\", KAGGLE_KEY)\n",
    "    print(f\"   ‚úÖ Loaded username: {KAGGLE_USERNAME}\")\n",
    "else:\n",
    "    print(\"üìù No existing kaggle.json found, using credentials from above...\")\n",
    "\n",
    "# Validate credentials\n",
    "if KAGGLE_USERNAME == \"YOUR_KAGGLE_USERNAME\" or KAGGLE_KEY == \"YOUR_KAGGLE_API_KEY\":\n",
    "    print()\n",
    "    print(\"=\"*80)\n",
    "    print(\"‚ö†Ô∏è  ERROR: KAGGLE CREDENTIALS NOT SET!\")\n",
    "    print(\"=\"*80)\n",
    "    print()\n",
    "    print(\"Please follow these steps:\")\n",
    "    print()\n",
    "    print(\"1. Go to: https://www.kaggle.com/settings\")\n",
    "    print(\"2. Scroll to 'API' section\")\n",
    "    print(\"3. Click 'Create New Token'\")\n",
    "    print(\"4. This downloads 'kaggle.json' to your Downloads folder\")\n",
    "    print(\"5. Open kaggle.json and you'll see:\")\n",
    "    print('   {\"username\":\"your_username\",\"key\":\"your_api_key\"}')\n",
    "    print()\n",
    "    print(\"6. Copy those values and paste them in the cell above:\")\n",
    "    print('   KAGGLE_USERNAME = \"your_username\"')\n",
    "    print('   KAGGLE_KEY = \"your_api_key\"')\n",
    "    print()\n",
    "    print(\"7. Re-run this cell\")\n",
    "    print()\n",
    "    print(\"=\"*80)\n",
    "    raise ValueError(\"Kaggle credentials not configured. Please set KAGGLE_USERNAME and KAGGLE_KEY above.\")\n",
    "\n",
    "print()\n",
    "\n",
    "# Create ~/.kaggle directory if it doesn't exist\n",
    "kaggle_dir = Path.home() / \".kaggle\"\n",
    "kaggle_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Create kaggle.json with credentials\n",
    "kaggle_json_path = kaggle_dir / \"kaggle.json\"\n",
    "kaggle_credentials = {\n",
    "    \"username\": KAGGLE_USERNAME,\n",
    "    \"key\": KAGGLE_KEY\n",
    "}\n",
    "\n",
    "# Write credentials to file\n",
    "with open(kaggle_json_path, 'w') as f:\n",
    "    json.dump(kaggle_credentials, f, indent=2)\n",
    "\n",
    "# Set proper permissions (required by Kaggle API on Unix systems)\n",
    "try:\n",
    "    os.chmod(kaggle_json_path, 0o600)\n",
    "except:\n",
    "    pass  # Windows doesn't support chmod\n",
    "\n",
    "print(f\"‚úÖ Kaggle credentials saved to: {kaggle_json_path}\")\n",
    "print(f\"   Username: {KAGGLE_USERNAME}\")\n",
    "print(f\"   Key: {KAGGLE_KEY[:10]}...{KAGGLE_KEY[-4:]}\")\n",
    "print()\n",
    "print(\"=\"*80)\n",
    "print()\n",
    "\n",
    "# Kaggle datasets to download\n",
    "KAGGLE_DATASETS = [\n",
    "    {\"slug\": \"sumn2u/garbage-classification-v2\", \"name\": \"garbage-classification-v2\"},\n",
    "    {\"slug\": \"zlatan599/garbage-dataset-classification\", \"name\": \"garbage-dataset-classification\"},\n",
    "    {\"slug\": \"parohod/warp-waste-recycling-plant-dataset\", \"name\": \"warp-waste-recycling-plant-dataset\"},\n",
    "    {\"slug\": \"asdasdasasdas/garbage-classification\", \"name\": \"garbage-classification\"},\n",
    "    {\"slug\": \"techsash/waste-classification-data\", \"name\": \"waste-classification-data\"},\n",
    "    {\"slug\": \"alistairking/recyclable-and-household-waste-classification\", \"name\": \"recyclable-and-household-waste-classification\"},\n",
    "    {\"slug\": \"vishallazrus/multi-class-garbage-classification-dataset\", \"name\": \"multi-class-garbage-classification-dataset\"},\n",
    "    {\"slug\": \"mostafaabla/garbage-classification\", \"name\": \"garbage-classification-mostafa\"}\n",
    "]\n",
    "\n",
    "def download_kaggle_datasets(datasets, base_dir=\"./data/kaggle\"):\n",
    "    \"\"\"\n",
    "    Download Kaggle datasets using the Kaggle Python API (not CLI).\n",
    "\n",
    "    Args:\n",
    "        datasets: List of dataset dictionaries with 'slug' and 'name'\n",
    "        base_dir: Base directory to store downloaded datasets\n",
    "    \"\"\"\n",
    "    import sys\n",
    "    import time\n",
    "\n",
    "    base_path = Path(base_dir)\n",
    "    base_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    print(\"=\"*80)\n",
    "    print(\"üì¶ KAGGLE DATASET DOWNLOAD\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    # Import Kaggle API\n",
    "    try:\n",
    "        from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "        api = KaggleApi()\n",
    "        api.authenticate()\n",
    "        print(\"‚úÖ Kaggle API authenticated successfully!\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed to authenticate Kaggle API: {e}\")\n",
    "        print(\"\\nPlease ensure:\")\n",
    "        print(\"1. You have a Kaggle account\")\n",
    "        print(\"2. Your username is correct in the cell above\")\n",
    "        print(\"3. Your API key is correct\")\n",
    "        return [], datasets\n",
    "\n",
    "    print()\n",
    "\n",
    "    downloaded = []\n",
    "    failed = []\n",
    "\n",
    "    for idx, dataset in enumerate(datasets, 1):\n",
    "        dataset_slug = dataset[\"slug\"]\n",
    "        dataset_name = dataset[\"name\"]\n",
    "        dataset_path = base_path / dataset_name\n",
    "\n",
    "        print(f\"\\n[{idx}/{len(datasets)}] {dataset_name}\")\n",
    "        print(f\"      Source: {dataset_slug}\")\n",
    "\n",
    "        # Check if already downloaded\n",
    "        if dataset_path.exists() and any(dataset_path.iterdir()):\n",
    "            print(f\"      ‚úÖ Already downloaded, skipping...\")\n",
    "            downloaded.append(dataset_name)\n",
    "            continue\n",
    "\n",
    "        print(f\"      üì• Downloading...\", end=\"\", flush=True)\n",
    "\n",
    "        try:\n",
    "            # Create dataset directory\n",
    "            dataset_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "            start_time = time.time()\n",
    "\n",
    "            # Download using Kaggle Python API with quiet mode\n",
    "            # This prevents blocking output\n",
    "            api.dataset_download_files(\n",
    "                dataset_slug,\n",
    "                path=str(dataset_path),\n",
    "                unzip=True,\n",
    "                quiet=True  # Changed to True to prevent blocking\n",
    "            )\n",
    "\n",
    "            elapsed = time.time() - start_time\n",
    "\n",
    "            # Verify download\n",
    "            if dataset_path.exists() and any(dataset_path.iterdir()):\n",
    "                print(f\" ‚úÖ Done! ({elapsed:.1f}s)\")\n",
    "                downloaded.append(dataset_name)\n",
    "            else:\n",
    "                print(f\" ‚ùå Failed (no files found)\")\n",
    "                failed.append(dataset_name)\n",
    "\n",
    "        except KeyboardInterrupt:\n",
    "            print(f\"\\n\\n‚ö†Ô∏è  Download interrupted by user!\")\n",
    "            print(f\"   Downloaded so far: {len(downloaded)}/{len(datasets)}\")\n",
    "            return downloaded, failed + [d[\"name\"] for d in datasets[idx-1:]]\n",
    "\n",
    "        except Exception as e:\n",
    "            error_msg = str(e)\n",
    "            # Shorten long error messages\n",
    "            if len(error_msg) > 100:\n",
    "                error_msg = error_msg[:100] + \"...\"\n",
    "            print(f\" ‚ùå Error: {error_msg}\")\n",
    "            failed.append(dataset_name)\n",
    "\n",
    "            # Clean up partial download\n",
    "            if dataset_path.exists():\n",
    "                try:\n",
    "                    shutil.rmtree(dataset_path)\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "        # Flush output to ensure it's displayed\n",
    "        sys.stdout.flush()\n",
    "\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üìä DOWNLOAD SUMMARY\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"‚úÖ Successfully downloaded: {len(downloaded)}/{len(datasets)}\")\n",
    "    print(f\"‚ùå Failed: {len(failed)}/{len(datasets)}\")\n",
    "\n",
    "    if downloaded:\n",
    "        print(f\"\\n‚úÖ Downloaded datasets:\")\n",
    "        for name in downloaded:\n",
    "            print(f\"   ‚úì {name}\")\n",
    "\n",
    "    if failed:\n",
    "        print(f\"\\n‚ö†Ô∏è  Failed datasets:\")\n",
    "        for name in failed:\n",
    "            print(f\"   ‚úó {name}\")\n",
    "\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    return downloaded, failed\n",
    "\n",
    "# Download all datasets\n",
    "print(\"Starting Kaggle dataset downloads...\")\n",
    "print(\"This may take 10-30 minutes depending on your internet connection.\")\n",
    "print(\"üí° TIP: If a download seems stuck, press Ctrl+C to skip and continue with next dataset\")\n",
    "print()\n",
    "\n",
    "try:\n",
    "    downloaded, failed = download_kaggle_datasets(KAGGLE_DATASETS)\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\n\\n‚ö†Ô∏è  Download process interrupted!\")\n",
    "    print(\"You can continue with the datasets that were successfully downloaded.\")\n",
    "    downloaded, failed = [], []\n",
    "\n",
    "if len(downloaded) == 0:\n",
    "    print(\"\\n‚ö†Ô∏è  WARNING: No datasets were downloaded!\")\n",
    "    print(\"Please check your Kaggle API token and internet connection.\")\n",
    "    print(\"\\nüí° You can still continue with the notebook - we'll use sample data for testing.\")\n",
    "else:\n",
    "    print(f\"\\n‚úÖ Ready to proceed with {len(downloaded)} datasets!\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üìù NOTE: Cell execution complete! You can now proceed to the next cell.\")\n",
    "print(\"=\"*80)\n",
    "\n"
   ],
   "id": "e6605fb339e5e0f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "üîë CONFIGURING KAGGLE API\n",
      "================================================================================\n",
      "\n",
      "üìÑ Found existing kaggle.json, loading credentials...\n",
      "   ‚úÖ Loaded username: michealjiang\n",
      "\n",
      "‚úÖ Kaggle credentials saved to: /Users/jiangshengbo/.kaggle/kaggle.json\n",
      "   Username: michealjiang\n",
      "   Key: 92ce58a4cc...123f\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Starting Kaggle dataset downloads...\n",
      "This may take 10-30 minutes depending on your internet connection.\n",
      "üí° TIP: If a download seems stuck, press Ctrl+C to skip and continue with next dataset\n",
      "\n",
      "================================================================================\n",
      "üì¶ KAGGLE DATASET DOWNLOAD\n",
      "================================================================================\n",
      "‚úÖ Kaggle API authenticated successfully!\n",
      "\n",
      "\n",
      "[1/8] garbage-classification-v2\n",
      "      Source: sumn2u/garbage-classification-v2\n",
      "      ‚úÖ Already downloaded, skipping...\n",
      "\n",
      "[2/8] garbage-dataset-classification\n",
      "      Source: zlatan599/garbage-dataset-classification\n",
      "      ‚úÖ Already downloaded, skipping...\n",
      "\n",
      "[3/8] warp-waste-recycling-plant-dataset\n",
      "      Source: parohod/warp-waste-recycling-plant-dataset\n",
      "      ‚úÖ Already downloaded, skipping...\n",
      "\n",
      "[4/8] garbage-classification\n",
      "      Source: asdasdasasdas/garbage-classification\n",
      "      ‚úÖ Already downloaded, skipping...\n",
      "\n",
      "[5/8] waste-classification-data\n",
      "      Source: techsash/waste-classification-data\n",
      "      ‚úÖ Already downloaded, skipping...\n",
      "\n",
      "[6/8] recyclable-and-household-waste-classification\n",
      "      Source: alistairking/recyclable-and-household-waste-classification\n",
      "      ‚úÖ Already downloaded, skipping...\n",
      "\n",
      "[7/8] multi-class-garbage-classification-dataset\n",
      "      Source: vishallazrus/multi-class-garbage-classification-dataset\n",
      "      ‚úÖ Already downloaded, skipping...\n",
      "\n",
      "[8/8] garbage-classification-mostafa\n",
      "      Source: mostafaabla/garbage-classification\n",
      "      ‚úÖ Already downloaded, skipping...\n",
      "\n",
      "================================================================================\n",
      "üìä DOWNLOAD SUMMARY\n",
      "================================================================================\n",
      "‚úÖ Successfully downloaded: 8/8\n",
      "‚ùå Failed: 0/8\n",
      "\n",
      "‚úÖ Downloaded datasets:\n",
      "   ‚úì garbage-classification-v2\n",
      "   ‚úì garbage-dataset-classification\n",
      "   ‚úì warp-waste-recycling-plant-dataset\n",
      "   ‚úì garbage-classification\n",
      "   ‚úì waste-classification-data\n",
      "   ‚úì recyclable-and-household-waste-classification\n",
      "   ‚úì multi-class-garbage-classification-dataset\n",
      "   ‚úì garbage-classification-mostafa\n",
      "================================================================================\n",
      "\n",
      "‚úÖ Ready to proceed with 8 datasets!\n",
      "\n",
      "================================================================================\n",
      "üìù NOTE: Cell execution complete! You can now proceed to the next cell.\n",
      "================================================================================\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-11T06:14:55.672233Z",
     "start_time": "2026-02-11T06:14:43.830328Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import random\n",
    "import logging\n",
    "import time\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple, Optional, Any\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "\n",
    "import timm\n",
    "from timm.data import create_transform, resolve_data_config\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GATv2Conv\n",
    "from tqdm.notebook import tqdm\n",
    "import wandb\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from sklearn.metrics import classification_report, confusion_matrix, precision_recall_fscore_support\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ],
   "id": "bd161b494b55e777",
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-11T06:14:55.699370Z",
     "start_time": "2026-02-11T06:14:55.693681Z"
    }
   },
   "source": [
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def set_seed(seed: int = 42):\n",
    "    \"\"\"Set random seed for reproducibility across all frameworks.\"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "    elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
    "        # MPS doesn't need special seeding\n",
    "        pass\n",
    "    logger.info(f\"‚úì Random seed set to {seed}\")\n",
    "\n",
    "def get_device():\n",
    "    \"\"\"\n",
    "    Detect and return the best available device for training.\n",
    "    Priority: CUDA > MPS (Apple Silicon) > CPU\n",
    "\n",
    "    CRITICAL: MPS DISABLED due to crashes with NumPy 2.x + manual tensor conversion\n",
    "    Using CPU for 100% stability until NumPy is fixed in Jupyter environment\n",
    "    \"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda\")\n",
    "        logger.info(f\"üöÄ Using CUDA GPU: {torch.cuda.get_device_name(0)}\")\n",
    "        logger.info(f\"   Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "        return device\n",
    "    # CRITICAL FIX: MPS disabled - causes Python crashes with NumPy 2.x\n",
    "    # elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
    "    #     device = torch.device(\"mps\")\n",
    "    #     logger.info(f\"üçé Using Apple Silicon MPS (Metal Performance Shaders)\")\n",
    "    #     logger.info(f\"   Optimized for M1/M2/M3 chips\")\n",
    "    #     return device\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "        logger.info(f\"üíª Using CPU for maximum stability\")\n",
    "        logger.info(f\"   ‚ö†Ô∏è  MPS disabled due to crashes - will re-enable after NumPy fix\")\n",
    "        logger.info(f\"   Training will be slower but 100% stable\")\n",
    "        return device\n",
    "\n",
    "def optimize_memory(device):\n",
    "    \"\"\"\n",
    "    Memory optimization for different hardware backends.\n",
    "    Supports CUDA, MPS (Apple Silicon), and CPU.\n",
    "    \"\"\"\n",
    "    if device.type == \"cuda\":\n",
    "        # CUDA GPU optimization\n",
    "        torch.cuda.empty_cache()\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "\n",
    "        # TF32 support (only in PyTorch 1.7+)\n",
    "        try:\n",
    "            torch.backends.cuda.matmul.allow_tf32 = True\n",
    "            torch.backends.cudnn.allow_tf32 = True\n",
    "        except AttributeError:\n",
    "            pass  # Older PyTorch versions don't have TF32 support\n",
    "\n",
    "        import os\n",
    "        os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True,max_split_size_mb:512'\n",
    "\n",
    "        try:\n",
    "            torch.cuda.set_per_process_memory_fraction(0.95)\n",
    "        except AttributeError:\n",
    "            pass  # Older PyTorch versions don't have this method\n",
    "\n",
    "        logger.info(\"‚úì CUDA memory optimization enabled\")\n",
    "\n",
    "    elif device.type == \"mps\":\n",
    "        # MPS (Apple Silicon) optimization\n",
    "        # MPS doesn't have explicit memory management like CUDA\n",
    "        # But we can set environment variables for better performance\n",
    "        import os\n",
    "        os.environ['PYTORCH_MPS_HIGH_WATERMARK_RATIO'] = '0.0'  # Disable memory caching\n",
    "\n",
    "        logger.info(\"‚úì MPS optimization enabled\")\n",
    "        logger.info(\"  - High watermark ratio: 0.0 (aggressive memory release)\")\n",
    "\n",
    "    else:\n",
    "        # CPU optimization\n",
    "        # Set number of threads for CPU training\n",
    "        import os\n",
    "        num_threads = os.cpu_count() or 4\n",
    "        torch.set_num_threads(num_threads)\n",
    "\n",
    "        logger.info(f\"‚úì CPU optimization enabled\")\n",
    "        logger.info(f\"  - Using {num_threads} threads\")\n",
    "\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=15, mode=\"max\", delta=0):\n",
    "        self.patience = patience\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.mode = mode\n",
    "        self.delta = delta\n",
    "\n",
    "    def __call__(self, current_score):\n",
    "        if self.best_score is None:\n",
    "            self.best_score = current_score\n",
    "        elif self.mode == \"max\":\n",
    "            if current_score <= self.best_score + self.delta:\n",
    "                self.counter += 1\n",
    "                if self.counter >= self.patience:\n",
    "                    self.early_stop = True\n",
    "            else:\n",
    "                self.best_score = current_score\n",
    "                self.counter = 0\n",
    "        return self.early_stop"
   ],
   "id": "e37d70388c34be67",
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-11T06:14:55.706653Z",
     "start_time": "2026-02-11T06:14:55.702888Z"
    }
   },
   "source": [
    "TARGET_CLASSES = [\n",
    "    'aerosol_cans', 'aluminum_food_cans', 'aluminum_soda_cans', 'cardboard_boxes', 'cardboard_packaging',\n",
    "    'clothing', 'coffee_grounds', 'disposable_plastic_cutlery', 'egg_shells', 'food_waste',\n",
    "    'glass_beverage_bottles', 'glass_cosmetic_containers', 'glass_food_jars', 'magazines',\n",
    "    'newspaper', 'office_paper', 'paper_cups', 'plastic_cup_lids', 'plastic_detergent_bottles',\n",
    "    'plastic_food_containers', 'plastic_shopping_bags', 'plastic_soda_bottles', 'plastic_straws',\n",
    "    'plastic_trash_bags', 'plastic_water_bottles', 'shoes', 'steel_food_cans', 'styrofoam_cups',\n",
    "    'styrofoam_food_containers', 'tea_bags'\n",
    "]\n",
    "\n",
    "VISION_CONFIG = {\n",
    "    \"model\": {\n",
    "        \"backbone\": \"eva02_base_patch14_224\",  # EVA02 Base (86M params) - Best for waste classification\n",
    "        \"pretrained\": True,\n",
    "        \"num_classes\": 30,\n",
    "        \"drop_rate\": 0.15,  # OPTIMIZED: Minimal dropout for maximum learning\n",
    "        \"drop_path_rate\": 0.05  # OPTIMIZED: Minimal stochastic depth for better gradients\n",
    "    },\n",
    "    \"data\": {\n",
    "        \"input_size\": 224,  # Standard EVA02 input size\n",
    "        \"num_workers\": 0,  # CRITICAL: Disabled for macOS stability\n",
    "        \"pin_memory\": False,  # Not needed for CPU\n",
    "        \"sources\": [\n",
    "            {\n",
    "                \"name\": \"master_30\",\n",
    "                \"path\": \"./data/kaggle/recyclable-and-household-waste-classification/images\",\n",
    "                \"type\": \"master\"\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"garbage_12\",\n",
    "                \"path\": \"./data/kaggle/garbage-classification-mostafa/garbage_classification\",\n",
    "                \"type\": \"mapped_12\"\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"waste_22k\",\n",
    "                \"path\": \"./data/kaggle/waste-classification-data/DATASET\",\n",
    "                \"type\": \"mapped_2\"\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"garbage_v2_10\",\n",
    "                \"path\": \"./data/kaggle/garbage-classification-v2\",\n",
    "                \"type\": \"mapped_10\"\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"garbage_6\",\n",
    "                \"path\": \"./data/kaggle/garbage-classification\",\n",
    "                \"type\": \"mapped_6\"\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"garbage_balanced\",\n",
    "                \"path\": \"./data/kaggle/garbage-dataset-classification\",\n",
    "                \"type\": \"mapped_6\"\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"warp_industrial\",\n",
    "                \"path\": \"./data/kaggle/warp-waste-recycling-plant-dataset\",\n",
    "                \"type\": \"industrial\"\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"multiclass_garbage\",\n",
    "                \"path\": \"./data/kaggle/multi-class-garbage-classification-dataset\",\n",
    "                \"type\": \"multiclass\"\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    \"training\": {\n",
    "        \"batch_size\": 8,  # INCREASED: CPU can handle this with optimized pipeline\n",
    "        \"grad_accum_steps\": 8,  # ADJUSTED: Maintain effective batch size of 64 (8 √ó 8)\n",
    "        \"learning_rate\": 2e-5,  # PEAK OPTIMAL: Best balance for fast learning + stability\n",
    "        \"weight_decay\": 0.05,  # OPTIMAL: Standard regularization strength\n",
    "        \"num_epochs\": 20,\n",
    "        \"patience\": 7,  # INCREASED: More patience for better convergence\n",
    "        \"use_amp\": False,  # AMP not supported on CPU\n",
    "        \"max_grad_norm\": 1.0,  # Gradient clipping for stability\n",
    "        \"warmup_epochs\": 2  # NEW: Warmup for stable start\n",
    "    }\n",
    "}"
   ],
   "id": "e85800f6504ff2e9",
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-11T06:14:55.723324Z",
     "start_time": "2026-02-11T06:14:55.709623Z"
    }
   },
   "source": [
    "class UnifiedWasteDataset(Dataset):\n",
    "    \"\"\"\n",
    "    A unified dataset that ingests data from multiple sources and maps them\n",
    "    to a single 30-class target schema.\n",
    "    \"\"\"\n",
    "    def __init__(self, sources_config, target_classes, transform=None):\n",
    "        self.transform = transform\n",
    "        self.target_classes = sorted(target_classes)\n",
    "        self.class_to_idx = {c: i for i, c in enumerate(self.target_classes)}\n",
    "        self.samples = []\n",
    "\n",
    "        self.skipped_count = 0\n",
    "        self.skipped_labels = {}  # Track what labels are being skipped\n",
    "\n",
    "        total_added = 0\n",
    "        total_skipped = 0\n",
    "\n",
    "        for source in sources_config:\n",
    "            added, skipped = self._ingest_source(source)\n",
    "            total_added += added\n",
    "            total_skipped += skipped\n",
    "\n",
    "        logger.info(f\"=\"*60)\n",
    "        logger.info(f\"üìä Dataset Summary:\")\n",
    "        logger.info(f\"  ‚úì Total images loaded: {len(self.samples)}\")\n",
    "        logger.info(f\"  ‚úì Images added: {total_added}\")\n",
    "        logger.info(f\"  ‚ö† Images skipped: {total_skipped}\")\n",
    "        logger.info(f\"  üìà Utilization: {100*total_added/(total_added+total_skipped) if (total_added+total_skipped) > 0 else 0:.1f}%\")\n",
    "        logger.info(f\"=\"*60)\n",
    "\n",
    "        # Log skipped labels for debugging (top 10 only)\n",
    "        if self.skipped_labels:\n",
    "            logger.warning(f\"‚ö† Top 10 skipped labels:\")\n",
    "            for label, count in sorted(self.skipped_labels.items(), key=lambda x: x[1], reverse=True)[:10]:\n",
    "                logger.warning(f\"  '{label}': {count} images\")\n",
    "\n",
    "        # Validate we have enough data\n",
    "        if len(self.samples) == 0:\n",
    "            raise ValueError(\n",
    "                \"‚ùå No images loaded! Please check:\\n\"\n",
    "                \"  1. Dataset paths are correct\\n\"\n",
    "                \"  2. Datasets are attached in Kaggle\\n\"\n",
    "                \"  3. Label mappings are configured correctly\"\n",
    "            )\n",
    "\n",
    "        if len(self.samples) < 100:\n",
    "            logger.warning(f\"‚ö† Very few images loaded ({len(self.samples)}). Training may not be effective.\")\n",
    "\n",
    "    def _ingest_source(self, source):\n",
    "        \"\"\"\n",
    "        Ingest images from a data source with robust error handling.\n",
    "        Returns: (images_added, images_skipped) tuple\n",
    "        \"\"\"\n",
    "        path = Path(source[\"path\"])\n",
    "        images_added = 0\n",
    "        images_skipped = 0\n",
    "\n",
    "        if not path.exists():\n",
    "            parent = path.parent\n",
    "            found = False\n",
    "            if parent.exists():\n",
    "                for child in parent.iterdir():\n",
    "                    if child.is_dir():\n",
    "                        try:\n",
    "                            if any(child.iterdir()):\n",
    "                                path = child\n",
    "                                found = True\n",
    "                                break\n",
    "                        except PermissionError:\n",
    "                            continue\n",
    "\n",
    "            if not found or not path.exists():\n",
    "                logger.warning(f\"‚ö† Source {source['name']} not found at {source['path']}. Skipping.\")\n",
    "                return images_added, images_skipped\n",
    "\n",
    "        logger.info(f\"üìÇ Ingesting {source['name']} from {path}...\")\n",
    "\n",
    "        for root, _, files in os.walk(path):\n",
    "            folder_name = Path(root).name.lower()\n",
    "\n",
    "            target_label = self._map_label(folder_name, source['type'])\n",
    "\n",
    "            if target_label:\n",
    "                target_idx = self.class_to_idx[target_label]\n",
    "                for file in files:\n",
    "                    if file.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp')):\n",
    "                        self.samples.append((Path(root) / file, target_idx))\n",
    "                        images_added += 1\n",
    "            else:\n",
    "                img_count = sum(1 for f in files if f.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp')))\n",
    "                if img_count > 0:\n",
    "                    self.skipped_count += img_count\n",
    "                    images_skipped += img_count\n",
    "                    # Track which labels are being skipped\n",
    "                    if folder_name not in self.skipped_labels:\n",
    "                        self.skipped_labels[folder_name] = 0\n",
    "                    self.skipped_labels[folder_name] += img_count\n",
    "\n",
    "        logger.info(f\"‚úì {source['name']}: Added {images_added} images, skipped {images_skipped}\")\n",
    "        return images_added, images_skipped\n",
    "\n",
    "    def _map_label(self, raw_label, source_type):\n",
    "        \"\"\"\n",
    "        Professional label mapping with comprehensive coverage.\n",
    "        Maps diverse dataset labels to unified 30-class taxonomy.\n",
    "        \"\"\"\n",
    "        raw = raw_label.lower().strip()\n",
    "\n",
    "        # Skip metadata/structure folders that are not actual labels\n",
    "        metadata_folders = {\n",
    "            'default', 'real_world', 'images', 'train', 'test', 'val',\n",
    "            'segmentationobject', 'segmentationclass', 'jpegimages',\n",
    "            'annotations', 'assets', 'data', 'dataset', 'samples'\n",
    "        }\n",
    "        if raw in metadata_folders:\n",
    "            return None\n",
    "\n",
    "        if source_type == 'master':\n",
    "            if raw in self.target_classes:\n",
    "                return raw\n",
    "            # Fallback: try to find closest match\n",
    "            for target in self.target_classes:\n",
    "                if raw in target or target in raw:\n",
    "                    return target\n",
    "            return None\n",
    "\n",
    "        if source_type == 'mapped_12':\n",
    "            mapping = {\n",
    "                'paper': 'office_paper',\n",
    "                'cardboard': 'cardboard_boxes',\n",
    "                'plastic': 'plastic_food_containers',\n",
    "                'metal': 'aluminum_food_cans',\n",
    "                'glass': 'glass_food_jars',\n",
    "                'brown-glass': 'glass_beverage_bottles',\n",
    "                'green-glass': 'glass_beverage_bottles',\n",
    "                'white-glass': 'glass_food_jars',\n",
    "                'clothes': 'clothing',\n",
    "                'shoes': 'shoes',\n",
    "                'biological': 'food_waste',\n",
    "                'trash': 'food_waste'\n",
    "            }\n",
    "            return mapping.get(raw)\n",
    "\n",
    "        if source_type == 'mapped_2':\n",
    "            # Organic waste\n",
    "            if raw in ['organic', 'o']:\n",
    "                return 'food_waste'\n",
    "            # Recyclable waste (paper, plastic, metal, glass mix)\n",
    "            if raw in ['recyclable', 'r']:\n",
    "                return 'plastic_food_containers'  # Generic recyclable\n",
    "            return None\n",
    "\n",
    "        if source_type == 'mapped_10':\n",
    "            mapping = {\n",
    "                'metal': 'aluminum_food_cans',\n",
    "                'glass': 'glass_food_jars',\n",
    "                'biological': 'food_waste',\n",
    "                'paper': 'office_paper',\n",
    "                'battery': 'aerosol_cans',\n",
    "                'trash': 'food_waste',\n",
    "                'cardboard': 'cardboard_boxes',\n",
    "                'shoes': 'shoes',\n",
    "                'clothes': 'clothing',\n",
    "                'plastic': 'plastic_food_containers'\n",
    "            }\n",
    "            return mapping.get(raw)\n",
    "\n",
    "        if source_type == 'mapped_6':\n",
    "            mapping = {\n",
    "                'cardboard': 'cardboard_boxes',\n",
    "                'glass': 'glass_food_jars',\n",
    "                'metal': 'aluminum_food_cans',\n",
    "                'paper': 'office_paper',\n",
    "                'plastic': 'plastic_food_containers',\n",
    "                'trash': 'food_waste'\n",
    "            }\n",
    "            return mapping.get(raw)\n",
    "\n",
    "        if source_type == 'industrial':\n",
    "            mapping = {\n",
    "                'pet': 'plastic_food_containers',\n",
    "                'hdpe': 'plastic_food_containers',\n",
    "                'pvc': 'plastic_food_containers',\n",
    "                'ldpe': 'plastic_food_containers',\n",
    "                'pp': 'plastic_food_containers',\n",
    "                'ps': 'plastic_food_containers',\n",
    "                'metal': 'aluminum_food_cans',\n",
    "                'glass': 'glass_food_jars',\n",
    "                'paper': 'office_paper',\n",
    "                'cardboard': 'cardboard_boxes',\n",
    "                'trash': 'food_waste'\n",
    "            }\n",
    "            return mapping.get(raw)\n",
    "\n",
    "        if source_type == 'multiclass':\n",
    "            mapping = {\n",
    "                'plastic': 'plastic_food_containers',\n",
    "                'metal': 'aluminum_food_cans',\n",
    "                'glass': 'glass_food_jars',\n",
    "                'paper': 'office_paper',\n",
    "                'cardboard': 'cardboard_boxes',\n",
    "                'trash': 'food_waste',\n",
    "                'organic': 'food_waste',\n",
    "                'battery': 'aerosol_cans',\n",
    "                'clothes': 'clothing',\n",
    "                'shoes': 'shoes'\n",
    "            }\n",
    "            return mapping.get(raw)\n",
    "\n",
    "        # Universal fallback mappings for common waste categories\n",
    "        # This ensures NO images are skipped\n",
    "        fallback_mapping = {\n",
    "            # Recyclables\n",
    "            'recyclable': 'plastic_food_containers',\n",
    "            'recycle': 'plastic_food_containers',\n",
    "            'recycling': 'plastic_food_containers',\n",
    "            # Waste types\n",
    "            'waste': 'food_waste',\n",
    "            'garbage': 'food_waste',\n",
    "            'rubbish': 'food_waste',\n",
    "            'refuse': 'food_waste',\n",
    "            # Organic\n",
    "            'compost': 'food_waste',\n",
    "            'food': 'food_waste',\n",
    "            'kitchen': 'food_waste',\n",
    "            'biological': 'food_waste',\n",
    "            # Paper products\n",
    "            'newspaper': 'newspaper',\n",
    "            'magazine': 'magazines',\n",
    "            'book': 'office_paper',\n",
    "            'document': 'office_paper',\n",
    "            # Plastic types\n",
    "            'bottle': 'plastic_water_bottles',\n",
    "            'bottle-transp': 'plastic_water_bottles',\n",
    "            'bottle-blue': 'plastic_water_bottles',\n",
    "            'bottle-dark': 'plastic_water_bottles',\n",
    "            'bottle-green': 'plastic_water_bottles',\n",
    "            'bottle-blue5l': 'plastic_water_bottles',\n",
    "            'bottle-milk': 'plastic_water_bottles',\n",
    "            'bottle-oil': 'plastic_water_bottles',\n",
    "            'bottle-yogurt': 'plastic_food_containers',\n",
    "            'bottle-multicolor': 'plastic_water_bottles',\n",
    "            'bottle-transp-full': 'plastic_water_bottles',\n",
    "            'bottle-blue-full': 'plastic_water_bottles',\n",
    "            'bottle-green-full': 'plastic_water_bottles',\n",
    "            'bottle-dark-full': 'plastic_water_bottles',\n",
    "            'bottle-milk-full': 'plastic_water_bottles',\n",
    "            'bottle-multicolorv-full': 'plastic_water_bottles',\n",
    "            'bottle-blue5l-full': 'plastic_water_bottles',\n",
    "            'bottle-oil-full': 'plastic_water_bottles',\n",
    "            'bag': 'plastic_shopping_bags',\n",
    "            'container': 'plastic_food_containers',\n",
    "            'cup': 'paper_cups',\n",
    "            'straw': 'plastic_straws',\n",
    "            # Detergents (plastic containers)\n",
    "            'detergent-white': 'plastic_food_containers',\n",
    "            'detergent-color': 'plastic_food_containers',\n",
    "            'detergent-transparent': 'plastic_food_containers',\n",
    "            'detergent-box': 'cardboard_boxes',\n",
    "            # Metal\n",
    "            'can': 'aluminum_soda_cans',\n",
    "            'cans': 'aluminum_soda_cans',\n",
    "            'tin': 'steel_food_cans',\n",
    "            'aluminum': 'aluminum_food_cans',\n",
    "            'steel': 'steel_food_cans',\n",
    "            'canister': 'aluminum_food_cans',\n",
    "            'battery': 'aerosol_cans',  # Hazardous, map to aerosol as closest\n",
    "            # Glass\n",
    "            'jar': 'glass_food_jars',\n",
    "            'glass-transp': 'glass_food_jars',\n",
    "            'glass-dark': 'glass_beverage_bottles',\n",
    "            'glass-green': 'glass_beverage_bottles',\n",
    "            'white-glass': 'glass_food_jars',\n",
    "            'brown-glass': 'glass_beverage_bottles',\n",
    "            'green-glass': 'glass_beverage_bottles',\n",
    "            # Cardboard\n",
    "            'milk-cardboard': 'cardboard_boxes',\n",
    "            'juice-cardboard': 'cardboard_boxes',\n",
    "            # Textiles\n",
    "            'fabric': 'clothing',\n",
    "            'textile': 'clothing',\n",
    "            # Foam\n",
    "            'foam': 'styrofoam_cups',\n",
    "            'styrofoam': 'styrofoam_cups',\n",
    "            'polystyrene': 'styrofoam_cups',\n",
    "        }\n",
    "\n",
    "        # Try fallback mapping\n",
    "        for key, value in fallback_mapping.items():\n",
    "            if key in raw:\n",
    "                return value\n",
    "\n",
    "        return None\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        PRODUCTION-GRADE: Load and transform image with comprehensive error handling\n",
    "        Ensures ALL images work perfectly regardless of format, size, or corruption\n",
    "        \"\"\"\n",
    "        path, label_idx = self.samples[idx]\n",
    "\n",
    "        try:\n",
    "            # Validate path exists\n",
    "            if not path.exists():\n",
    "                raise FileNotFoundError(f\"Image file not found: {path}\")\n",
    "\n",
    "            # Load image with PIL (handles all formats)\n",
    "            img = Image.open(path)\n",
    "            img.load()  # Force load to catch corruption early\n",
    "\n",
    "            # Convert to RGB (handles RGBA, L, P, etc.)\n",
    "            if img.mode != 'RGB':\n",
    "                img = img.convert('RGB')\n",
    "\n",
    "            # Validate image size\n",
    "            if img.size[0] < 10 or img.size[1] < 10:\n",
    "                raise ValueError(f\"Image too small: {img.size}\")\n",
    "\n",
    "            # Apply transforms if provided\n",
    "            if self.transform:\n",
    "                try:\n",
    "                    img = self.transform(img)\n",
    "                except Exception as transform_error:\n",
    "                    # Log transform errors specifically\n",
    "                    logger.error(f\"‚ùå Transform failed for {path}: {transform_error}\")\n",
    "                    raise\n",
    "                return img, label_idx\n",
    "            else:\n",
    "                return img, label_idx\n",
    "\n",
    "        except Exception as e:\n",
    "            # CRITICAL: Log every failure - this should be RARE\n",
    "            logger.error(f\"‚ùå FAILED TO LOAD IMAGE {idx}: {path}\")\n",
    "            logger.error(f\"   Error: {type(e).__name__}: {e}\")\n",
    "\n",
    "            # Track failure count\n",
    "            if not hasattr(self, '_failure_count'):\n",
    "                self._failure_count = 0\n",
    "            self._failure_count += 1\n",
    "\n",
    "            # ABORT if too many failures\n",
    "            if self._failure_count > 100:\n",
    "                raise RuntimeError(\n",
    "                    f\"‚ùå TOO MANY IMAGE LOADING FAILURES ({self._failure_count})! \"\n",
    "                    \"This indicates a serious dataset problem. Aborting training.\"\n",
    "                )\n",
    "\n",
    "            # FALLBACK: Create valid dummy tensor for corrupt/missing images\n",
    "            # This should only happen for truly corrupt images (< 1%)\n",
    "            dummy_tensor = torch.zeros(3, 224, 224, dtype=torch.float32)\n",
    "            # Apply ImageNet normalization to match real images\n",
    "            dummy_tensor[0] = -0.485 / 0.229  # Normalized black for R channel\n",
    "            dummy_tensor[1] = -0.456 / 0.224  # Normalized black for G channel\n",
    "            dummy_tensor[2] = -0.406 / 0.225  # Normalized black for B channel\n",
    "\n",
    "            return dummy_tensor, label_idx\n",
    "\n",
    "    def get_labels(self):\n",
    "        return [s[1] for s in self.samples]"
   ],
   "id": "4a83856bf02ace6d",
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-11T06:14:55.730502Z",
     "start_time": "2026-02-11T06:14:55.726267Z"
    }
   },
   "source": [
    "def get_vision_transforms(config, model, is_train=True):\n",
    "    \"\"\"\n",
    "    Get vision transforms using standard PyTorch transforms.\n",
    "    Compatible with PIL Images from UnifiedWasteDataset.\n",
    "    \"\"\"\n",
    "    # Get config's input_size (prioritize config over model defaults)\n",
    "    config_input_size = config.get('data', {}).get('input_size', 224)\n",
    "\n",
    "    # Get model config for input size\n",
    "    try:\n",
    "        if hasattr(model, 'default_cfg'):\n",
    "            model_cfg = model.default_cfg\n",
    "        elif hasattr(model, 'pretrained_cfg'):\n",
    "            model_cfg = model.pretrained_cfg\n",
    "        else:\n",
    "            model_cfg = {\n",
    "                'input_size': (3, config_input_size, config_input_size),\n",
    "                'mean': (0.485, 0.456, 0.406),\n",
    "                'std': (0.229, 0.224, 0.225)\n",
    "            }\n",
    "\n",
    "        # Extract input size (handle tuple format)\n",
    "        input_size_tuple = model_cfg.get('input_size', (3, config_input_size, config_input_size))\n",
    "        if isinstance(input_size_tuple, tuple) and len(input_size_tuple) == 3:\n",
    "            img_size = input_size_tuple[1]  # Get height (assuming square images)\n",
    "        else:\n",
    "            img_size = config_input_size  # Use config's input_size\n",
    "\n",
    "        mean = model_cfg.get('mean', (0.485, 0.456, 0.406))\n",
    "        std = model_cfg.get('std', (0.229, 0.224, 0.225))\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.warning(f\"Failed to get model config: {e}, using defaults\")\n",
    "        # Force config's input_size for Mac compatibility (override model default)\n",
    "        img_size = config_input_size\n",
    "        mean = (0.485, 0.456, 0.406)\n",
    "        std = (0.229, 0.224, 0.225)\n",
    "\n",
    "    logger.info(f\"Using transforms with input_size={img_size}, mean={mean}, std={std}\")\n",
    "\n",
    "    # Use standard PyTorch transforms (compatible with PIL Images)\n",
    "    if is_train:\n",
    "        return transforms.Compose([\n",
    "            transforms.Resize((img_size, img_size), interpolation=transforms.InterpolationMode.BICUBIC),\n",
    "            transforms.RandomHorizontalFlip(p=0.5),\n",
    "            transforms.RandomRotation(degrees=15),\n",
    "            transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.1),\n",
    "            transforms.RandomAffine(degrees=0, translate=(0.1, 0.1), scale=(0.9, 1.1)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=mean, std=std)\n",
    "        ])\n",
    "    else:\n",
    "        return transforms.Compose([\n",
    "            transforms.Resize((img_size, img_size), interpolation=transforms.InterpolationMode.BICUBIC),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=mean, std=std)\n",
    "        ])"
   ],
   "id": "8cac2161a057a33e",
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-11T06:14:55.735334Z",
     "start_time": "2026-02-11T06:14:55.733315Z"
    }
   },
   "source": [
    "def create_vision_model(config):\n",
    "    logger.info(f\"Creating model: {config['model']['backbone']}\")\n",
    "    model = timm.create_model(\n",
    "        config[\"model\"][\"backbone\"],\n",
    "        pretrained=config[\"model\"][\"pretrained\"],\n",
    "        num_classes=config[\"model\"][\"num_classes\"],\n",
    "        drop_rate=config[\"model\"][\"drop_rate\"],\n",
    "        drop_path_rate=config[\"model\"][\"drop_path_rate\"]\n",
    "    )\n",
    "    return model"
   ],
   "id": "20be2291a212f609",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-11T06:14:55.772616Z",
     "start_time": "2026-02-11T06:14:55.738442Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_vision_model(config, resume_from_checkpoint=None):\n",
    "    \"\"\"\n",
    "    Professional-grade vision model training with comprehensive error handling.\n",
    "    Optimized for Tesla T4 GPU (14.74 GB) with production-ready memory management.\n",
    "\n",
    "    Args:\n",
    "        config: Training configuration dictionary\n",
    "        resume_from_checkpoint: Path to checkpoint file to resume from (optional)\n",
    "\n",
    "    Returns:\n",
    "        Trained model or None if training fails\n",
    "    \"\"\"\n",
    "    start_epoch = 0\n",
    "    best_val_acc = 0.0\n",
    "    metrics_history = {\n",
    "        \"train_loss\": [], \"train_acc\": [],\n",
    "        \"val_loss\": [], \"val_acc\": [],\n",
    "        \"per_class_f1\": [], \"learning_rate\": []\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        set_seed()\n",
    "        device = get_device()\n",
    "        optimize_memory(device)\n",
    "        logger.info(f\"Using device: {device}\")\n",
    "\n",
    "        # Create and configure model\n",
    "        model = create_vision_model(config).to(device)\n",
    "        total_params = sum(p.numel() for p in model.parameters())\n",
    "        trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "        logger.info(f\"Model parameters: {total_params / 1e6:.2f}M total, {trainable_params / 1e6:.2f}M trainable\")\n",
    "\n",
    "        # Enable gradient checkpointing for memory efficiency (NOT compatible with MPS)\n",
    "        if device.type != \"mps\" and hasattr(model, 'set_grad_checkpointing'):\n",
    "            model.set_grad_checkpointing(enable=True)\n",
    "            logger.info(\"‚úì Gradient checkpointing enabled (saves ~40% memory)\")\n",
    "        elif device.type == \"mps\":\n",
    "            logger.warning(\"‚ö†Ô∏è  Gradient checkpointing disabled (incompatible with MPS - causes crashes)\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Model initialization failed: {e}\")\n",
    "        raise\n",
    "\n",
    "    train_transform = get_vision_transforms(config, model, is_train=True)\n",
    "    val_transform = get_vision_transforms(config, model, is_train=False)\n",
    "\n",
    "    # CRITICAL: Validate transform output size matches model expectations\n",
    "    logger.info(\"üîç Validating transform pipeline...\")\n",
    "    try:\n",
    "        # Create dummy image for validation\n",
    "        import numpy as np\n",
    "        dummy_img = Image.new('RGB', (640, 480), color=(128, 128, 128))\n",
    "\n",
    "        # Convert to numpy array first to avoid NumPy version compatibility issues\n",
    "        # This works around the \"expected np.ndarray (got numpy.ndarray)\" error\n",
    "        dummy_array = np.array(dummy_img)\n",
    "        dummy_img_fixed = Image.fromarray(dummy_array)\n",
    "\n",
    "        transformed = train_transform(dummy_img_fixed)\n",
    "        actual_size = transformed.shape\n",
    "        expected_channels = 3\n",
    "        expected_size = config.get('data', {}).get('input_size', 224)\n",
    "\n",
    "        logger.info(f\"  Transform output shape: {actual_size}\")\n",
    "        logger.info(f\"  Expected: ({expected_channels}, {expected_size}, {expected_size})\")\n",
    "\n",
    "        if actual_size[0] != expected_channels or actual_size[1] != expected_size or actual_size[2] != expected_size:\n",
    "            raise ValueError(\n",
    "                f\"Transform size mismatch! Output {actual_size} != Expected ({expected_channels}, {expected_size}, {expected_size})\"\n",
    "            )\n",
    "        logger.info(\"  ‚úÖ Transform validation passed\")\n",
    "    except TypeError as e:\n",
    "        if \"expected np.ndarray\" in str(e):\n",
    "            logger.warning(f\"‚ö†Ô∏è  NumPy compatibility issue detected: {e}\")\n",
    "            logger.warning(\"  Skipping transform validation (will validate with real data)\")\n",
    "            logger.warning(\"  Consider upgrading: pip install 'numpy<2.0'\")\n",
    "        else:\n",
    "            logger.error(f\"‚ùå Transform validation failed: {e}\")\n",
    "            raise\n",
    "    except Exception as e:\n",
    "        logger.error(f\"‚ùå Transform validation failed: {e}\")\n",
    "        raise\n",
    "\n",
    "    full_dataset = UnifiedWasteDataset(\n",
    "        sources_config=config[\"data\"][\"sources\"],\n",
    "        target_classes=TARGET_CLASSES,\n",
    "        transform=None\n",
    "    )\n",
    "\n",
    "    if len(full_dataset) == 0:\n",
    "        logger.error(\"Dataset is empty. Check paths.\")\n",
    "        return None\n",
    "\n",
    "    # CRITICAL: Validate that samples actually exist on disk\n",
    "    logger.info(\"üîç Validating dataset samples...\")\n",
    "    missing_count = 0\n",
    "    sample_check_count = min(1000, len(full_dataset.samples))\n",
    "\n",
    "    for i in range(sample_check_count):\n",
    "        path, label = full_dataset.samples[i]\n",
    "        if not path.exists():\n",
    "            missing_count += 1\n",
    "            if missing_count <= 5:  # Log first 5 missing files\n",
    "                logger.error(f\"  ‚ùå Missing file: {path}\")\n",
    "\n",
    "    if missing_count > 0:\n",
    "        logger.error(f\"‚ùå {missing_count}/{sample_check_count} sample files are MISSING!\")\n",
    "        raise FileNotFoundError(\n",
    "            f\"{missing_count} image files are missing from disk. \"\n",
    "            \"Dataset paths may be incorrect.\"\n",
    "        )\n",
    "\n",
    "    logger.info(f\"  ‚úÖ All {sample_check_count} checked samples exist on disk\")\n",
    "\n",
    "    train_size = int(0.85 * len(full_dataset))\n",
    "    val_size = len(full_dataset) - train_size\n",
    "    train_dataset, val_dataset = torch.utils.data.random_split(full_dataset, [train_size, val_size])\n",
    "\n",
    "    train_dataset.dataset.transform = train_transform\n",
    "    val_dataset.dataset.transform = val_transform\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=config[\"training\"][\"batch_size\"],\n",
    "        shuffle=True,\n",
    "        num_workers=0,  # Disabled for macOS compatibility (multiprocessing issue)\n",
    "        pin_memory=config[\"data\"][\"pin_memory\"],\n",
    "        persistent_workers=False\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=config[\"training\"][\"batch_size\"] * 2,\n",
    "        shuffle=False,\n",
    "        num_workers=0,  # Disabled for macOS compatibility (multiprocessing issue)\n",
    "        persistent_workers=False\n",
    "    )\n",
    "\n",
    "    # PEAK OPTIMIZER: AdamW with optimal hyperparameters\n",
    "    optimizer = optim.AdamW(\n",
    "        model.parameters(),\n",
    "        lr=config[\"training\"][\"learning_rate\"],\n",
    "        weight_decay=config[\"training\"][\"weight_decay\"],\n",
    "        betas=(0.9, 0.999),  # Standard momentum\n",
    "        eps=1e-8\n",
    "    )\n",
    "\n",
    "    # PEAK CRITERION: Minimal label smoothing for maximum accuracy\n",
    "    criterion = nn.CrossEntropyLoss(label_smoothing=0.0)  # No smoothing for clearest signal\n",
    "\n",
    "    # Professional training configuration\n",
    "    use_amp = config[\"training\"].get(\"use_amp\", False) and (device.type == \"cuda\")\n",
    "    scaler = torch.cuda.amp.GradScaler(enabled=use_amp) if use_amp else None\n",
    "    accumulation_steps = config[\"training\"][\"grad_accum_steps\"]\n",
    "    max_grad_norm = config[\"training\"].get(\"max_grad_norm\", 1.0)\n",
    "    warmup_epochs = config[\"training\"].get(\"warmup_epochs\", 0)\n",
    "\n",
    "    # PEAK SCHEDULER: Cosine annealing with warmup for optimal convergence\n",
    "    total_steps = len(train_loader) * config[\"training\"][\"num_epochs\"] // accumulation_steps\n",
    "    warmup_steps = (len(train_loader) * warmup_epochs) // accumulation_steps\n",
    "\n",
    "    if warmup_steps > 0:\n",
    "        # Use OneCycleLR with warmup\n",
    "        scheduler = optim.lr_scheduler.OneCycleLR(\n",
    "            optimizer,\n",
    "            max_lr=config[\"training\"][\"learning_rate\"],  # Peak at base LR\n",
    "            total_steps=total_steps,\n",
    "            pct_start=warmup_steps / total_steps,  # Warmup percentage\n",
    "            anneal_strategy='cos',\n",
    "            div_factor=10.0,  # Start at LR/10\n",
    "            final_div_factor=100.0  # End at LR/100\n",
    "        )\n",
    "    else:\n",
    "        # Use CosineAnnealingLR without warmup\n",
    "        scheduler = optim.lr_scheduler.CosineAnnealingLR(\n",
    "            optimizer,\n",
    "            T_max=total_steps,\n",
    "            eta_min=config[\"training\"][\"learning_rate\"] / 100\n",
    "        )\n",
    "\n",
    "    # CRITICAL: Load checkpoint if resuming training\n",
    "    if resume_from_checkpoint and Path(resume_from_checkpoint).exists():\n",
    "        logger.info(f\"üìÇ Loading checkpoint from {resume_from_checkpoint}\")\n",
    "        checkpoint = torch.load(resume_from_checkpoint, map_location=device)\n",
    "\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "\n",
    "        if 'scheduler_state_dict' in checkpoint:\n",
    "            scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "\n",
    "        start_epoch = checkpoint.get('epoch', 0) + 1  # Start from next epoch\n",
    "        best_val_acc = checkpoint.get('val_acc', 0.0)\n",
    "\n",
    "        if 'metrics_history' in checkpoint:\n",
    "            metrics_history = checkpoint['metrics_history']\n",
    "\n",
    "        logger.info(f\"‚úÖ Resumed from epoch {start_epoch}, best val acc: {best_val_acc:.2f}%\")\n",
    "    elif resume_from_checkpoint:\n",
    "        logger.warning(f\"‚ö†Ô∏è  Checkpoint not found: {resume_from_checkpoint}. Starting from scratch.\")\n",
    "\n",
    "    early_stopping = EarlyStopping(patience=config[\"training\"][\"patience\"])\n",
    "\n",
    "    if device.type == \"mps\":\n",
    "        logger.info(\"‚ÑπÔ∏è  MPS detected: AMP disabled (not supported on Apple Silicon)\")\n",
    "    elif device.type == \"cpu\":\n",
    "        logger.info(\"‚ÑπÔ∏è  CPU detected: AMP disabled (not supported on CPU)\")\n",
    "    else:\n",
    "        logger.info(f\"‚ÑπÔ∏è  AMP {'enabled' if use_amp else 'disabled'}\")\n",
    "\n",
    "    logger.info(f\"Training configuration:\")\n",
    "    logger.info(f\"  - Batch size: {config['training']['batch_size']}\")\n",
    "    logger.info(f\"  - Gradient accumulation: {accumulation_steps}\")\n",
    "    logger.info(f\"  - Effective batch size: {config['training']['batch_size'] * accumulation_steps}\")\n",
    "    logger.info(f\"  - Mixed precision (AMP): {use_amp}\")\n",
    "    logger.info(f\"  - Gradient clipping: {max_grad_norm}\")\n",
    "    logger.info(f\"  - Learning rate: {config['training']['learning_rate']}\")\n",
    "\n",
    "    # INDUSTRIAL-GRADE: Best model tracking\n",
    "    # Note: best_val_acc and metrics_history initialized at function start (for checkpoint resume support)\n",
    "    best_model_state = None\n",
    "    checkpoint_dir = Path(\"checkpoints\")\n",
    "    checkpoint_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    # Initialize Weights & Biases with graceful fallback\n",
    "    try:\n",
    "        wandb.init(project=\"sustainability-vision-lake\", config=config, mode=\"online\")\n",
    "        logger.info(\"‚úì W&B logging enabled\")\n",
    "    except Exception as e:\n",
    "        logger.warning(f\"W&B initialization failed: {e}. Continuing without logging.\")\n",
    "        wandb.init(mode=\"disabled\")\n",
    "\n",
    "    # CRITICAL: Pre-training sanity check - validate one batch\n",
    "    logger.info(\"üîç Running pre-training sanity check...\")\n",
    "    try:\n",
    "        model.eval()\n",
    "        test_batch = next(iter(train_loader))\n",
    "        test_images, test_labels = test_batch\n",
    "\n",
    "        logger.info(f\"  Batch shape: {test_images.shape}\")\n",
    "        logger.info(f\"  Expected: [batch_size, 3, {config.get('data', {}).get('input_size', 224)}, {config.get('data', {}).get('input_size', 224)}]\")\n",
    "\n",
    "        # Validate batch dimensions\n",
    "        expected_size = config.get('data', {}).get('input_size', 224)\n",
    "        if test_images.shape[1] != 3:\n",
    "            raise ValueError(f\"Invalid channel count: {test_images.shape[1]} (expected 3)\")\n",
    "        if test_images.shape[2] != expected_size or test_images.shape[3] != expected_size:\n",
    "            raise ValueError(\n",
    "                f\"Invalid image size: {test_images.shape[2]}x{test_images.shape[3]} \"\n",
    "                f\"(expected {expected_size}x{expected_size})\"\n",
    "            )\n",
    "\n",
    "        # Test forward pass\n",
    "        use_non_blocking = (device.type == \"cuda\")\n",
    "        test_images = test_images.to(device, non_blocking=use_non_blocking)\n",
    "        test_labels = test_labels.to(device, non_blocking=use_non_blocking)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            test_outputs = model(test_images)\n",
    "            logger.info(f\"  Model output shape: {test_outputs.shape}\")\n",
    "            logger.info(f\"  Expected: [batch_size, {config['model']['num_classes']}]\")\n",
    "\n",
    "            if test_outputs.shape[1] != config['model']['num_classes']:\n",
    "                raise ValueError(\n",
    "                    f\"Invalid output classes: {test_outputs.shape[1]} \"\n",
    "                    f\"(expected {config['model']['num_classes']})\"\n",
    "                )\n",
    "\n",
    "        logger.info(\"  ‚úÖ Pre-training sanity check passed!\")\n",
    "        logger.info(f\"  ‚úÖ All images are {expected_size}x{expected_size}\")\n",
    "        logger.info(f\"  ‚úÖ Model accepts input and produces correct output shape\")\n",
    "\n",
    "        # Clean up\n",
    "        del test_batch, test_images, test_labels, test_outputs\n",
    "        if device.type == \"cuda\":\n",
    "            torch.cuda.empty_cache()\n",
    "        elif device.type == \"mps\":\n",
    "            try:\n",
    "                torch.mps.empty_cache()\n",
    "            except AttributeError:\n",
    "                pass\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"‚ùå Pre-training sanity check failed: {e}\")\n",
    "        logger.error(\"This indicates a fundamental configuration issue. Aborting training.\")\n",
    "        raise\n",
    "\n",
    "    # COMPREHENSIVE DATA QUALITY VALIDATION\n",
    "    logger.info(\"=\"*80)\n",
    "    logger.info(\"üî¨ COMPREHENSIVE DATA QUALITY VALIDATION\")\n",
    "    logger.info(\"=\"*80)\n",
    "\n",
    "    try:\n",
    "        # CRITICAL TEST 1: Validate individual image loading\n",
    "        logger.info(\"Test 1: Individual Image Loading (100 random samples)...\")\n",
    "        import random\n",
    "        sample_indices = random.sample(range(len(train_dataset)), min(100, len(train_dataset)))\n",
    "\n",
    "        failed_samples = []\n",
    "        dummy_tensor_count = 0\n",
    "\n",
    "        for idx in sample_indices:\n",
    "            try:\n",
    "                img, label = train_dataset[idx]\n",
    "\n",
    "                # Check if this is a dummy tensor (all zeros after normalization)\n",
    "                if isinstance(img, torch.Tensor):\n",
    "                    # Check if it's the dummy tensor pattern\n",
    "                    expected_dummy_r = -0.485 / 0.229\n",
    "                    expected_dummy_g = -0.456 / 0.224\n",
    "                    expected_dummy_b = -0.406 / 0.225\n",
    "\n",
    "                    if (torch.allclose(img[0], torch.full_like(img[0], expected_dummy_r), atol=1e-4) and\n",
    "                        torch.allclose(img[1], torch.full_like(img[1], expected_dummy_g), atol=1e-4) and\n",
    "                        torch.allclose(img[2], torch.full_like(img[2], expected_dummy_b), atol=1e-4)):\n",
    "                        dummy_tensor_count += 1\n",
    "                        failed_samples.append(idx)\n",
    "\n",
    "            except Exception as e:\n",
    "                failed_samples.append(idx)\n",
    "                logger.error(f\"  ‚ùå Sample {idx} failed: {e}\")\n",
    "\n",
    "        success_rate = (len(sample_indices) - len(failed_samples)) / len(sample_indices) * 100\n",
    "        logger.info(f\"  ‚úÖ Success rate: {success_rate:.1f}% ({len(sample_indices) - len(failed_samples)}/{len(sample_indices)})\")\n",
    "        logger.info(f\"  ‚ö†Ô∏è  Dummy tensors detected: {dummy_tensor_count}\")\n",
    "        logger.info(f\"  ‚ö†Ô∏è  Failed samples: {len(failed_samples)}\")\n",
    "\n",
    "        # ABORT if too many failures\n",
    "        if dummy_tensor_count > 5:\n",
    "            logger.error(f\"‚ùå TOO MANY DUMMY TENSORS ({dummy_tensor_count}/100)!\")\n",
    "            logger.error(\"   This means images are NOT loading correctly.\")\n",
    "            logger.error(\"   Checking first failed sample for details...\")\n",
    "\n",
    "            if failed_samples:\n",
    "                # Get details about first failure\n",
    "                first_fail_idx = failed_samples[0]\n",
    "                path, label = train_dataset.dataset.samples[first_fail_idx]\n",
    "                logger.error(f\"   Failed sample path: {path}\")\n",
    "                logger.error(f\"   Path exists: {path.exists()}\")\n",
    "                if path.exists():\n",
    "                    logger.error(f\"   File size: {path.stat().st_size} bytes\")\n",
    "\n",
    "            raise RuntimeError(\n",
    "                f\"Dataset loading is BROKEN! {dummy_tensor_count}/100 samples are dummy tensors. \"\n",
    "                \"This is NOT acceptable for training.\"\n",
    "            )\n",
    "\n",
    "        # CRITICAL TEST 2: Validate batch loading\n",
    "        logger.info(\"Test 2: Batch Loading (10 random batches)...\")\n",
    "        batch_count = 0\n",
    "        total_images = 0\n",
    "        value_ranges = []\n",
    "\n",
    "        for batch_idx, (images, labels) in enumerate(train_loader):\n",
    "            if batch_idx >= 10:\n",
    "                break\n",
    "\n",
    "            batch_count += 1\n",
    "            total_images += images.size(0)\n",
    "\n",
    "            # Check for NaN or Inf\n",
    "            if torch.isnan(images).any():\n",
    "                logger.error(f\"  ‚ùå Batch {batch_idx}: Contains NaN values!\")\n",
    "                raise ValueError(\"Dataset contains NaN values\")\n",
    "\n",
    "            if torch.isinf(images).any():\n",
    "                logger.error(f\"  ‚ùå Batch {batch_idx}: Contains Inf values!\")\n",
    "                raise ValueError(\"Dataset contains Inf values\")\n",
    "\n",
    "            # Track value ranges\n",
    "            batch_min = images.min().item()\n",
    "            batch_max = images.max().item()\n",
    "            value_ranges.append((batch_min, batch_max))\n",
    "\n",
    "            # Check if batch contains mostly dummy tensors\n",
    "            # Dummy tensors have very specific values\n",
    "            if batch_min > -2.5 and batch_max < -1.5:\n",
    "                logger.warning(f\"  ‚ö†Ô∏è  Batch {batch_idx} may contain dummy tensors (range: [{batch_min:.3f}, {batch_max:.3f}])\")\n",
    "\n",
    "            # Validate labels\n",
    "            if labels.min() < 0 or labels.max() >= 30:\n",
    "                logger.error(f\"  ‚ùå Batch {batch_idx}: Invalid labels [{labels.min()}, {labels.max()}]\")\n",
    "                raise ValueError(f\"Invalid label range: [{labels.min()}, {labels.max()}]\")\n",
    "\n",
    "        # Report statistics\n",
    "        min_vals = [r[0] for r in value_ranges]\n",
    "        max_vals = [r[1] for r in value_ranges]\n",
    "        overall_min = min(min_vals)\n",
    "        overall_max = max(max_vals)\n",
    "\n",
    "        logger.info(f\"  ‚úÖ Tested {batch_count} batches ({total_images} images)\")\n",
    "        logger.info(f\"  ‚úÖ Value range: [{overall_min:.3f}, {overall_max:.3f}]\")\n",
    "        logger.info(f\"  ‚úÖ No NaN or Inf values detected\")\n",
    "        logger.info(f\"  ‚úÖ All labels valid [0, 29]\")\n",
    "\n",
    "        # Validate value range is reasonable for real images\n",
    "        # Real images after ImageNet normalization should be roughly [-2.5, 2.5]\n",
    "        if overall_min > -1.0 or overall_max < 1.0:\n",
    "            logger.warning(f\"  ‚ö†Ô∏è  WARNING: Value range [{overall_min:.3f}, {overall_max:.3f}] seems narrow!\")\n",
    "            logger.warning(f\"     Expected range for real images: approximately [-2.5, 2.5]\")\n",
    "            logger.warning(f\"     This may indicate dummy tensors are being used!\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"‚ùå Data quality validation failed: {e}\")\n",
    "        raise\n",
    "\n",
    "    logger.info(\"=\"*80)\n",
    "    logger.info(\"‚úÖ ALL VALIDATION TESTS PASSED - READY TO TRAIN\")\n",
    "    logger.info(\"=\"*80)\n",
    "\n",
    "    model.train()  # Set back to training mode\n",
    "\n",
    "    # Main training loop with error handling\n",
    "    try:\n",
    "        for epoch in range(start_epoch, config[\"training\"][\"num_epochs\"]):\n",
    "            model.train()\n",
    "            running_loss = 0.0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "\n",
    "            pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{config['training']['num_epochs']}\")\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            for i, (images, labels) in enumerate(pbar):\n",
    "                try:\n",
    "                    # CRITICAL: Aggressive memory cleanup every 100 batches for MPS stability\n",
    "                    if i > 0 and i % 100 == 0 and device.type == \"mps\":\n",
    "                        try:\n",
    "                            torch.mps.empty_cache()\n",
    "                        except AttributeError:\n",
    "                            pass\n",
    "\n",
    "                    # CRITICAL: Validate batch shape before processing\n",
    "                    expected_size = config.get('data', {}).get('input_size', 224)\n",
    "                    if images.shape[1] != 3 or images.shape[2] != expected_size or images.shape[3] != expected_size:\n",
    "                        logger.error(\n",
    "                            f\"‚ùå Batch {i} has invalid shape: {images.shape}. \"\n",
    "                            f\"Expected: [batch_size, 3, {expected_size}, {expected_size}]. Skipping batch.\"\n",
    "                        )\n",
    "                        continue\n",
    "\n",
    "                    # non_blocking only works with CUDA + pin_memory\n",
    "                    use_non_blocking = (device.type == \"cuda\")\n",
    "                    images, labels = images.to(device, non_blocking=use_non_blocking), labels.to(device, non_blocking=use_non_blocking)\n",
    "\n",
    "                except RuntimeError as e:\n",
    "                    if \"out of memory\" in str(e) or \"MPS\" in str(e):\n",
    "                        logger.error(f\"OOM at batch {i}. Clearing cache and skipping batch.\")\n",
    "                        if device.type == \"cuda\":\n",
    "                            torch.cuda.empty_cache()\n",
    "                        elif device.type == \"mps\":\n",
    "                            try:\n",
    "                                torch.mps.empty_cache()\n",
    "                            except AttributeError:\n",
    "                                pass  # MPS empty_cache not available in older PyTorch\n",
    "                        continue\n",
    "                    raise\n",
    "                except AssertionError as e:\n",
    "                    # Catch assertion errors from model (e.g., size mismatches)\n",
    "                    logger.error(f\"‚ùå Assertion error at batch {i}: {e}\")\n",
    "                    logger.error(f\"   Batch shape: {images.shape}\")\n",
    "                    logger.error(f\"   This indicates a size mismatch. Skipping batch.\")\n",
    "                    continue\n",
    "\n",
    "                try:\n",
    "                    if use_amp:\n",
    "                        with torch.cuda.amp.autocast():\n",
    "                            outputs = model(images)\n",
    "                            loss = criterion(outputs, labels) / accumulation_steps\n",
    "                        scaler.scale(loss).backward()\n",
    "\n",
    "                        if (i + 1) % accumulation_steps == 0:\n",
    "                            scaler.unscale_(optimizer)\n",
    "\n",
    "                            # CRITICAL: Check gradient health\n",
    "                            grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=max_grad_norm)\n",
    "                            if not np.isfinite(grad_norm.item()):\n",
    "                                logger.error(f\"‚ùå Non-finite gradient norm at batch {i}: {grad_norm.item()}\")\n",
    "                                logger.error(\"   Resetting optimizer state and skipping update.\")\n",
    "                                optimizer.zero_grad()\n",
    "                                continue\n",
    "\n",
    "                            scaler.step(optimizer)\n",
    "                            scaler.update()\n",
    "                            optimizer.zero_grad()\n",
    "                            scheduler.step()  # OneCycleLR steps per batch\n",
    "                    else:\n",
    "                        outputs = model(images)\n",
    "                        loss = criterion(outputs, labels) / accumulation_steps\n",
    "                        loss.backward()\n",
    "                        if (i + 1) % accumulation_steps == 0:\n",
    "                            # CRITICAL: Check gradient health\n",
    "                            grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=max_grad_norm)\n",
    "                            if not np.isfinite(grad_norm.item()):\n",
    "                                logger.error(f\"‚ùå Non-finite gradient norm at batch {i}: {grad_norm.item()}\")\n",
    "                                logger.error(\"   Resetting optimizer state and skipping update.\")\n",
    "                                optimizer.zero_grad()\n",
    "                                continue\n",
    "\n",
    "                            optimizer.step()\n",
    "                            optimizer.zero_grad()\n",
    "                            scheduler.step()  # OneCycleLR steps per batch\n",
    "\n",
    "                except AssertionError as e:\n",
    "                    # Catch assertion errors from model forward pass\n",
    "                    logger.error(f\"‚ùå Model forward pass failed at batch {i}: {e}\")\n",
    "                    logger.error(f\"   Input shape: {images.shape}\")\n",
    "                    logger.error(f\"   Expected size: {expected_size}x{expected_size}\")\n",
    "                    logger.error(\"   Skipping batch and continuing training.\")\n",
    "                    continue\n",
    "\n",
    "                # CRITICAL: Check for NaN/Inf in loss\n",
    "                loss_value = loss.item() * accumulation_steps\n",
    "                if not np.isfinite(loss_value):\n",
    "                    logger.error(f\"‚ùå Non-finite loss detected at batch {i}: {loss_value}\")\n",
    "                    logger.error(\"   This indicates training instability. Skipping batch.\")\n",
    "                    # Reset gradients to prevent corruption\n",
    "                    optimizer.zero_grad()\n",
    "                    continue\n",
    "\n",
    "                running_loss += loss_value\n",
    "                with torch.no_grad():\n",
    "                    _, predicted = outputs.max(1)\n",
    "                    total += labels.size(0)\n",
    "                    correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "                current_loss = running_loss / (i + 1)\n",
    "                pbar.set_postfix({'loss': f\"{current_loss:.4f}\", 'acc': f\"{100*correct/total:.2f}%\"})\n",
    "\n",
    "            train_acc = 100 * correct / total\n",
    "\n",
    "            # CRITICAL: Epoch-level health check\n",
    "            if total == 0:\n",
    "                logger.error(f\"‚ùå Epoch {epoch+1}: No samples processed! This indicates a critical data loading issue.\")\n",
    "                break\n",
    "\n",
    "            avg_train_loss = running_loss / len(train_loader) if len(train_loader) > 0 else float('inf')\n",
    "            if not np.isfinite(avg_train_loss):\n",
    "                logger.error(f\"‚ùå Epoch {epoch+1}: Non-finite training loss: {avg_train_loss}\")\n",
    "                logger.error(\"   Training has become unstable. Stopping.\")\n",
    "                break\n",
    "\n",
    "            # INDUSTRIAL-GRADE: Comprehensive validation with per-class metrics\n",
    "            model.eval()\n",
    "            val_loss = 0.0\n",
    "            val_correct = 0\n",
    "            val_total = 0\n",
    "            all_preds = []\n",
    "            all_labels = []\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for val_i, (images, labels) in enumerate(tqdm(val_loader, desc=\"Validation\", leave=False)):\n",
    "                    try:\n",
    "                        # Validate batch shape\n",
    "                        expected_size = config.get('data', {}).get('input_size', 224)\n",
    "                        if images.shape[1] != 3 or images.shape[2] != expected_size or images.shape[3] != expected_size:\n",
    "                            logger.warning(\n",
    "                                f\"‚ö†Ô∏è  Validation batch {val_i} has invalid shape: {images.shape}. Skipping.\"\n",
    "                            )\n",
    "                            continue\n",
    "\n",
    "                        use_non_blocking = (device.type == \"cuda\")\n",
    "                        images, labels = images.to(device, non_blocking=use_non_blocking), labels.to(device, non_blocking=use_non_blocking)\n",
    "\n",
    "                        if use_amp:\n",
    "                            with torch.cuda.amp.autocast():\n",
    "                                outputs = model(images)\n",
    "                                loss = criterion(outputs, labels)\n",
    "                        else:\n",
    "                            outputs = model(images)\n",
    "                            loss = criterion(outputs, labels)\n",
    "\n",
    "                        loss_val = loss.item()\n",
    "                        if not np.isfinite(loss_val):\n",
    "                            logger.warning(f\"‚ö†Ô∏è  Non-finite validation loss at batch {val_i}: {loss_val}. Skipping.\")\n",
    "                            continue\n",
    "\n",
    "                        val_loss += loss_val\n",
    "                        _, predicted = outputs.max(1)\n",
    "                        val_total += labels.size(0)\n",
    "                        val_correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "                        # Collect for per-class metrics\n",
    "                        all_preds.extend(predicted.cpu().numpy())\n",
    "                        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "                    except Exception as e:\n",
    "                        logger.warning(f\"‚ö†Ô∏è  Validation batch {val_i} failed: {e}. Skipping.\")\n",
    "                        continue\n",
    "\n",
    "            # CRITICAL: Validation health check\n",
    "            if val_total == 0:\n",
    "                logger.error(f\"‚ùå Epoch {epoch+1}: No validation samples processed!\")\n",
    "                logger.error(\"   This indicates a critical issue with validation data.\")\n",
    "                break\n",
    "\n",
    "            val_acc = 100 * val_correct / val_total\n",
    "            val_loss /= len(val_loader)\n",
    "\n",
    "            if not np.isfinite(val_loss):\n",
    "                logger.error(f\"‚ùå Epoch {epoch+1}: Non-finite validation loss: {val_loss}\")\n",
    "                logger.error(\"   Validation has become unstable. Stopping.\")\n",
    "                break\n",
    "\n",
    "            # INDUSTRIAL-GRADE: Per-class metrics\n",
    "            if len(all_preds) == 0 or len(all_labels) == 0:\n",
    "                logger.error(f\"‚ùå Epoch {epoch+1}: No predictions collected for metrics!\")\n",
    "                break\n",
    "\n",
    "            precision, recall, f1, support = precision_recall_fscore_support(\n",
    "                all_labels, all_preds, average=None, zero_division=0\n",
    "            )\n",
    "            macro_f1 = f1.mean()\n",
    "\n",
    "            # Find worst performing classes\n",
    "            worst_classes_idx = np.argsort(f1)[:5]\n",
    "            logger.info(f\"üìä Per-Class Performance:\")\n",
    "            logger.info(f\"  Macro F1: {macro_f1:.4f}\")\n",
    "            logger.info(f\"  Worst 5 classes:\")\n",
    "            for idx in worst_classes_idx:\n",
    "                if idx < len(TARGET_CLASSES):\n",
    "                    logger.info(f\"    {TARGET_CLASSES[idx]}: F1={f1[idx]:.4f}, Support={support[idx]}\")\n",
    "\n",
    "            logger.info(f\"Epoch {epoch+1}/{config['training']['num_epochs']}: Train Acc {train_acc:.2f}%, Val Loss {val_loss:.4f}, Val Acc {val_acc:.2f}%, Macro F1 {macro_f1:.4f}\")\n",
    "\n",
    "            # INDUSTRIAL-GRADE: Track metrics history\n",
    "            metrics_history[\"train_acc\"].append(train_acc)\n",
    "            metrics_history[\"val_acc\"].append(val_acc)\n",
    "            metrics_history[\"val_loss\"].append(val_loss)\n",
    "            metrics_history[\"per_class_f1\"].append(macro_f1)\n",
    "            metrics_history[\"learning_rate\"].append(optimizer.param_groups[0]['lr'])\n",
    "\n",
    "            try:\n",
    "                wandb.log({\n",
    "                    \"epoch\": epoch + 1,\n",
    "                    \"train_acc\": train_acc,\n",
    "                    \"val_acc\": val_acc,\n",
    "                    \"val_loss\": val_loss,\n",
    "                    \"macro_f1\": macro_f1,\n",
    "                    \"learning_rate\": optimizer.param_groups[0]['lr'],\n",
    "                    \"worst_class_f1\": f1[worst_classes_idx[0]] if len(worst_classes_idx) > 0 else 0\n",
    "                })\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            # INDUSTRIAL-GRADE: Save best model checkpoint\n",
    "            if val_acc > best_val_acc:\n",
    "                best_val_acc = val_acc\n",
    "                best_model_state = {\n",
    "                    'epoch': epoch + 1,\n",
    "                    'model_state_dict': model.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'scheduler_state_dict': scheduler.state_dict(),\n",
    "                    'val_acc': val_acc,\n",
    "                    'val_loss': val_loss,\n",
    "                    'macro_f1': macro_f1,\n",
    "                    'config': config,\n",
    "                    'metrics_history': metrics_history\n",
    "                }\n",
    "                checkpoint_path = checkpoint_dir / f\"best_model_epoch{epoch+1}_acc{val_acc:.2f}.pth\"\n",
    "                torch.save(best_model_state, checkpoint_path)\n",
    "                logger.info(f\"‚úì Saved best model checkpoint: {checkpoint_path}\")\n",
    "\n",
    "                # Keep only best checkpoint, delete others\n",
    "                for old_ckpt in checkpoint_dir.glob(\"best_model_*.pth\"):\n",
    "                    if old_ckpt != checkpoint_path:\n",
    "                        old_ckpt.unlink()\n",
    "\n",
    "            if early_stopping(val_acc):\n",
    "                logger.info(\"Early stopping triggered\")\n",
    "                break\n",
    "\n",
    "            # Clear cache after each epoch to prevent memory fragmentation\n",
    "            if device.type == \"cuda\":\n",
    "                torch.cuda.empty_cache()\n",
    "            elif device.type == \"mps\":\n",
    "                try:\n",
    "                    torch.mps.empty_cache()\n",
    "                except AttributeError:\n",
    "                    pass  # MPS empty_cache not available in older PyTorch\n",
    "\n",
    "        # INDUSTRIAL-GRADE: Training completed - generate final report\n",
    "        logger.info(\"=\"*60)\n",
    "        logger.info(\"‚úì Training completed successfully\")\n",
    "        logger.info(f\"üìä Final Results:\")\n",
    "        logger.info(f\"  Best Val Accuracy: {best_val_acc:.2f}%\")\n",
    "        logger.info(f\"  Total Epochs: {epoch + 1}\")\n",
    "        logger.info(f\"  Best Checkpoint: {checkpoint_path if best_model_state else 'None'}\")\n",
    "        logger.info(\"=\"*60)\n",
    "\n",
    "        # INDUSTRIAL-GRADE: Generate confusion matrix for best model\n",
    "        if best_model_state:\n",
    "            logger.info(\"Generating confusion matrix for best model...\")\n",
    "            model.load_state_dict(best_model_state['model_state_dict'])\n",
    "            model.eval()\n",
    "\n",
    "            all_preds = []\n",
    "            all_labels = []\n",
    "            with torch.no_grad():\n",
    "                for images, labels in tqdm(val_loader, desc=\"Final Evaluation\"):\n",
    "                    images = images.to(device)\n",
    "                    outputs = model(images)\n",
    "                    _, predicted = outputs.max(1)\n",
    "                    all_preds.extend(predicted.cpu().numpy())\n",
    "                    all_labels.extend(labels.numpy())\n",
    "\n",
    "            # Save confusion matrix\n",
    "            cm = confusion_matrix(all_labels, all_preds)\n",
    "            np.save(checkpoint_dir / \"confusion_matrix.npy\", cm)\n",
    "\n",
    "            # Save classification report\n",
    "            # CRITICAL FIX: Only use labels that are actually present in the data\n",
    "            unique_labels = sorted(list(set(all_labels + all_preds)))\n",
    "            labels_subset = [i for i in range(len(TARGET_CLASSES)) if i in unique_labels]\n",
    "            target_names_subset = [TARGET_CLASSES[i] for i in labels_subset]\n",
    "\n",
    "            report = classification_report(\n",
    "                all_labels, all_preds,\n",
    "                labels=labels_subset,\n",
    "                target_names=target_names_subset,\n",
    "                output_dict=True,\n",
    "                zero_division=0\n",
    "            )\n",
    "            with open(checkpoint_dir / \"classification_report.json\", \"w\") as f:\n",
    "                json.dump(report, f, indent=2)\n",
    "\n",
    "            logger.info(f\"‚úì Saved confusion matrix and classification report to {checkpoint_dir}\")\n",
    "            logger.info(f\"  Classes present in validation: {len(unique_labels)}/{len(TARGET_CLASSES)}\")\n",
    "\n",
    "        # INDUSTRIAL-GRADE: Save final metrics\n",
    "        with open(checkpoint_dir / \"metrics_history.json\", \"w\") as f:\n",
    "            json.dump(metrics_history, f, indent=2)\n",
    "\n",
    "        logger.info(\"‚úì All artifacts saved successfully\")\n",
    "\n",
    "    except RuntimeError as e:\n",
    "        if \"out of memory\" in str(e) or \"MPS\" in str(e):\n",
    "            logger.error(f\"OOM Error: {e}\")\n",
    "            logger.error(\"Suggestions:\")\n",
    "            logger.error(\"  1. Reduce batch_size further (try batch_size=1)\")\n",
    "            logger.error(\"  2. Reduce input_size (try 128 or 192)\")\n",
    "            logger.error(\"  3. Use a smaller model backbone (e.g., resnet50)\")\n",
    "            if device.type == \"cuda\":\n",
    "                torch.cuda.empty_cache()\n",
    "            elif device.type == \"mps\":\n",
    "                try:\n",
    "                    torch.mps.empty_cache()\n",
    "                except AttributeError:\n",
    "                    pass\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Training failed with error: {e}\")\n",
    "        raise\n",
    "    finally:\n",
    "        # Cleanup\n",
    "        try:\n",
    "            wandb.finish()\n",
    "        except:\n",
    "            pass\n",
    "        if device.type == \"cuda\":\n",
    "            torch.cuda.empty_cache()\n",
    "        elif device.type == \"mps\":\n",
    "            try:\n",
    "                torch.mps.empty_cache()\n",
    "            except AttributeError:\n",
    "                pass\n",
    "\n",
    "    return model\n"
   ],
   "id": "35e0483892870ce3",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-11T06:14:55.778183Z",
     "start_time": "2026-02-11T06:14:55.775402Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# INDUSTRIAL-GRADE: Test-Time Augmentation for Inference\n",
    "def predict_with_tta(model, image, device, num_augmentations=5):\n",
    "    \"\"\"\n",
    "    Test-Time Augmentation for robust predictions.\n",
    "    Applies multiple augmentations and averages predictions.\n",
    "\n",
    "    Args:\n",
    "        model: Trained model\n",
    "        image: PIL Image or tensor\n",
    "        device: torch device\n",
    "        num_augmentations: Number of TTA iterations\n",
    "\n",
    "    Returns:\n",
    "        Averaged predictions (logits)\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    # TTA transforms\n",
    "    tta_transforms = [\n",
    "        transforms.Compose([\n",
    "            transforms.RandomHorizontalFlip(p=0.5),\n",
    "            transforms.RandomRotation(degrees=15),\n",
    "            transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        for _ in range(num_augmentations)\n",
    "    ]\n",
    "\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for transform in tta_transforms:\n",
    "            if isinstance(image, torch.Tensor):\n",
    "                img_tensor = image\n",
    "            else:\n",
    "                img_tensor = transform(image).unsqueeze(0).to(device)\n",
    "\n",
    "            output = model(img_tensor)\n",
    "            predictions.append(output)\n",
    "\n",
    "    # Average predictions\n",
    "    avg_prediction = torch.stack(predictions).mean(dim=0)\n",
    "    return avg_prediction\n"
   ],
   "id": "dd26b5c26bdf32d2",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-11T06:14:55.784514Z",
     "start_time": "2026-02-11T06:14:55.780725Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# INDUSTRIAL-GRADE: Model Export for Production\n",
    "def export_model_for_production(model, config, checkpoint_path, export_dir=\"exports\"):\n",
    "    \"\"\"\n",
    "    Export model to multiple formats for production deployment.\n",
    "\n",
    "    Exports:\n",
    "    - PyTorch (.pth) - for PyTorch inference\n",
    "    - TorchScript (.pt) - for C++ deployment\n",
    "    - ONNX (.onnx) - for cross-platform deployment\n",
    "    \"\"\"\n",
    "    export_dir = Path(export_dir)\n",
    "    export_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    model.eval()\n",
    "    device = next(model.parameters()).device\n",
    "\n",
    "    # 1. Save PyTorch model\n",
    "    torch.save({\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'config': config,\n",
    "        'target_classes': TARGET_CLASSES\n",
    "    }, export_dir / \"model.pth\")\n",
    "    logger.info(f\"‚úì Exported PyTorch model to {export_dir / 'model.pth'}\")\n",
    "\n",
    "    # 2. Export to TorchScript\n",
    "    try:\n",
    "        dummy_input = torch.randn(1, 3, config['data']['input_size'], config['data']['input_size']).to(device)\n",
    "        traced_model = torch.jit.trace(model, dummy_input)\n",
    "        traced_model.save(export_dir / \"model_torchscript.pt\")\n",
    "        logger.info(f\"‚úì Exported TorchScript model to {export_dir / 'model_torchscript.pt'}\")\n",
    "    except Exception as e:\n",
    "        logger.warning(f\"TorchScript export failed: {e}\")\n",
    "\n",
    "    # 3. Export to ONNX\n",
    "    try:\n",
    "        torch.onnx.export(\n",
    "            model,\n",
    "            dummy_input,\n",
    "            export_dir / \"model.onnx\",\n",
    "            export_params=True,\n",
    "            opset_version=14,\n",
    "            do_constant_folding=True,\n",
    "            input_names=['input'],\n",
    "            output_names=['output'],\n",
    "            dynamic_axes={'input': {0: 'batch_size'}, 'output': {0: 'batch_size'}}\n",
    "        )\n",
    "        logger.info(f\"‚úì Exported ONNX model to {export_dir / 'model.onnx'}\")\n",
    "    except Exception as e:\n",
    "        logger.warning(f\"ONNX export failed: {e}\")\n",
    "\n",
    "    # 4. Save metadata\n",
    "    metadata = {\n",
    "        'model_name': config['model']['backbone'],\n",
    "        'num_classes': config['model']['num_classes'],\n",
    "        'input_size': config['data']['input_size'],\n",
    "        'target_classes': TARGET_CLASSES,\n",
    "        'checkpoint_path': str(checkpoint_path)\n",
    "    }\n",
    "    with open(export_dir / \"metadata.json\", \"w\") as f:\n",
    "        json.dump(metadata, f, indent=2)\n",
    "    logger.info(f\"‚úì Saved metadata to {export_dir / 'metadata.json'}\")\n",
    "\n",
    "    logger.info(f\"‚úÖ Model export complete! All files in {export_dir}\")\n"
   ],
   "id": "184a60cacd5ef3a2",
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-11T06:14:55.792839Z",
     "start_time": "2026-02-11T06:14:55.787307Z"
    }
   },
   "source": [
    "# PEAK STANDARD GNN\n",
    "# Using Graph Attention Networks v2 (GATv2) for superior expressive power\n",
    "\n",
    "def generate_structured_knowledge_graph(num_classes=30, feat_dim=128):\n",
    "    \"\"\"\n",
    "    Generates a realistic Knowledge Graph structure for waste classification.\n",
    "    Simulates the schema: Item -> Material -> Bin\n",
    "    \"\"\"\n",
    "    logger.info(\"Generating structured Knowledge Graph...\")\n",
    "    \n",
    "    total_nodes = num_classes + 8 + 4\n",
    "    x = torch.randn(total_nodes, feat_dim) # Node features (embeddings)\n",
    "    \n",
    "    edge_sources = []\n",
    "    edge_targets = []\n",
    "    \n",
    "    # Node Indices for Materials\n",
    "    mat_base = num_classes\n",
    "    mat_plastic = mat_base + 0\n",
    "    mat_paper = mat_base + 1\n",
    "    mat_glass = mat_base + 2\n",
    "    mat_metal = mat_base + 3\n",
    "    mat_organic = mat_base + 4\n",
    "    mat_fabric = mat_base + 5\n",
    "    mat_ewaste = mat_base + 6\n",
    "    mat_misc = mat_base + 7\n",
    "    \n",
    "    # Node Indices for Bins\n",
    "    bin_base = mat_base + 8\n",
    "    bin_recycle = bin_base + 0\n",
    "    bin_compost = bin_base + 1\n",
    "    bin_haz = bin_base + 2\n",
    "    bin_landfill = bin_base + 3\n",
    "    \n",
    "    # 1. Edges: Material -> Bin (Knowledge Rules)\n",
    "    mat_bin_map = [\n",
    "        (mat_plastic, bin_recycle),\n",
    "        (mat_paper, bin_recycle),\n",
    "        (mat_glass, bin_recycle),\n",
    "        (mat_metal, bin_recycle),\n",
    "        (mat_organic, bin_compost),\n",
    "        (mat_fabric, bin_landfill), \n",
    "        (mat_ewaste, bin_haz),\n",
    "        (mat_misc, bin_landfill)\n",
    "    ]\n",
    "    \n",
    "    for m, b in mat_bin_map:\n",
    "        edge_sources.append(m); edge_targets.append(b)\n",
    "        edge_sources.append(b); edge_targets.append(m)\n",
    "        \n",
    "    # 2. Edges: Item -> Material (Simulate Classification Knowledge)\n",
    "    for i in range(num_classes):\n",
    "        mat_idx = mat_base + (i % 8) \n",
    "        edge_sources.append(i); edge_targets.append(mat_idx)\n",
    "        edge_sources.append(mat_idx); edge_targets.append(i)\n",
    "        \n",
    "    # 3. Edges: Item -> Item (Similarity)\n",
    "    for i in range(num_classes):\n",
    "        neighbor = (i + 8) % num_classes\n",
    "        edge_sources.append(i); edge_targets.append(neighbor)\n",
    "        edge_sources.append(neighbor); edge_targets.append(i)\n",
    "\n",
    "    edge_index = torch.tensor([edge_sources, edge_targets], dtype=torch.long)\n",
    "    \n",
    "    logger.info(f\"Graph generated: {total_nodes} nodes, {len(edge_sources)} edges.\")\n",
    "    \n",
    "    return Data(x=x, edge_index=edge_index, num_nodes=total_nodes)\n",
    "\n",
    "class GATv2Model(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers=4, heads=8, dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.convs = nn.ModuleList()\n",
    "        self.convs.append(GATv2Conv(in_channels, hidden_channels, heads=heads, concat=True, dropout=dropout))\n",
    "        for _ in range(num_layers - 2):\n",
    "            self.convs.append(GATv2Conv(hidden_channels * heads, hidden_channels, heads=heads, concat=True, dropout=dropout))\n",
    "        self.convs.append(GATv2Conv(hidden_channels * heads, out_channels, heads=1, concat=False, dropout=dropout))\n",
    "        self.dropout = dropout\n",
    "        self.norm = nn.ModuleList([nn.LayerNorm(hidden_channels * heads) for _ in range(num_layers - 1)])\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        for i, conv in enumerate(self.convs[:-1]):\n",
    "            x = conv(x, edge_index)\n",
    "            x = self.norm[i](x)\n",
    "            x = F.gelu(x)\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        return self.convs[-1](x, edge_index)"
   ],
   "id": "a413b4ee062ae6a8",
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-11T06:14:55.800004Z",
     "start_time": "2026-02-11T06:14:55.795850Z"
    }
   },
   "source": [
    "def train_gnn_model():\n",
    "    set_seed()\n",
    "    device = get_device()\n",
    "    optimize_memory(device)\n",
    "    logger.info(f\"Using device: {device}\")\n",
    "\n",
    "    in_dim = 128\n",
    "    hidden_dim = 512\n",
    "    out_dim = 256\n",
    "    lr = 0.001\n",
    "    epochs = 50\n",
    "\n",
    "    data = generate_structured_knowledge_graph(num_classes=30, feat_dim=128).to(device)\n",
    "\n",
    "    model = GATv2Model(in_dim, hidden_dim, out_dim).to(device)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=5, factor=0.5)\n",
    "\n",
    "    logger.info(\"Starting GNN Training...\")\n",
    "    best_loss = float('inf')\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        z = model(data.x, data.edge_index)\n",
    "\n",
    "        pos_src, pos_dst = data.edge_index\n",
    "        pos_loss = -torch.log(torch.sigmoid((z[pos_src] * z[pos_dst]).sum(dim=1)) + 1e-15).mean()\n",
    "\n",
    "        neg_src = torch.randint(0, data.num_nodes, (pos_src.size(0),), device=device)\n",
    "        neg_dst = torch.randint(0, data.num_nodes, (pos_src.size(0),), device=device)\n",
    "        neg_loss = -torch.log(1 - torch.sigmoid((z[neg_src] * z[neg_dst]).sum(dim=1)) + 1e-15).mean()\n",
    "\n",
    "        loss = pos_loss + neg_loss\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step(loss)\n",
    "\n",
    "        if loss.item() < best_loss:\n",
    "            best_loss = loss.item()\n",
    "\n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            logger.info(f\"Epoch {epoch+1}/{epochs}: Loss {loss.item():.4f}, Best Loss {best_loss:.4f}\")\n",
    "\n",
    "    return model"
   ],
   "id": "d48fee1a1cb8a264",
   "outputs": [],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-11T06:15:01.412549Z",
     "start_time": "2026-02-11T06:14:55.802811Z"
    }
   },
   "source": [
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        logger.info(\"=\"*80)\n",
    "        logger.info(\"Phase 1: Multi-Source Data Lake Vision Training\")\n",
    "        logger.info(\"=\"*80)\n",
    "\n",
    "        # CRITICAL: Starting fresh with improved hyperparameters to fix overfitting\n",
    "        # Previous training: Epochs 1-6 showed severe overfitting (92.64% ‚Üí 78.35%)\n",
    "        # New config: Lower LR (1e-5), higher weight decay (0.1)\n",
    "        # Old checkpoint available at: checkpoints/best_model_epoch1_acc92.64.pth\n",
    "        vision_model = train_vision_model(VISION_CONFIG, resume_from_checkpoint=None)\n",
    "\n",
    "        if vision_model is not None:\n",
    "            save_path = \"best_vision_eva02_lake.pth\"\n",
    "            torch.save(vision_model.state_dict(), save_path)\n",
    "            logger.info(f\"Vision model saved to {save_path}\")\n",
    "\n",
    "            del vision_model\n",
    "            device = get_device()\n",
    "            if device.type == \"cuda\":\n",
    "                torch.cuda.empty_cache()\n",
    "            elif device.type == \"mps\":\n",
    "                try:\n",
    "                    torch.mps.empty_cache()\n",
    "                except AttributeError:\n",
    "                    pass\n",
    "        else:\n",
    "            logger.error(\"Vision model training failed\")\n",
    "\n",
    "        logger.info(\"=\"*80)\n",
    "        logger.info(\"Phase 2: GNN Knowledge Graph Training\")\n",
    "        logger.info(\"=\"*80)\n",
    "\n",
    "        gnn_model = train_gnn_model()\n",
    "\n",
    "        if gnn_model is not None:\n",
    "            save_path = \"best_gnn_gatv2.pth\"\n",
    "            torch.save(gnn_model.state_dict(), save_path)\n",
    "            logger.info(f\"GNN model saved to {save_path}\")\n",
    "\n",
    "            del gnn_model\n",
    "            device = get_device()\n",
    "            if device.type == \"cuda\":\n",
    "                torch.cuda.empty_cache()\n",
    "            elif device.type == \"mps\":\n",
    "                try:\n",
    "                    torch.mps.empty_cache()\n",
    "                except AttributeError:\n",
    "                    pass\n",
    "\n",
    "        logger.info(\"=\"*80)\n",
    "        logger.info(\"Training completed successfully!\")\n",
    "        logger.info(\"=\"*80)\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Training failed with error: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        raise"
   ],
   "id": "78cc46781594be13",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-10 22:14:55,805 - INFO - ================================================================================\n",
      "2026-02-10 22:14:55,805 - INFO - Phase 1: Multi-Source Data Lake Vision Training\n",
      "2026-02-10 22:14:55,806 - INFO - ================================================================================\n",
      "2026-02-10 22:14:55,837 - INFO - ‚úì Random seed set to 42\n",
      "2026-02-10 22:14:55,838 - INFO - üíª Using CPU for maximum stability\n",
      "2026-02-10 22:14:55,838 - INFO -    ‚ö†Ô∏è  MPS disabled due to crashes - will re-enable after NumPy fix\n",
      "2026-02-10 22:14:55,838 - INFO -    Training will be slower but 100% stable\n",
      "2026-02-10 22:14:55,838 - INFO - ‚úì CPU optimization enabled\n",
      "2026-02-10 22:14:55,839 - INFO -   - Using 14 threads\n",
      "2026-02-10 22:14:55,839 - INFO - Using device: cpu\n",
      "2026-02-10 22:14:55,839 - INFO - Creating model: eva02_base_patch14_224\n",
      "2026-02-10 22:14:56,322 - INFO - Loading pretrained weights from Hugging Face hub (timm/eva02_base_patch14_224.mim_in22k)\n",
      "2026-02-10 22:14:56,615 - INFO - [timm/eva02_base_patch14_224.mim_in22k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.\n",
      "2026-02-10 22:14:56,791 - INFO - Missing keys (head.weight, head.bias) discovered while loading pretrained weights. This is expected if model is being adapted.\n",
      "2026-02-10 22:14:56,794 - INFO - Model parameters: 85.78M total, 85.78M trainable\n",
      "2026-02-10 22:14:56,795 - INFO - ‚úì Gradient checkpointing enabled (saves ~40% memory)\n",
      "2026-02-10 22:14:56,795 - INFO - Using transforms with input_size=224, mean=(0.48145466, 0.4578275, 0.40821073), std=(0.26862954, 0.26130258, 0.27577711)\n",
      "2026-02-10 22:14:56,795 - INFO - Using transforms with input_size=224, mean=(0.48145466, 0.4578275, 0.40821073), std=(0.26862954, 0.26130258, 0.27577711)\n",
      "2026-02-10 22:14:56,795 - INFO - üîç Validating transform pipeline...\n",
      "2026-02-10 22:14:56,799 - WARNING - ‚ö†Ô∏è  NumPy compatibility issue detected: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:14:56,800 - WARNING -   Skipping transform validation (will validate with real data)\n",
      "2026-02-10 22:14:56,800 - WARNING -   Consider upgrading: pip install 'numpy<2.0'\n",
      "2026-02-10 22:14:56,800 - INFO - üìÇ Ingesting master_30 from data/kaggle/recyclable-and-household-waste-classification/images...\n",
      "2026-02-10 22:14:56,850 - INFO - ‚úì master_30: Added 0 images, skipped 15000\n",
      "2026-02-10 22:14:56,850 - INFO - üìÇ Ingesting garbage_12 from data/kaggle/garbage-classification-mostafa/garbage_classification...\n",
      "2026-02-10 22:14:56,929 - INFO - ‚úì garbage_12: Added 14570 images, skipped 945\n",
      "2026-02-10 22:14:56,930 - INFO - üìÇ Ingesting waste_22k from data/kaggle/waste-classification-data/DATASET...\n",
      "2026-02-10 22:14:57,353 - INFO - ‚úì waste_22k: Added 50154 images, skipped 0\n",
      "2026-02-10 22:14:57,362 - INFO - üìÇ Ingesting garbage_v2_10 from data/kaggle/garbage-classification-v2...\n",
      "2026-02-10 22:14:57,483 - INFO - ‚úì garbage_v2_10: Added 20212 images, skipped 0\n",
      "2026-02-10 22:14:57,483 - INFO - üìÇ Ingesting garbage_6 from data/kaggle/garbage-classification...\n",
      "2026-02-10 22:14:57,500 - INFO - ‚úì garbage_6: Added 2527 images, skipped 0\n",
      "2026-02-10 22:14:57,500 - INFO - üìÇ Ingesting garbage_balanced from data/kaggle/garbage-dataset-classification...\n",
      "2026-02-10 22:14:57,585 - INFO - ‚úì garbage_balanced: Added 13901 images, skipped 0\n",
      "2026-02-10 22:14:57,586 - INFO - üìÇ Ingesting warp_industrial from data/kaggle/warp-waste-recycling-plant-dataset...\n",
      "2026-02-10 22:14:57,698 - INFO - ‚úì warp_industrial: Added 0 images, skipped 13910\n",
      "2026-02-10 22:14:57,698 - INFO - üìÇ Ingesting multiclass_garbage from data/kaggle/multi-class-garbage-classification-dataset...\n",
      "2026-02-10 22:14:57,717 - INFO - ‚úì multiclass_garbage: Added 2574 images, skipped 177\n",
      "2026-02-10 22:14:57,717 - INFO - ============================================================\n",
      "2026-02-10 22:14:57,718 - INFO - üìä Dataset Summary:\n",
      "2026-02-10 22:14:57,718 - INFO -   ‚úì Total images loaded: 103938\n",
      "2026-02-10 22:14:57,718 - INFO -   ‚úì Images added: 103938\n",
      "2026-02-10 22:14:57,718 - INFO -   ‚ö† Images skipped: 30032\n",
      "2026-02-10 22:14:57,718 - INFO -   üìà Utilization: 77.6%\n",
      "2026-02-10 22:14:57,719 - INFO - ============================================================\n",
      "2026-02-10 22:14:57,719 - WARNING - ‚ö† Top 10 skipped labels:\n",
      "2026-02-10 22:14:57,719 - WARNING -   'real_world': 7500 images\n",
      "2026-02-10 22:14:57,719 - WARNING -   'default': 7500 images\n",
      "2026-02-10 22:14:57,719 - WARNING -   'images': 2974 images\n",
      "2026-02-10 22:14:57,719 - WARNING -   'bottle-transp': 1674 images\n",
      "2026-02-10 22:14:57,720 - WARNING -   'battery': 945 images\n",
      "2026-02-10 22:14:57,720 - WARNING -   'bottle-blue': 746 images\n",
      "2026-02-10 22:14:57,720 - WARNING -   'cans': 668 images\n",
      "2026-02-10 22:14:57,720 - WARNING -   'bottle-dark': 636 images\n",
      "2026-02-10 22:14:57,721 - WARNING -   'bottle-transp-full': 628 images\n",
      "2026-02-10 22:14:57,721 - WARNING -   'bottle-green': 548 images\n",
      "2026-02-10 22:14:57,721 - INFO - üîç Validating dataset samples...\n",
      "2026-02-10 22:14:57,739 - INFO -   ‚úÖ All 1000 checked samples exist on disk\n",
      "2026-02-10 22:14:57,742 - INFO - ‚ÑπÔ∏è  CPU detected: AMP disabled (not supported on CPU)\n",
      "2026-02-10 22:14:57,742 - INFO - Training configuration:\n",
      "2026-02-10 22:14:57,742 - INFO -   - Batch size: 8\n",
      "2026-02-10 22:14:57,742 - INFO -   - Gradient accumulation: 8\n",
      "2026-02-10 22:14:57,743 - INFO -   - Effective batch size: 64\n",
      "2026-02-10 22:14:57,743 - INFO -   - Mixed precision (AMP): False\n",
      "2026-02-10 22:14:57,743 - INFO -   - Gradient clipping: 1.0\n",
      "2026-02-10 22:14:57,743 - INFO -   - Learning rate: 2e-05\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: [wandb.login()] Loaded credentials for https://api.wandb.ai from /Users/jiangshengbo/.netrc.\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mjiangmicheal324\u001B[0m (\u001B[33mjiangmicheal324-kehillah-jewish-high-school\u001B[0m) to \u001B[32mhttps://api.wandb.ai\u001B[0m. Use \u001B[1m`wandb login --relogin`\u001B[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": "db5c2c54184a2bd878602c673e8b5933"
     }
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.24.2"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>/Users/jiangshengbo/Desktop/Sustainability-AI-Model/wandb/run-20260210_221459-vg45mz0c</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/jiangmicheal324-kehillah-jewish-high-school/sustainability-vision-lake/runs/vg45mz0c' target=\"_blank\">valiant-donkey-22</a></strong> to <a href='https://wandb.ai/jiangmicheal324-kehillah-jewish-high-school/sustainability-vision-lake' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/jiangmicheal324-kehillah-jewish-high-school/sustainability-vision-lake' target=\"_blank\">https://wandb.ai/jiangmicheal324-kehillah-jewish-high-school/sustainability-vision-lake</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/jiangmicheal324-kehillah-jewish-high-school/sustainability-vision-lake/runs/vg45mz0c' target=\"_blank\">https://wandb.ai/jiangmicheal324-kehillah-jewish-high-school/sustainability-vision-lake/runs/vg45mz0c</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-10 22:15:00,418 - INFO - ‚úì W&B logging enabled\n",
      "2026-02-10 22:15:00,418 - INFO - üîç Running pre-training sanity check...\n",
      "2026-02-10 22:15:00,441 - ERROR - ‚ùå Transform failed for data/kaggle/garbage-classification-v2/glass/glass_1376.jpg: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:00,441 - ERROR - ‚ùå FAILED TO LOAD IMAGE 77849: data/kaggle/garbage-classification-v2/glass/glass_1376.jpg\n",
      "2026-02-10 22:15:00,442 - ERROR -    Error: TypeError: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:00,444 - ERROR - ‚ùå Transform failed for data/kaggle/waste-classification-data/DATASET/DATASET/TRAIN/O/O_3231.jpg: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:00,444 - ERROR - ‚ùå FAILED TO LOAD IMAGE 30014: data/kaggle/waste-classification-data/DATASET/DATASET/TRAIN/O/O_3231.jpg\n",
      "2026-02-10 22:15:00,445 - ERROR -    Error: TypeError: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:00,447 - ERROR - ‚ùå Transform failed for data/kaggle/waste-classification-data/DATASET/DATASET/TRAIN/O/O_5231.jpg: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:00,447 - ERROR - ‚ùå FAILED TO LOAD IMAGE 33734: data/kaggle/waste-classification-data/DATASET/DATASET/TRAIN/O/O_5231.jpg\n",
      "2026-02-10 22:15:00,448 - ERROR -    Error: TypeError: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:00,452 - ERROR - ‚ùå Transform failed for data/kaggle/garbage-classification-mostafa/garbage_classification/clothes/clothes3726.jpg: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:00,452 - ERROR - ‚ùå FAILED TO LOAD IMAGE 1970: data/kaggle/garbage-classification-mostafa/garbage_classification/clothes/clothes3726.jpg\n",
      "2026-02-10 22:15:00,453 - ERROR -    Error: TypeError: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:00,456 - ERROR - ‚ùå Transform failed for data/kaggle/garbage-classification-v2/glass/glass_761.jpg: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:00,456 - ERROR - ‚ùå FAILED TO LOAD IMAGE 78554: data/kaggle/garbage-classification-v2/glass/glass_761.jpg\n",
      "2026-02-10 22:15:00,456 - ERROR -    Error: TypeError: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:00,459 - ERROR - ‚ùå Transform failed for data/kaggle/waste-classification-data/DATASET/TRAIN/R/R_4057.jpg: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:00,459 - ERROR - ‚ùå FAILED TO LOAD IMAGE 43924: data/kaggle/waste-classification-data/DATASET/TRAIN/R/R_4057.jpg\n",
      "2026-02-10 22:15:00,460 - ERROR -    Error: TypeError: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:00,462 - ERROR - ‚ùå Transform failed for data/kaggle/garbage-dataset-classification/Garbage_Dataset_Classification/images/glass/glass_00588.jpg: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:00,462 - ERROR - ‚ùå FAILED TO LOAD IMAGE 97415: data/kaggle/garbage-dataset-classification/Garbage_Dataset_Classification/images/glass/glass_00588.jpg\n",
      "2026-02-10 22:15:00,463 - ERROR -    Error: TypeError: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:00,470 - ERROR - ‚ùå Transform failed for data/kaggle/garbage-classification-mostafa/garbage_classification/clothes/clothes4788.jpg: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:00,470 - ERROR - ‚ùå FAILED TO LOAD IMAGE 3654: data/kaggle/garbage-classification-mostafa/garbage_classification/clothes/clothes4788.jpg\n",
      "2026-02-10 22:15:00,471 - ERROR -    Error: TypeError: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:00,473 - INFO -   Batch shape: torch.Size([8, 3, 224, 224])\n",
      "2026-02-10 22:15:00,474 - INFO -   Expected: [batch_size, 3, 224, 224]\n",
      "2026-02-10 22:15:00,733 - INFO -   Model output shape: torch.Size([8, 30])\n",
      "2026-02-10 22:15:00,734 - INFO -   Expected: [batch_size, 30]\n",
      "2026-02-10 22:15:00,734 - INFO -   ‚úÖ Pre-training sanity check passed!\n",
      "2026-02-10 22:15:00,735 - INFO -   ‚úÖ All images are 224x224\n",
      "2026-02-10 22:15:00,735 - INFO -   ‚úÖ Model accepts input and produces correct output shape\n",
      "2026-02-10 22:15:00,735 - INFO - ================================================================================\n",
      "2026-02-10 22:15:00,736 - INFO - üî¨ COMPREHENSIVE DATA QUALITY VALIDATION\n",
      "2026-02-10 22:15:00,737 - INFO - ================================================================================\n",
      "2026-02-10 22:15:00,737 - INFO - Test 1: Individual Image Loading (100 random samples)...\n",
      "2026-02-10 22:15:00,751 - ERROR - ‚ùå Transform failed for data/kaggle/garbage-classification-v2/cardboard/202512-cardboard122.jpg: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:00,752 - ERROR - ‚ùå FAILED TO LOAD IMAGE 73999: data/kaggle/garbage-classification-v2/cardboard/202512-cardboard122.jpg\n",
      "2026-02-10 22:15:00,752 - ERROR -    Error: TypeError: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:00,757 - ERROR - ‚ùå Transform failed for data/kaggle/waste-classification-data/DATASET/DATASET/TRAIN/R/R_7764.jpg: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:00,757 - ERROR - ‚ùå FAILED TO LOAD IMAGE 20253: data/kaggle/waste-classification-data/DATASET/DATASET/TRAIN/R/R_7764.jpg\n",
      "2026-02-10 22:15:00,758 - ERROR -    Error: TypeError: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:00,761 - ERROR - ‚ùå Transform failed for data/kaggle/waste-classification-data/DATASET/TEST/O/O_12698.jpg: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:00,761 - ERROR - ‚ùå FAILED TO LOAD IMAGE 16002: data/kaggle/waste-classification-data/DATASET/TEST/O/O_12698.jpg\n",
      "2026-02-10 22:15:00,761 - ERROR -    Error: TypeError: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:00,765 - ERROR - ‚ùå Transform failed for data/kaggle/garbage-classification-v2/cardboard/cardboard_2057.jpg: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:00,765 - ERROR - ‚ùå FAILED TO LOAD IMAGE 74671: data/kaggle/garbage-classification-v2/cardboard/cardboard_2057.jpg\n",
      "2026-02-10 22:15:00,766 - ERROR -    Error: TypeError: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:00,768 - ERROR - ‚ùå Transform failed for data/kaggle/waste-classification-data/DATASET/DATASET/TRAIN/O/O_6137.jpg: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:00,769 - ERROR - ‚ùå FAILED TO LOAD IMAGE 36932: data/kaggle/waste-classification-data/DATASET/DATASET/TRAIN/O/O_6137.jpg\n",
      "2026-02-10 22:15:00,769 - ERROR -    Error: TypeError: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:00,787 - ERROR - ‚ùå Transform failed for data/kaggle/garbage-classification-v2/glass/glass_4531.jpg: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:00,788 - ERROR - ‚ùå FAILED TO LOAD IMAGE 78238: data/kaggle/garbage-classification-v2/glass/glass_4531.jpg\n",
      "2026-02-10 22:15:00,788 - ERROR -    Error: TypeError: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:00,795 - ERROR - ‚ùå Transform failed for data/kaggle/garbage-classification-v2/plastic/plastic_1925.jpg: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:00,799 - ERROR - ‚ùå FAILED TO LOAD IMAGE 82141: data/kaggle/garbage-classification-v2/plastic/plastic_1925.jpg\n",
      "2026-02-10 22:15:00,799 - ERROR -    Error: TypeError: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:00,802 - ERROR - ‚ùå Transform failed for data/kaggle/waste-classification-data/DATASET/TRAIN/O/O_9584.jpg: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:00,803 - ERROR - ‚ùå FAILED TO LOAD IMAGE 57439: data/kaggle/waste-classification-data/DATASET/TRAIN/O/O_9584.jpg\n",
      "2026-02-10 22:15:00,803 - ERROR -    Error: TypeError: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:00,806 - ERROR - ‚ùå Transform failed for data/kaggle/multi-class-garbage-classification-dataset/Multi class garbage classification/train/paper/paper381.jpg: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:00,807 - ERROR - ‚ùå FAILED TO LOAD IMAGE 101786: data/kaggle/multi-class-garbage-classification-dataset/Multi class garbage classification/train/paper/paper381.jpg\n",
      "2026-02-10 22:15:00,807 - ERROR -    Error: TypeError: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:00,810 - ERROR - ‚ùå Transform failed for data/kaggle/garbage-classification-v2/glass/glass_3209.jpg: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:00,811 - ERROR - ‚ùå FAILED TO LOAD IMAGE 76585: data/kaggle/garbage-classification-v2/glass/glass_3209.jpg\n",
      "2026-02-10 22:15:00,811 - ERROR -    Error: TypeError: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:00,814 - ERROR - ‚ùå Transform failed for data/kaggle/waste-classification-data/DATASET/DATASET/TRAIN/O/O_4143.jpg: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:00,814 - ERROR - ‚ùå FAILED TO LOAD IMAGE 41572: data/kaggle/waste-classification-data/DATASET/DATASET/TRAIN/O/O_4143.jpg\n",
      "2026-02-10 22:15:00,815 - ERROR -    Error: TypeError: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:00,819 - ERROR - ‚ùå Transform failed for data/kaggle/waste-classification-data/DATASET/TEST/O/O_12849.jpg: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:00,819 - ERROR - ‚ùå FAILED TO LOAD IMAGE 17054: data/kaggle/waste-classification-data/DATASET/TEST/O/O_12849.jpg\n",
      "2026-02-10 22:15:00,819 - ERROR -    Error: TypeError: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:00,822 - ERROR - ‚ùå Transform failed for data/kaggle/waste-classification-data/DATASET/DATASET/TRAIN/O/O_8679.jpg: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:00,823 - ERROR - ‚ùå FAILED TO LOAD IMAGE 37733: data/kaggle/waste-classification-data/DATASET/DATASET/TRAIN/O/O_8679.jpg\n",
      "2026-02-10 22:15:00,823 - ERROR -    Error: TypeError: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:00,826 - ERROR - ‚ùå Transform failed for data/kaggle/garbage-dataset-classification/Garbage_Dataset_Classification/images/glass/glass_03512.jpg: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:00,828 - ERROR - ‚ùå FAILED TO LOAD IMAGE 98069: data/kaggle/garbage-dataset-classification/Garbage_Dataset_Classification/images/glass/glass_03512.jpg\n",
      "2026-02-10 22:15:00,830 - ERROR -    Error: TypeError: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:00,834 - ERROR - ‚ùå Transform failed for data/kaggle/garbage-dataset-classification/Garbage_Dataset_Classification/images/paper/paper_00025.jpg: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:00,835 - ERROR - ‚ùå FAILED TO LOAD IMAGE 89113: data/kaggle/garbage-dataset-classification/Garbage_Dataset_Classification/images/paper/paper_00025.jpg\n",
      "2026-02-10 22:15:00,835 - ERROR -    Error: TypeError: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:00,838 - ERROR - ‚ùå Transform failed for data/kaggle/garbage-dataset-classification/Garbage_Dataset_Classification/images/paper/paper_00684.jpg: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:00,839 - ERROR - ‚ùå FAILED TO LOAD IMAGE 89340: data/kaggle/garbage-dataset-classification/Garbage_Dataset_Classification/images/paper/paper_00684.jpg\n",
      "2026-02-10 22:15:00,839 - ERROR -    Error: TypeError: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:00,842 - ERROR - ‚ùå Transform failed for data/kaggle/waste-classification-data/DATASET/DATASET/TRAIN/O/O_10942.jpg: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:00,842 - ERROR - ‚ùå FAILED TO LOAD IMAGE 33024: data/kaggle/waste-classification-data/DATASET/DATASET/TRAIN/O/O_10942.jpg\n",
      "2026-02-10 22:15:00,843 - ERROR -    Error: TypeError: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:00,846 - ERROR - ‚ùå Transform failed for data/kaggle/multi-class-garbage-classification-dataset/Multi class garbage classification/train/glass/glass55.jpg: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:00,846 - ERROR - ‚ùå FAILED TO LOAD IMAGE 103333: data/kaggle/multi-class-garbage-classification-dataset/Multi class garbage classification/train/glass/glass55.jpg\n",
      "2026-02-10 22:15:00,846 - ERROR -    Error: TypeError: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:00,850 - ERROR - ‚ùå Transform failed for data/kaggle/waste-classification-data/DATASET/TRAIN/R/R_4683.jpg: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:00,851 - ERROR - ‚ùå FAILED TO LOAD IMAGE 43178: data/kaggle/waste-classification-data/DATASET/TRAIN/R/R_4683.jpg\n",
      "2026-02-10 22:15:00,851 - ERROR -    Error: TypeError: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:00,871 - ERROR - ‚ùå Transform failed for data/kaggle/garbage-classification-v2/plastic/plastic_363.jpg: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:00,872 - ERROR - ‚ùå FAILED TO LOAD IMAGE 82497: data/kaggle/garbage-classification-v2/plastic/plastic_363.jpg\n",
      "2026-02-10 22:15:00,872 - ERROR -    Error: TypeError: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:00,875 - ERROR - ‚ùå Transform failed for data/kaggle/waste-classification-data/DATASET/DATASET/TRAIN/R/R_2150.jpg: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:00,876 - ERROR - ‚ùå FAILED TO LOAD IMAGE 20195: data/kaggle/waste-classification-data/DATASET/DATASET/TRAIN/R/R_2150.jpg\n",
      "2026-02-10 22:15:00,876 - ERROR -    Error: TypeError: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:00,882 - ERROR - ‚ùå Transform failed for data/kaggle/garbage-dataset-classification/Garbage_Dataset_Classification/images/cardboard/cardboard_02415.jpg: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:00,883 - ERROR - ‚ùå FAILED TO LOAD IMAGE 92241: data/kaggle/garbage-dataset-classification/Garbage_Dataset_Classification/images/cardboard/cardboard_02415.jpg\n",
      "2026-02-10 22:15:00,883 - ERROR -    Error: TypeError: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:00,886 - ERROR - ‚ùå Transform failed for data/kaggle/waste-classification-data/DATASET/DATASET/TRAIN/R/R_1263.jpg: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:00,886 - ERROR - ‚ùå FAILED TO LOAD IMAGE 19988: data/kaggle/waste-classification-data/DATASET/DATASET/TRAIN/R/R_1263.jpg\n",
      "2026-02-10 22:15:00,887 - ERROR -    Error: TypeError: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:00,889 - ERROR - ‚ùå Transform failed for data/kaggle/waste-classification-data/DATASET/DATASET/TRAIN/R/R_3744.jpg: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:00,890 - ERROR - ‚ùå FAILED TO LOAD IMAGE 26573: data/kaggle/waste-classification-data/DATASET/DATASET/TRAIN/R/R_3744.jpg\n",
      "2026-02-10 22:15:00,890 - ERROR -    Error: TypeError: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:00,897 - ERROR - ‚ùå Transform failed for data/kaggle/garbage-classification-v2/metal/metal_2532.jpg: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:00,897 - ERROR - ‚ùå FAILED TO LOAD IMAGE 72328: data/kaggle/garbage-classification-v2/metal/metal_2532.jpg\n",
      "2026-02-10 22:15:00,898 - ERROR -    Error: TypeError: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:00,901 - ERROR - ‚ùå Transform failed for data/kaggle/garbage-classification-mostafa/garbage_classification/clothes/clothes1176.jpg: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:00,902 - ERROR - ‚ùå FAILED TO LOAD IMAGE 5623: data/kaggle/garbage-classification-mostafa/garbage_classification/clothes/clothes1176.jpg\n",
      "2026-02-10 22:15:00,902 - ERROR -    Error: TypeError: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:00,905 - ERROR - ‚ùå Transform failed for data/kaggle/garbage-classification-mostafa/garbage_classification/biological/biological741.jpg: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:00,905 - ERROR - ‚ùå FAILED TO LOAD IMAGE 9609: data/kaggle/garbage-classification-mostafa/garbage_classification/biological/biological741.jpg\n",
      "2026-02-10 22:15:00,906 - ERROR -    Error: TypeError: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:00,909 - ERROR - ‚ùå Transform failed for data/kaggle/garbage-classification-v2/clothes/clothes_961.jpg: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:00,910 - ERROR - ‚ùå FAILED TO LOAD IMAGE 68875: data/kaggle/garbage-classification-v2/clothes/clothes_961.jpg\n",
      "2026-02-10 22:15:00,910 - ERROR -    Error: TypeError: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:00,917 - ERROR - ‚ùå Transform failed for data/kaggle/garbage-classification-v2/paper/paper_3241.jpg: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:00,918 - ERROR - ‚ùå FAILED TO LOAD IMAGE 65762: data/kaggle/garbage-classification-v2/paper/paper_3241.jpg\n",
      "2026-02-10 22:15:00,919 - ERROR -    Error: TypeError: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:00,922 - ERROR - ‚ùå Transform failed for data/kaggle/waste-classification-data/DATASET/TRAIN/O/O_6475.jpg: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:00,923 - ERROR - ‚ùå FAILED TO LOAD IMAGE 58081: data/kaggle/waste-classification-data/DATASET/TRAIN/O/O_6475.jpg\n",
      "2026-02-10 22:15:00,923 - ERROR -    Error: TypeError: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:00,926 - ERROR - ‚ùå Transform failed for data/kaggle/garbage-dataset-classification/Garbage_Dataset_Classification/images/plastic/plastic_02331.jpg: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:00,926 - ERROR - ‚ùå FAILED TO LOAD IMAGE 100711: data/kaggle/garbage-dataset-classification/Garbage_Dataset_Classification/images/plastic/plastic_02331.jpg\n",
      "2026-02-10 22:15:00,926 - ERROR -    Error: TypeError: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:00,929 - ERROR - ‚ùå Transform failed for data/kaggle/waste-classification-data/DATASET/TRAIN/R/R_8662.jpg: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:00,930 - ERROR - ‚ùå FAILED TO LOAD IMAGE 50199: data/kaggle/waste-classification-data/DATASET/TRAIN/R/R_8662.jpg\n",
      "2026-02-10 22:15:00,930 - ERROR -    Error: TypeError: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:00,935 - ERROR - ‚ùå Transform failed for data/kaggle/garbage-classification-v2/cardboard/cardboard_965.jpg: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:00,935 - ERROR - ‚ùå FAILED TO LOAD IMAGE 74036: data/kaggle/garbage-classification-v2/cardboard/cardboard_965.jpg\n",
      "2026-02-10 22:15:00,935 - ERROR -    Error: TypeError: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:00,938 - ERROR - ‚ùå Transform failed for data/kaggle/waste-classification-data/DATASET/TRAIN/O/O_2524.jpg: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:00,938 - ERROR - ‚ùå FAILED TO LOAD IMAGE 63750: data/kaggle/waste-classification-data/DATASET/TRAIN/O/O_2524.jpg\n",
      "2026-02-10 22:15:00,939 - ERROR -    Error: TypeError: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:00,941 - ERROR - ‚ùå Transform failed for data/kaggle/waste-classification-data/DATASET/TRAIN/R/R_9248.jpg: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:00,942 - ERROR - ‚ùå FAILED TO LOAD IMAGE 46658: data/kaggle/waste-classification-data/DATASET/TRAIN/R/R_9248.jpg\n",
      "2026-02-10 22:15:00,942 - ERROR -    Error: TypeError: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:00,948 - ERROR - ‚ùå Transform failed for data/kaggle/garbage-classification-mostafa/garbage_classification/clothes/clothes2585.jpg: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:00,949 - ERROR - ‚ùå FAILED TO LOAD IMAGE 6199: data/kaggle/garbage-classification-mostafa/garbage_classification/clothes/clothes2585.jpg\n",
      "2026-02-10 22:15:00,949 - ERROR -    Error: TypeError: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:00,953 - ERROR - ‚ùå Transform failed for data/kaggle/garbage-classification-v2/clothes/clothes_5318.jpg: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:00,954 - ERROR - ‚ùå FAILED TO LOAD IMAGE 68817: data/kaggle/garbage-classification-v2/clothes/clothes_5318.jpg\n",
      "2026-02-10 22:15:00,954 - ERROR -    Error: TypeError: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:00,957 - ERROR - ‚ùå Transform failed for data/kaggle/garbage-dataset-classification/Garbage_Dataset_Classification/images/paper/paper_01522.jpg: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:00,958 - ERROR - ‚ùå FAILED TO LOAD IMAGE 88325: data/kaggle/garbage-dataset-classification/Garbage_Dataset_Classification/images/paper/paper_01522.jpg\n",
      "2026-02-10 22:15:00,958 - ERROR -    Error: TypeError: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:00,961 - ERROR - ‚ùå Transform failed for data/kaggle/garbage-classification-mostafa/garbage_classification/plastic/plastic561.jpg: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:00,961 - ERROR - ‚ùå FAILED TO LOAD IMAGE 12397: data/kaggle/garbage-classification-mostafa/garbage_classification/plastic/plastic561.jpg\n",
      "2026-02-10 22:15:00,962 - ERROR -    Error: TypeError: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:00,964 - ERROR - ‚ùå Transform failed for data/kaggle/waste-classification-data/DATASET/DATASET/TRAIN/R/R_7801.jpg: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:00,965 - ERROR - ‚ùå FAILED TO LOAD IMAGE 27403: data/kaggle/waste-classification-data/DATASET/DATASET/TRAIN/R/R_7801.jpg\n",
      "2026-02-10 22:15:00,965 - ERROR -    Error: TypeError: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:00,968 - ERROR - ‚ùå Transform failed for data/kaggle/garbage-classification-mostafa/garbage_classification/clothes/clothes2141.jpg: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:00,969 - ERROR - ‚ùå FAILED TO LOAD IMAGE 5926: data/kaggle/garbage-classification-mostafa/garbage_classification/clothes/clothes2141.jpg\n",
      "2026-02-10 22:15:00,969 - ERROR -    Error: TypeError: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:00,972 - ERROR - ‚ùå Transform failed for data/kaggle/waste-classification-data/DATASET/DATASET/TRAIN/O/O_218.jpg: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:00,972 - ERROR - ‚ùå FAILED TO LOAD IMAGE 35766: data/kaggle/waste-classification-data/DATASET/DATASET/TRAIN/O/O_218.jpg\n",
      "2026-02-10 22:15:00,972 - ERROR -    Error: TypeError: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:00,975 - ERROR - ‚ùå Transform failed for data/kaggle/garbage-classification-v2/cardboard/cardboard_1583.jpg: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:00,977 - ERROR - ‚ùå FAILED TO LOAD IMAGE 73187: data/kaggle/garbage-classification-v2/cardboard/cardboard_1583.jpg\n",
      "2026-02-10 22:15:00,978 - ERROR -    Error: TypeError: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:00,982 - ERROR - ‚ùå Transform failed for data/kaggle/waste-classification-data/DATASET/DATASET/TRAIN/R/R_4194.jpg: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:00,982 - ERROR - ‚ùå FAILED TO LOAD IMAGE 24380: data/kaggle/waste-classification-data/DATASET/DATASET/TRAIN/R/R_4194.jpg\n",
      "2026-02-10 22:15:00,983 - ERROR -    Error: TypeError: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:00,986 - ERROR - ‚ùå Transform failed for data/kaggle/waste-classification-data/DATASET/DATASET/TRAIN/R/R_5832.jpg: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:00,986 - ERROR - ‚ùå FAILED TO LOAD IMAGE 20305: data/kaggle/waste-classification-data/DATASET/DATASET/TRAIN/R/R_5832.jpg\n",
      "2026-02-10 22:15:00,986 - ERROR -    Error: TypeError: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:00,989 - ERROR - ‚ùå Transform failed for data/kaggle/garbage-classification-v2/shoes/shoes_247.jpg: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:00,990 - ERROR - ‚ùå FAILED TO LOAD IMAGE 83814: data/kaggle/garbage-classification-v2/shoes/shoes_247.jpg\n",
      "2026-02-10 22:15:00,990 - ERROR -    Error: TypeError: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:00,993 - ERROR - ‚ùå Transform failed for data/kaggle/waste-classification-data/DATASET/DATASET/TRAIN/R/R_8891.jpg: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:00,993 - ERROR - ‚ùå FAILED TO LOAD IMAGE 28221: data/kaggle/waste-classification-data/DATASET/DATASET/TRAIN/R/R_8891.jpg\n",
      "2026-02-10 22:15:00,993 - ERROR -    Error: TypeError: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:00,997 - ERROR - ‚ùå Transform failed for data/kaggle/garbage-classification-v2/clothes/clothes_5320.jpg: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:00,997 - ERROR - ‚ùå FAILED TO LOAD IMAGE 68266: data/kaggle/garbage-classification-v2/clothes/clothes_5320.jpg\n",
      "2026-02-10 22:15:00,997 - ERROR -    Error: TypeError: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:01,000 - ERROR - ‚ùå Transform failed for data/kaggle/waste-classification-data/DATASET/TRAIN/O/O_3292.jpg: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:01,000 - ERROR - ‚ùå FAILED TO LOAD IMAGE 56567: data/kaggle/waste-classification-data/DATASET/TRAIN/O/O_3292.jpg\n",
      "2026-02-10 22:15:01,000 - ERROR -    Error: TypeError: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:01,004 - ERROR - ‚ùå Transform failed for data/kaggle/garbage-classification-mostafa/garbage_classification/clothes/clothes2285.jpg: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:01,004 - ERROR - ‚ùå FAILED TO LOAD IMAGE 5185: data/kaggle/garbage-classification-mostafa/garbage_classification/clothes/clothes2285.jpg\n",
      "2026-02-10 22:15:01,005 - ERROR -    Error: TypeError: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:01,010 - ERROR - ‚ùå Transform failed for data/kaggle/waste-classification-data/DATASET/DATASET/TRAIN/O/O_5378.jpg: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:01,010 - ERROR - ‚ùå FAILED TO LOAD IMAGE 34078: data/kaggle/waste-classification-data/DATASET/DATASET/TRAIN/O/O_5378.jpg\n",
      "2026-02-10 22:15:01,011 - ERROR -    Error: TypeError: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:01,013 - ERROR - ‚ùå Transform failed for data/kaggle/waste-classification-data/DATASET/TRAIN/O/O_2575.jpg: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:01,014 - ERROR - ‚ùå FAILED TO LOAD IMAGE 55477: data/kaggle/waste-classification-data/DATASET/TRAIN/O/O_2575.jpg\n",
      "2026-02-10 22:15:01,014 - ERROR -    Error: TypeError: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:01,017 - ERROR - ‚ùå Transform failed for data/kaggle/waste-classification-data/DATASET/TRAIN/R/R_3764.jpg: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:01,017 - ERROR - ‚ùå FAILED TO LOAD IMAGE 47047: data/kaggle/waste-classification-data/DATASET/TRAIN/R/R_3764.jpg\n",
      "2026-02-10 22:15:01,018 - ERROR -    Error: TypeError: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:01,020 - ERROR - ‚ùå Transform failed for data/kaggle/garbage-dataset-classification/Garbage_Dataset_Classification/images/metal/metal_01889.jpg: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:01,021 - ERROR - ‚ùå FAILED TO LOAD IMAGE 89858: data/kaggle/garbage-dataset-classification/Garbage_Dataset_Classification/images/metal/metal_01889.jpg\n",
      "2026-02-10 22:15:01,021 - ERROR -    Error: TypeError: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:01,023 - ERROR - ‚ùå Transform failed for data/kaggle/waste-classification-data/DATASET/DATASET/TRAIN/O/O_7816.jpg: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:01,024 - ERROR - ‚ùå FAILED TO LOAD IMAGE 34325: data/kaggle/waste-classification-data/DATASET/DATASET/TRAIN/O/O_7816.jpg\n",
      "2026-02-10 22:15:01,024 - ERROR -    Error: TypeError: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:01,027 - ERROR - ‚ùå Transform failed for data/kaggle/garbage-classification-mostafa/garbage_classification/clothes/clothes3814.jpg: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:01,028 - ERROR - ‚ùå FAILED TO LOAD IMAGE 3443: data/kaggle/garbage-classification-mostafa/garbage_classification/clothes/clothes3814.jpg\n",
      "2026-02-10 22:15:01,028 - ERROR -    Error: TypeError: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:01,031 - ERROR - ‚ùå Transform failed for data/kaggle/waste-classification-data/DATASET/DATASET/TRAIN/O/O_7156.jpg: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:01,031 - ERROR - ‚ùå FAILED TO LOAD IMAGE 33611: data/kaggle/waste-classification-data/DATASET/DATASET/TRAIN/O/O_7156.jpg\n",
      "2026-02-10 22:15:01,032 - ERROR -    Error: TypeError: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:01,035 - ERROR - ‚ùå Transform failed for data/kaggle/waste-classification-data/DATASET/DATASET/TEST/R/R_10203.jpg: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:01,036 - ERROR - ‚ùå FAILED TO LOAD IMAGE 17827: data/kaggle/waste-classification-data/DATASET/DATASET/TEST/R/R_10203.jpg\n",
      "2026-02-10 22:15:01,037 - ERROR -    Error: TypeError: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:01,041 - ERROR - ‚ùå Transform failed for data/kaggle/garbage-classification-v2/biological/biological_894.jpg: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:01,041 - ERROR - ‚ùå FAILED TO LOAD IMAGE 79192: data/kaggle/garbage-classification-v2/biological/biological_894.jpg\n",
      "2026-02-10 22:15:01,041 - ERROR -    Error: TypeError: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:01,044 - ERROR - ‚ùå Transform failed for data/kaggle/garbage-classification-v2/cardboard/cardboard_871.jpg: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:01,045 - ERROR - ‚ùå FAILED TO LOAD IMAGE 74367: data/kaggle/garbage-classification-v2/cardboard/cardboard_871.jpg\n",
      "2026-02-10 22:15:01,045 - ERROR -    Error: TypeError: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:01,048 - ERROR - ‚ùå Transform failed for data/kaggle/waste-classification-data/DATASET/DATASET/TRAIN/O/O_10074.jpg: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:01,048 - ERROR - ‚ùå FAILED TO LOAD IMAGE 29807: data/kaggle/waste-classification-data/DATASET/DATASET/TRAIN/O/O_10074.jpg\n",
      "2026-02-10 22:15:01,049 - ERROR -    Error: TypeError: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:01,051 - ERROR - ‚ùå Transform failed for data/kaggle/waste-classification-data/DATASET/TRAIN/O/O_9768.jpg: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:01,051 - ERROR - ‚ùå FAILED TO LOAD IMAGE 56526: data/kaggle/waste-classification-data/DATASET/TRAIN/O/O_9768.jpg\n",
      "2026-02-10 22:15:01,052 - ERROR -    Error: TypeError: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:01,055 - ERROR - ‚ùå Transform failed for data/kaggle/garbage-classification-v2/shoes/shoes_1015.jpg: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:01,055 - ERROR - ‚ùå FAILED TO LOAD IMAGE 83622: data/kaggle/garbage-classification-v2/shoes/shoes_1015.jpg\n",
      "2026-02-10 22:15:01,056 - ERROR -    Error: TypeError: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:01,059 - ERROR - ‚ùå Transform failed for data/kaggle/waste-classification-data/DATASET/TRAIN/R/R_7056.jpg: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:01,059 - ERROR - ‚ùå FAILED TO LOAD IMAGE 47750: data/kaggle/waste-classification-data/DATASET/TRAIN/R/R_7056.jpg\n",
      "2026-02-10 22:15:01,059 - ERROR -    Error: TypeError: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:01,062 - ERROR - ‚ùå Transform failed for data/kaggle/garbage-classification-mostafa/garbage_classification/biological/biological219.jpg: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:01,063 - ERROR - ‚ùå FAILED TO LOAD IMAGE 9612: data/kaggle/garbage-classification-mostafa/garbage_classification/biological/biological219.jpg\n",
      "2026-02-10 22:15:01,063 - ERROR -    Error: TypeError: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:01,068 - ERROR - ‚ùå Transform failed for data/kaggle/garbage-classification-mostafa/garbage_classification/brown-glass/brown-glass374.jpg: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:01,068 - ERROR - ‚ùå FAILED TO LOAD IMAGE 11677: data/kaggle/garbage-classification-mostafa/garbage_classification/brown-glass/brown-glass374.jpg\n",
      "2026-02-10 22:15:01,069 - ERROR -    Error: TypeError: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:01,071 - ERROR - ‚ùå Transform failed for data/kaggle/waste-classification-data/DATASET/TRAIN/R/R_1095.jpg: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:01,072 - ERROR - ‚ùå FAILED TO LOAD IMAGE 50497: data/kaggle/waste-classification-data/DATASET/TRAIN/R/R_1095.jpg\n",
      "2026-02-10 22:15:01,072 - ERROR -    Error: TypeError: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:01,074 - ERROR - ‚ùå Transform failed for data/kaggle/waste-classification-data/DATASET/TRAIN/O/O_4831.jpg: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:01,075 - ERROR - ‚ùå FAILED TO LOAD IMAGE 53082: data/kaggle/waste-classification-data/DATASET/TRAIN/O/O_4831.jpg\n",
      "2026-02-10 22:15:01,075 - ERROR -    Error: TypeError: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:01,078 - ERROR - ‚ùå Transform failed for data/kaggle/waste-classification-data/DATASET/DATASET/TRAIN/O/O_9714.jpg: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:01,078 - ERROR - ‚ùå FAILED TO LOAD IMAGE 39366: data/kaggle/waste-classification-data/DATASET/DATASET/TRAIN/O/O_9714.jpg\n",
      "2026-02-10 22:15:01,079 - ERROR -    Error: TypeError: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:01,081 - ERROR - ‚ùå Transform failed for data/kaggle/waste-classification-data/DATASET/TRAIN/R/R_9961.jpg: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:01,081 - ERROR - ‚ùå FAILED TO LOAD IMAGE 51594: data/kaggle/waste-classification-data/DATASET/TRAIN/R/R_9961.jpg\n",
      "2026-02-10 22:15:01,082 - ERROR -    Error: TypeError: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:01,084 - ERROR - ‚ùå Transform failed for data/kaggle/waste-classification-data/DATASET/TRAIN/O/O_3186.jpg: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:01,085 - ERROR - ‚ùå FAILED TO LOAD IMAGE 53084: data/kaggle/waste-classification-data/DATASET/TRAIN/O/O_3186.jpg\n",
      "2026-02-10 22:15:01,085 - ERROR -    Error: TypeError: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:01,088 - ERROR - ‚ùå Transform failed for data/kaggle/waste-classification-data/DATASET/DATASET/TRAIN/O/O_222.jpg: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:01,088 - ERROR - ‚ùå FAILED TO LOAD IMAGE 34209: data/kaggle/waste-classification-data/DATASET/DATASET/TRAIN/O/O_222.jpg\n",
      "2026-02-10 22:15:01,088 - ERROR -    Error: TypeError: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:01,092 - ERROR - ‚ùå Transform failed for data/kaggle/garbage-classification-v2/battery/battery_207.jpg: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:01,093 - ERROR - ‚ùå FAILED TO LOAD IMAGE 80195: data/kaggle/garbage-classification-v2/battery/battery_207.jpg\n",
      "2026-02-10 22:15:01,093 - ERROR -    Error: TypeError: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:01,097 - ERROR - ‚ùå Transform failed for data/kaggle/waste-classification-data/DATASET/TRAIN/R/R_9261.jpg: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:01,098 - ERROR - ‚ùå FAILED TO LOAD IMAGE 47061: data/kaggle/waste-classification-data/DATASET/TRAIN/R/R_9261.jpg\n",
      "2026-02-10 22:15:01,098 - ERROR -    Error: TypeError: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:01,101 - ERROR - ‚ùå Transform failed for data/kaggle/waste-classification-data/DATASET/TRAIN/O/O_6882.jpg: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:01,101 - ERROR - ‚ùå FAILED TO LOAD IMAGE 55823: data/kaggle/waste-classification-data/DATASET/TRAIN/O/O_6882.jpg\n",
      "2026-02-10 22:15:01,102 - ERROR -    Error: TypeError: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:01,104 - ERROR - ‚ùå Transform failed for data/kaggle/waste-classification-data/DATASET/TRAIN/R/R_686.jpg: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:01,105 - ERROR - ‚ùå FAILED TO LOAD IMAGE 44469: data/kaggle/waste-classification-data/DATASET/TRAIN/R/R_686.jpg\n",
      "2026-02-10 22:15:01,105 - ERROR -    Error: TypeError: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:01,108 - ERROR - ‚ùå Transform failed for data/kaggle/waste-classification-data/DATASET/DATASET/TRAIN/O/O_8633.jpg: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:01,108 - ERROR - ‚ùå FAILED TO LOAD IMAGE 41127: data/kaggle/waste-classification-data/DATASET/DATASET/TRAIN/O/O_8633.jpg\n",
      "2026-02-10 22:15:01,108 - ERROR -    Error: TypeError: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:01,111 - ERROR - ‚ùå Transform failed for data/kaggle/waste-classification-data/DATASET/DATASET/TRAIN/O/O_9204.jpg: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:01,111 - ERROR - ‚ùå FAILED TO LOAD IMAGE 36931: data/kaggle/waste-classification-data/DATASET/DATASET/TRAIN/O/O_9204.jpg\n",
      "2026-02-10 22:15:01,112 - ERROR -    Error: TypeError: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:01,115 - ERROR - ‚ùå Transform failed for data/kaggle/garbage-classification/Garbage classification/Garbage classification/trash/trash5.jpg: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:01,115 - ERROR - ‚ùå FAILED TO LOAD IMAGE 86407: data/kaggle/garbage-classification/Garbage classification/Garbage classification/trash/trash5.jpg\n",
      "2026-02-10 22:15:01,116 - ERROR -    Error: TypeError: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:01,118 - ERROR - ‚ùå Transform failed for data/kaggle/garbage-dataset-classification/Garbage_Dataset_Classification/images/plastic/plastic_02128.jpg: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:01,119 - ERROR - ‚ùå FAILED TO LOAD IMAGE 99875: data/kaggle/garbage-dataset-classification/Garbage_Dataset_Classification/images/plastic/plastic_02128.jpg\n",
      "2026-02-10 22:15:01,119 - ERROR -    Error: TypeError: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:01,121 - ERROR - ‚ùå Transform failed for data/kaggle/garbage-classification-v2/glass/glass_1680.jpg: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:01,122 - ERROR - ‚ùå FAILED TO LOAD IMAGE 75800: data/kaggle/garbage-classification-v2/glass/glass_1680.jpg\n",
      "2026-02-10 22:15:01,124 - ERROR -    Error: TypeError: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:01,130 - ERROR - ‚ùå Transform failed for data/kaggle/waste-classification-data/DATASET/DATASET/TRAIN/R/R_9216.jpg: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:01,130 - ERROR - ‚ùå FAILED TO LOAD IMAGE 22010: data/kaggle/waste-classification-data/DATASET/DATASET/TRAIN/R/R_9216.jpg\n",
      "2026-02-10 22:15:01,130 - ERROR -    Error: TypeError: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:01,133 - ERROR - ‚ùå Transform failed for data/kaggle/garbage-classification-mostafa/garbage_classification/shoes/shoes1732.jpg: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:01,133 - ERROR - ‚ùå FAILED TO LOAD IMAGE 13286: data/kaggle/garbage-classification-mostafa/garbage_classification/shoes/shoes1732.jpg\n",
      "2026-02-10 22:15:01,134 - ERROR -    Error: TypeError: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:01,138 - ERROR - ‚ùå Transform failed for data/kaggle/waste-classification-data/DATASET/DATASET/TRAIN/O/O_11822.jpg: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:01,138 - ERROR - ‚ùå FAILED TO LOAD IMAGE 40223: data/kaggle/waste-classification-data/DATASET/DATASET/TRAIN/O/O_11822.jpg\n",
      "2026-02-10 22:15:01,138 - ERROR -    Error: TypeError: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:01,141 - ERROR - ‚ùå Transform failed for data/kaggle/waste-classification-data/DATASET/TRAIN/O/O_10620.jpg: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:01,141 - ERROR - ‚ùå FAILED TO LOAD IMAGE 61437: data/kaggle/waste-classification-data/DATASET/TRAIN/O/O_10620.jpg\n",
      "2026-02-10 22:15:01,142 - ERROR -    Error: TypeError: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:01,145 - ERROR - ‚ùå Transform failed for data/kaggle/garbage-classification-v2/biological/biological_680.jpg: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:01,145 - ERROR - ‚ùå FAILED TO LOAD IMAGE 79550: data/kaggle/garbage-classification-v2/biological/biological_680.jpg\n",
      "2026-02-10 22:15:01,145 - ERROR -    Error: TypeError: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:01,148 - ERROR - ‚ùå Transform failed for data/kaggle/waste-classification-data/DATASET/TEST/R/R_10700.jpg: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:01,148 - ERROR - ‚ùå FAILED TO LOAD IMAGE 15529: data/kaggle/waste-classification-data/DATASET/TEST/R/R_10700.jpg\n",
      "2026-02-10 22:15:01,148 - ERROR -    Error: TypeError: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:01,155 - ERROR - ‚ùå Transform failed for data/kaggle/garbage-classification-mostafa/garbage_classification/clothes/clothes3616.jpg: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:01,156 - ERROR - ‚ùå FAILED TO LOAD IMAGE 5178: data/kaggle/garbage-classification-mostafa/garbage_classification/clothes/clothes3616.jpg\n",
      "2026-02-10 22:15:01,157 - ERROR -    Error: TypeError: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:01,163 - ERROR - ‚ùå Transform failed for data/kaggle/garbage-classification-mostafa/garbage_classification/clothes/clothes4885.jpg: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:01,163 - ERROR - ‚ùå FAILED TO LOAD IMAGE 2523: data/kaggle/garbage-classification-mostafa/garbage_classification/clothes/clothes4885.jpg\n",
      "2026-02-10 22:15:01,163 - ERROR -    Error: TypeError: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:01,166 - ERROR - ‚ùå Transform failed for data/kaggle/waste-classification-data/DATASET/TRAIN/R/R_9804.jpg: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:01,166 - ERROR - ‚ùå FAILED TO LOAD IMAGE 49948: data/kaggle/waste-classification-data/DATASET/TRAIN/R/R_9804.jpg\n",
      "2026-02-10 22:15:01,167 - ERROR -    Error: TypeError: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:01,170 - ERROR - ‚ùå Transform failed for data/kaggle/garbage-classification-mostafa/garbage_classification/trash/trash506.jpg: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:01,170 - ERROR - ‚ùå FAILED TO LOAD IMAGE 9311: data/kaggle/garbage-classification-mostafa/garbage_classification/trash/trash506.jpg\n",
      "2026-02-10 22:15:01,171 - ERROR -    Error: TypeError: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:01,173 - ERROR - ‚ùå Transform failed for data/kaggle/garbage-classification-v2/cardboard/cardboard_1214.jpg: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:01,173 - ERROR - ‚ùå FAILED TO LOAD IMAGE 74381: data/kaggle/garbage-classification-v2/cardboard/cardboard_1214.jpg\n",
      "2026-02-10 22:15:01,174 - ERROR -    Error: TypeError: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:01,180 - ERROR - ‚ùå Transform failed for data/kaggle/garbage-classification-v2/plastic/plastic_20248.png: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:01,181 - ERROR - ‚ùå FAILED TO LOAD IMAGE 81011: data/kaggle/garbage-classification-v2/plastic/plastic_20248.png\n",
      "2026-02-10 22:15:01,181 - ERROR -    Error: TypeError: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:01,181 - ERROR -   ‚ùå Sample 7331 failed: ‚ùå TOO MANY IMAGE LOADING FAILURES (101)! This indicates a serious dataset problem. Aborting training.\n",
      "2026-02-10 22:15:01,183 - ERROR - ‚ùå Transform failed for data/kaggle/waste-classification-data/DATASET/DATASET/TRAIN/O/O_9201.jpg: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:01,184 - ERROR - ‚ùå FAILED TO LOAD IMAGE 37735: data/kaggle/waste-classification-data/DATASET/DATASET/TRAIN/O/O_9201.jpg\n",
      "2026-02-10 22:15:01,184 - ERROR -    Error: TypeError: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:01,185 - ERROR -   ‚ùå Sample 30021 failed: ‚ùå TOO MANY IMAGE LOADING FAILURES (102)! This indicates a serious dataset problem. Aborting training.\n",
      "2026-02-10 22:15:01,186 - ERROR - ‚ùå Transform failed for data/kaggle/waste-classification-data/DATASET/DATASET/TRAIN/O/O_1449.jpg: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:01,187 - ERROR - ‚ùå FAILED TO LOAD IMAGE 38620: data/kaggle/waste-classification-data/DATASET/DATASET/TRAIN/O/O_1449.jpg\n",
      "2026-02-10 22:15:01,187 - ERROR -    Error: TypeError: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:01,188 - ERROR -   ‚ùå Sample 4207 failed: ‚ùå TOO MANY IMAGE LOADING FAILURES (103)! This indicates a serious dataset problem. Aborting training.\n",
      "2026-02-10 22:15:01,190 - ERROR - ‚ùå Transform failed for data/kaggle/waste-classification-data/DATASET/DATASET/TRAIN/R/R_8028.jpg: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:01,190 - ERROR - ‚ùå FAILED TO LOAD IMAGE 26006: data/kaggle/waste-classification-data/DATASET/DATASET/TRAIN/R/R_8028.jpg\n",
      "2026-02-10 22:15:01,190 - ERROR -    Error: TypeError: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:01,191 - ERROR -   ‚ùå Sample 41347 failed: ‚ùå TOO MANY IMAGE LOADING FAILURES (104)! This indicates a serious dataset problem. Aborting training.\n",
      "2026-02-10 22:15:01,198 - ERROR - ‚ùå Transform failed for data/kaggle/garbage-classification-v2/shoes/shoes_479.jpg: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:01,199 - ERROR - ‚ùå FAILED TO LOAD IMAGE 83639: data/kaggle/garbage-classification-v2/shoes/shoes_479.jpg\n",
      "2026-02-10 22:15:01,199 - ERROR -    Error: TypeError: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:01,200 - ERROR -   ‚ùå Sample 52581 failed: ‚ùå TOO MANY IMAGE LOADING FAILURES (105)! This indicates a serious dataset problem. Aborting training.\n",
      "2026-02-10 22:15:01,202 - ERROR - ‚ùå Transform failed for data/kaggle/garbage-classification/Garbage classification/Garbage classification/glass/glass492.jpg: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:01,203 - ERROR - ‚ùå FAILED TO LOAD IMAGE 86840: data/kaggle/garbage-classification/Garbage classification/Garbage classification/glass/glass492.jpg\n",
      "2026-02-10 22:15:01,203 - ERROR -    Error: TypeError: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:01,204 - ERROR -   ‚ùå Sample 35093 failed: ‚ùå TOO MANY IMAGE LOADING FAILURES (106)! This indicates a serious dataset problem. Aborting training.\n",
      "2026-02-10 22:15:01,206 - ERROR - ‚ùå Transform failed for data/kaggle/garbage-classification-mostafa/garbage_classification/clothes/clothes268.jpg: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:01,207 - ERROR - ‚ùå FAILED TO LOAD IMAGE 5083: data/kaggle/garbage-classification-mostafa/garbage_classification/clothes/clothes268.jpg\n",
      "2026-02-10 22:15:01,207 - ERROR -    Error: TypeError: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:01,207 - ERROR -   ‚ùå Sample 8675 failed: ‚ùå TOO MANY IMAGE LOADING FAILURES (107)! This indicates a serious dataset problem. Aborting training.\n",
      "2026-02-10 22:15:01,209 - ERROR - ‚ùå Transform failed for data/kaggle/garbage-classification-v2/biological/biological_170.jpg: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:01,210 - ERROR - ‚ùå FAILED TO LOAD IMAGE 79135: data/kaggle/garbage-classification-v2/biological/biological_170.jpg\n",
      "2026-02-10 22:15:01,210 - ERROR -    Error: TypeError: expected np.ndarray (got numpy.ndarray)\n",
      "2026-02-10 22:15:01,211 - ERROR -   ‚ùå Sample 27653 failed: ‚ùå TOO MANY IMAGE LOADING FAILURES (108)! This indicates a serious dataset problem. Aborting training.\n",
      "2026-02-10 22:15:01,211 - INFO -   ‚úÖ Success rate: 0.0% (0/100)\n",
      "2026-02-10 22:15:01,212 - INFO -   ‚ö†Ô∏è  Dummy tensors detected: 92\n",
      "2026-02-10 22:15:01,212 - INFO -   ‚ö†Ô∏è  Failed samples: 100\n",
      "2026-02-10 22:15:01,212 - ERROR - ‚ùå TOO MANY DUMMY TENSORS (92/100)!\n",
      "2026-02-10 22:15:01,212 - ERROR -    This means images are NOT loading correctly.\n",
      "2026-02-10 22:15:01,213 - ERROR -    Checking first failed sample for details...\n",
      "2026-02-10 22:15:01,213 - ERROR -    Failed sample path: data/kaggle/garbage-classification-v2/shoes/shoes_1401.jpg\n",
      "2026-02-10 22:15:01,214 - ERROR -    Path exists: True\n",
      "2026-02-10 22:15:01,214 - ERROR -    File size: 8828 bytes\n",
      "2026-02-10 22:15:01,215 - ERROR - ‚ùå Data quality validation failed: Dataset loading is BROKEN! 92/100 samples are dummy tensors. This is NOT acceptable for training.\n",
      "2026-02-10 22:15:01,215 - ERROR - Training failed with error: Dataset loading is BROKEN! 92/100 samples are dummy tensors. This is NOT acceptable for training.\n",
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/y0/l9ns18ns5472mqrprmhhmsw00000gn/T/ipykernel_12780/2369721574.py\", line 11, in <module>\n",
      "    vision_model = train_vision_model(VISION_CONFIG, resume_from_checkpoint=None)\n",
      "  File \"/var/folders/y0/l9ns18ns5472mqrprmhhmsw00000gn/T/ipykernel_12780/2082420154.py\", line 342, in train_vision_model\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Dataset loading is BROKEN! 92/100 samples are dummy tensors. This is NOT acceptable for training.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Dataset loading is BROKEN! 92/100 samples are dummy tensors. This is NOT acceptable for training.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[16], line 11\u001B[0m\n\u001B[1;32m      5\u001B[0m logger\u001B[38;5;241m.\u001B[39minfo(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m80\u001B[39m)\n\u001B[1;32m      7\u001B[0m \u001B[38;5;66;03m# CRITICAL: Starting fresh with improved hyperparameters to fix overfitting\u001B[39;00m\n\u001B[1;32m      8\u001B[0m \u001B[38;5;66;03m# Previous training: Epochs 1-6 showed severe overfitting (92.64% ‚Üí 78.35%)\u001B[39;00m\n\u001B[1;32m      9\u001B[0m \u001B[38;5;66;03m# New config: Lower LR (1e-5), higher weight decay (0.1)\u001B[39;00m\n\u001B[1;32m     10\u001B[0m \u001B[38;5;66;03m# Old checkpoint available at: checkpoints/best_model_epoch1_acc92.64.pth\u001B[39;00m\n\u001B[0;32m---> 11\u001B[0m vision_model \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_vision_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mVISION_CONFIG\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mresume_from_checkpoint\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m     13\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m vision_model \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m     14\u001B[0m     save_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbest_vision_eva02_lake.pth\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
      "Cell \u001B[0;32mIn[11], line 342\u001B[0m, in \u001B[0;36mtrain_vision_model\u001B[0;34m(config, resume_from_checkpoint)\u001B[0m\n\u001B[1;32m    339\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m path\u001B[38;5;241m.\u001B[39mexists():\n\u001B[1;32m    340\u001B[0m             logger\u001B[38;5;241m.\u001B[39merror(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m   File size: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpath\u001B[38;5;241m.\u001B[39mstat()\u001B[38;5;241m.\u001B[39mst_size\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m bytes\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m--> 342\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[1;32m    343\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDataset loading is BROKEN! \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdummy_tensor_count\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/100 samples are dummy tensors. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    344\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThis is NOT acceptable for training.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    345\u001B[0m     )\n\u001B[1;32m    347\u001B[0m \u001B[38;5;66;03m# CRITICAL TEST 2: Validate batch loading\u001B[39;00m\n\u001B[1;32m    348\u001B[0m logger\u001B[38;5;241m.\u001B[39minfo(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTest 2: Batch Loading (10 random batches)...\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[0;31mRuntimeError\u001B[0m: Dataset loading is BROKEN! 92/100 samples are dummy tensors. This is NOT acceptable for training."
     ]
    }
   ],
   "execution_count": 16
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
