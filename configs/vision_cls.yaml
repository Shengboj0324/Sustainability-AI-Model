# Vision Classifier Configuration
# Waste and material classification from images
# PEAK STANDARD: SOTA EVA-02 Backbone with 448px resolution

model:
  backbone: "eva02_large_patch14_448.mim_m38m_ft_in22k_in1k" # State-of-the-art Vision Transformer
  pretrained: true
  pretrained_source: "timm"

  # Multi-head classification
  multi_head: true
  num_classes_item: 20 # Bottle, can, box, bag, cup, textile, e-waste, etc.
  num_classes_material: 15 # PET, HDPE, PP, PVC, glass, aluminum, paper, etc.
  num_classes_bin: 4 # Recycle, compost, landfill, hazardous

  # Model architecture
  drop_rate: 0.2 # Increased for larger model
  drop_path_rate: 0.2 # Stochastic depth

  # Class definitions
  item_classes:
    - "plastic_bottle"
    - "glass_bottle"
    - "aluminum_can"
    - "steel_can"
    - "cardboard_box"
    - "paper"
    - "plastic_bag"
    - "food_container"
    - "cup"
    - "textile"
    - "e_waste"
    - "battery"
    - "light_bulb"
    - "organic_waste"
    - "styrofoam"
    - "tetra_pak"
    - "mixed_plastic"
    - "metal_scrap"
    - "wood"
    - "other"

  material_classes:
    - "PET"
    - "HDPE"
    - "PVC"
    - "LDPE"
    - "PP"
    - "PS"
    - "glass"
    - "aluminum"
    - "steel"
    - "paper"
    - "cardboard"
    - "cotton"
    - "polyester"
    - "mixed"
    - "other"

data:
  # Data directories
  data_dir: "data/processed/vision_cls"
  train_dir: "data/processed/vision_cls/train"
  val_dir: "data/processed/vision_cls/val"
  test_dir: "data/processed/vision_cls/test"

  # Image processing
  input_size: 448 # CRITICAL: Higher resolution for fine-grained details
  interpolation: "bicubic"
  mean: [0.48145466, 0.4578275, 0.40821073] # CLIP/EVA mean
  std: [0.26862954, 0.26130258, 0.27577711] # CLIP/EVA std

  # Data loading
  num_workers: 8
  pin_memory: true
  persistent_workers: true

  # Augmentations for training (Peak Standard)
  augmentations:
    - type: "random_resized_crop"
      size: 448
      scale: [0.08, 1.0] # Aggressive scaling
      ratio: [0.75, 1.3333333333333333]
    - type: "horizontal_flip"
      p: 0.5
    - type: "rand_augment" # AutoAugment/RandAugment
      num_ops: 2
      magnitude: 9
    - type: "color_jitter"
      brightness: 0.4
      contrast: 0.4
      saturation: 0.4
      hue: 0.1
    - type: "random_erasing"
      p: 0.25
      mode: "pixel"
    - type: "normalize"
      mean: [0.48145466, 0.4578275, 0.40821073]
      std: [0.26862954, 0.26130258, 0.27577711]

training:
  # Output
  output_dir: "models/vision/classifier"
  experiment_name: "waste_classifier_eva02_peak_v1"

  # CRITICAL: Reproducibility
  seed: 42

  # Batch size (Reduced for larger model/res)
  batch_size: 16
  val_batch_size: 32
  gradient_accumulation_steps: 4 # Effective batch size = 64

  # Training duration
  num_epochs: 50
  early_stopping_patience: 15

  # Optimization
  optimizer: "adamw"
  learning_rate: 1.0e-4 # Lower LR for fine-tuning
  weight_decay: 0.05
  layer_decay: 0.8 # Layer-wise LR decay (crucial for Transformers)
  betas: [0.9, 0.999]
  eps: 1.0e-8

  # Learning rate schedule
  lr_scheduler: "cosine"
  warmup_epochs: 5
  min_lr: 1.0e-6

  # Regularization
  label_smoothing: 0.1
  mixup_alpha: 0.8 # Stronger mixup
  cutmix_alpha: 1.0 # Stronger cutmix
  mixup_prob: 1.0 # Always apply mixup/cutmix
  cutmix_prob: 1.0

  # Gradient clipping
  clip_grad_norm: 5.0 # Transformers sometimes need higher clip

  # Mixed precision
  use_amp: true
  amp_dtype: "bfloat16" # CRITICAL: Better stability than fp16

  # Checkpointing
  save_freq: 1
  save_every: 1
  save_best_only: false

  # Class balancing
  use_balanced_sampler: true

  # Logging
  log_interval: 10
  val_interval: 1

loss:
  # Multi-task loss configuration
  item_type_loss: "cross_entropy"
  material_loss: "cross_entropy"
  bin_type_loss: "cross_entropy"

  # Loss weights
  loss_weights:
    item_type: 1.0
    material: 1.0
    bin_type: 0.5

evaluation:
  # Metrics
  metrics:
    - "top1_acc_item"
    - "top5_acc_item"
    - "top1_acc_material"
    - "top5_acc_material"
    - "top1_acc_bin"
    - "f1_macro_item"
    - "f1_macro_material"
    - "f1_weighted_item"
    - "f1_weighted_material"

  # Confusion matrix
  confusion_matrix: true
  save_confusion_matrix: true

  # Per-class metrics
  per_class_metrics: true

inference:
  # Inference settings
  batch_size: 32
  tta: true # CRITICAL: Enable TTA by default
  tta_transforms: 10 # 10-crop equivalent
