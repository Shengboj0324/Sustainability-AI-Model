# LLM Supervised Fine-Tuning Configuration
# Domain specialization for sustainability, recycling, and upcycling
# PEAK STANDARD: Expert Persona & Strict Safety

model:
  base_model_name: "meta-llama/Llama-3-8B-Instruct"
  model_type: "causal_lm"
  trust_remote_code: true

  # LoRA configuration for efficient fine-tuning
  lora:
    enabled: true
    r: 64
    alpha: 128
    dropout: 0.05
    target_modules: "all-linear" # Target all linear layers for maximum expressivity
    bias: "none"
    task_type: "CAUSAL_LM"

  # Quantization for memory efficiency
  quantization:
    enabled: true
    load_in_4bit: true
    bnb_4bit_compute_dtype: "bfloat16"
    bnb_4bit_quant_type: "nf4"
    bnb_4bit_use_double_quant: true

data:
  # Training data files
  train_files:
    - "data/processed/llm_sft/sustainability_qa_train.jsonl"
    - "data/processed/llm_sft/upcycling_qa_train.jsonl"
    - "data/processed/llm_sft/org_routing_train.jsonl"
    - "data/processed/llm_sft/expert_thinking_traces.jsonl" # Added Chain-of-Thought data

  # Validation data files
  val_files:
    - "data/processed/llm_sft/sustainability_qa_val.jsonl"
    - "data/processed/llm_sft/org_routing_val.jsonl"

  # Data format and processing
  format: "chat"
  max_length: 4096 # Doubled context length
  packing: true
  num_workers: 8

  # Data composition weights
  sampling_weights:
    sustainability_qa: 0.30
    upcycling_qa: 0.30
    org_routing: 0.15
    expert_thinking_traces: 0.15 # Focus on reasoning
    safety_examples: 0.10

training:
  # Trainer configuration
  trainer: "hf_trainer"
  output_dir: "models/llm/adapters/sustainability-expert-v1"

  # Batch size
  per_device_train_batch_size: 2
  per_device_eval_batch_size: 2
  gradient_accumulation_steps: 16

  # Training duration
  num_train_epochs: 3

  # Optimization
  learning_rate: 1.0e-4
  lr_scheduler_type: "cosine"
  warmup_ratio: 0.03
  weight_decay: 0.05
  max_grad_norm: 0.5 # Stricter clipping

  # Optimizer settings
  optim: "paged_adamw_32bit" # Memory efficient

  # Mixed precision
  bf16: true
  fp16: false

  # Logging
  logging_steps: 10
  save_steps: 200
  eval_steps: 200
  save_total_limit: 3
  load_best_model_at_end: true

  # Evaluation
  evaluation_strategy: "steps"
  save_strategy: "steps"

  # Reproducibility
  seed: 42

peft:
  use_lora: true
  lora_inference_merge: false

evaluation:
  metrics:
    - "loss"
    - "perplexity"
    - "rouge"
    - "bertscore"

  max_eval_samples: 500

inference:
  max_new_tokens: 1024
  temperature: 0.6 # Lower temperature for precision
  top_p: 0.9
  repetition_penalty: 1.15

system_prompt: |
  You are ReleAF AI, a Senior Environmental Scientist and Master Upcycler. 
  Your mission is to guide users towards zero-waste living with scientific accuracy and creative flair.

  CORE DIRECTIVES:
  1. ACCURACY: Base all material identification and chemical property claims on verification. If unsure, state limitations.
  2. SAFETY: Immediately identify hazards (e.g., chemicals in plastics, sharp edges). Prioritize user safety above all.
  3. CREATIVITY: For upcycling, generate novel, practical, and aesthetically pleasing ideas. Provide step-by-step logic.
  4. HOLISTIC VIEW: Consider the entire lifecycle of a product. Suggest disposal only as a last resort.

  RESPONSE FORMAT:
  - Structure answers clearly with headers.
  - Use markdown for readability.
  - When suggesting ideas, include a "Difficulty" and "Tools Needed" section.

  You represent the pinnacle of sustainability AI. Be helpful, precise, and inspiring.
