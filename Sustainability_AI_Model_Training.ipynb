{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-23T20:11:07.438201Z",
     "start_time": "2026-01-23T20:10:30.572497Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import subprocess\n",
    "import sys\n",
    "import os\n",
    "\n",
    "print(\"Installing dependencies for Sustainability AI Model (MacBook Local Training)...\")\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Install packages one by one with error handling\n",
    "def install_package(package_spec, description=\"\"):\n",
    "    \"\"\"Install a package with error handling.\"\"\"\n",
    "    try:\n",
    "        print(f\"Installing {description or package_spec}...\")\n",
    "        subprocess.check_call(\n",
    "            [sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"--upgrade\"] + package_spec.split(),\n",
    "            timeout=300  # 5 minute timeout per package\n",
    "        )\n",
    "        print(f\"  âœ… {description or package_spec}\")\n",
    "        return True\n",
    "    except subprocess.TimeoutExpired:\n",
    "        print(f\"  âš ï¸  Timeout installing {description or package_spec}, skipping...\")\n",
    "        return False\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"  âš ï¸  Failed to install {description or package_spec}: {e}\")\n",
    "        return False\n",
    "\n",
    "# Upgrade pip first\n",
    "print(\"Upgrading pip...\")\n",
    "subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"--upgrade\", \"pip\"], timeout=60)\n",
    "\n",
    "# Install Kaggle API\n",
    "install_package(\"kaggle\", \"Kaggle API\")\n",
    "\n",
    "# Install core dependencies (Python 3.9 compatible versions)\n",
    "install_package(\"numpy>=1.19.0,<2.0\", \"NumPy\")\n",
    "install_package(\"scipy>=1.7.0,<1.15.0\", \"SciPy\")\n",
    "install_package(\"Pillow>=8.0.0\", \"Pillow\")\n",
    "install_package(\"pandas>=1.3.0\", \"Pandas\")\n",
    "install_package(\"scikit-learn>=1.0.0\", \"scikit-learn\")\n",
    "install_package(\"matplotlib>=3.4.0\", \"Matplotlib\")\n",
    "install_package(\"seaborn>=0.11.0\", \"Seaborn\")\n",
    "install_package(\"tqdm>=4.62.0\", \"tqdm\")\n",
    "\n",
    "# Install PyTorch with compatible torchvision version\n",
    "print(\"Checking PyTorch installation...\")\n",
    "try:\n",
    "    import torch\n",
    "    import torchvision\n",
    "    torch_version = torch.__version__\n",
    "    torchvision_version = torchvision.__version__\n",
    "    print(f\"  Current PyTorch: {torch_version}\")\n",
    "    print(f\"  Current torchvision: {torchvision_version}\")\n",
    "\n",
    "    # Check if versions are compatible\n",
    "    # PyTorch 2.x needs torchvision 0.15+\n",
    "    # PyTorch 1.x needs torchvision 0.x\n",
    "    torch_major = int(torch_version.split('.')[0])\n",
    "    tv_major = int(torchvision_version.split('.')[0])\n",
    "\n",
    "    if torch_major == 2 and tv_major == 0 and int(torchvision_version.split('.')[1]) < 15:\n",
    "        print(\"  âš ï¸  Version mismatch detected! Reinstalling compatible versions...\")\n",
    "        subprocess.run([sys.executable, \"-m\", \"pip\", \"uninstall\", \"-y\", \"torch\", \"torchvision\"], check=False)\n",
    "        install_package(\"torch==2.0.1 torchvision==0.15.2\", \"PyTorch 2.0.1 + torchvision 0.15.2\")\n",
    "    elif torch_major != tv_major:\n",
    "        print(\"  âš ï¸  Major version mismatch! Reinstalling compatible versions...\")\n",
    "        subprocess.run([sys.executable, \"-m\", \"pip\", \"uninstall\", \"-y\", \"torch\", \"torchvision\"], check=False)\n",
    "        install_package(\"torch==2.0.1 torchvision==0.15.2\", \"PyTorch 2.0.1 + torchvision 0.15.2\")\n",
    "    else:\n",
    "        print(\"  âœ… PyTorch and torchvision versions are compatible\")\n",
    "\n",
    "except ImportError:\n",
    "    print(\"  Installing PyTorch and torchvision...\")\n",
    "    install_package(\"torch==2.0.1 torchvision==0.15.2\", \"PyTorch 2.0.1 + torchvision 0.15.2\")\n",
    "except AttributeError as e:\n",
    "    print(f\"  âš ï¸  Version compatibility issue detected: {e}\")\n",
    "    print(\"  Reinstalling compatible PyTorch and torchvision versions...\")\n",
    "    subprocess.run([sys.executable, \"-m\", \"pip\", \"uninstall\", \"-y\", \"torch\", \"torchvision\"], check=False)\n",
    "    install_package(\"torch==2.0.1 torchvision==0.15.2\", \"PyTorch 2.0.1 + torchvision 0.15.2\")\n",
    "\n",
    "# Install timm (Python 3.9 compatible)\n",
    "install_package(\"timm>=0.9.0\", \"timm\")\n",
    "\n",
    "# Install albumentations\n",
    "install_package(\"albumentations>=1.3.0\", \"Albumentations\")\n",
    "\n",
    "# Install other dependencies\n",
    "install_package(\"einops>=0.6.0\", \"einops\")\n",
    "install_package(\"wandb>=0.15.0\", \"Weights & Biases\")\n",
    "\n",
    "# Install PyTorch Geometric (simplified for Python 3.9)\n",
    "print(\"Installing PyTorch Geometric...\")\n",
    "install_package(\"torch-geometric\", \"PyTorch Geometric\")\n",
    "\n",
    "# Try to install torch-scatter and torch-sparse (optional, may fail on some systems)\n",
    "print(\"Installing optional PyG dependencies (may fail, that's OK)...\")\n",
    "try:\n",
    "    subprocess.run(\n",
    "        [sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"torch-scatter\", \"torch-sparse\"],\n",
    "        timeout=300,\n",
    "        check=False  # Don't fail if this doesn't work\n",
    "    )\n",
    "    print(\"  âœ… torch-scatter and torch-sparse installed\")\n",
    "except:\n",
    "    print(\"  âš ï¸  torch-scatter/torch-sparse installation skipped (optional)\")\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"âœ… Core dependencies installed successfully!\")\n",
    "print(\"=\"*60)\n"
   ],
   "id": "fe2ac872aef6e882",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing dependencies for Sustainability AI Model (MacBook Local Training)...\n",
      "Python version: 3.9.6 (default, Dec  2 2025, 07:27:58) \n",
      "[Clang 17.0.0 (clang-1700.6.3.2)]\n",
      "============================================================\n",
      "Upgrading pip...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[33mWARNING: Ignoring invalid distribution -cipy (/Users/jiangshengbo/Library/Python/3.9/lib/python/site-packages)\u001B[0m\u001B[33m\n",
      "\u001B[0m\u001B[33mWARNING: Ignoring invalid distribution -cipy (/Users/jiangshengbo/Library/Python/3.9/lib/python/site-packages)\u001B[0m\u001B[33m\n",
      "\u001B[0m\u001B[33mWARNING: Ignoring invalid distribution -cipy (/Users/jiangshengbo/Library/Python/3.9/lib/python/site-packages)\u001B[0m\u001B[33m\n",
      "\u001B[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing Kaggle API...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[33mWARNING: Ignoring invalid distribution -cipy (/Users/jiangshengbo/Library/Python/3.9/lib/python/site-packages)\u001B[0m\u001B[33m\n",
      "\u001B[0m\u001B[33mWARNING: Ignoring invalid distribution -cipy (/Users/jiangshengbo/Library/Python/3.9/lib/python/site-packages)\u001B[0m\u001B[33m\n",
      "\u001B[0m\u001B[33mWARNING: Ignoring invalid distribution -cipy (/Users/jiangshengbo/Library/Python/3.9/lib/python/site-packages)\u001B[0m\u001B[33m\n",
      "\u001B[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ… Kaggle API\n",
      "Installing NumPy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[33mWARNING: Ignoring invalid distribution -cipy (/Users/jiangshengbo/Library/Python/3.9/lib/python/site-packages)\u001B[0m\u001B[33m\n",
      "\u001B[0m\u001B[33mWARNING: Ignoring invalid distribution -cipy (/Users/jiangshengbo/Library/Python/3.9/lib/python/site-packages)\u001B[0m\u001B[33m\n",
      "\u001B[0m\u001B[33m  WARNING: The script f2py is installed in '/Users/jiangshengbo/Library/Python/3.9/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001B[0m\u001B[33m\n",
      "\u001B[0m\u001B[33mWARNING: Ignoring invalid distribution -cipy (/Users/jiangshengbo/Library/Python/3.9/lib/python/site-packages)\u001B[0m\u001B[33m\n",
      "\u001B[0m\u001B[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "chromadb 1.1.0 requires tenacity>=8.2.3, but you have tenacity 8.2.0 which is incompatible.\n",
      "great-expectations 0.17.0 requires pydantic<2.0,>=1.9.2, but you have pydantic 2.12.3 which is incompatible.\n",
      "opencv-python-headless 4.13.0.90 requires numpy>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\u001B[0m\u001B[31m\n",
      "\u001B[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ… NumPy\n",
      "Installing SciPy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[33mWARNING: Ignoring invalid distribution -cipy (/Users/jiangshengbo/Library/Python/3.9/lib/python/site-packages)\u001B[0m\u001B[33m\n",
      "\u001B[0m\u001B[33mWARNING: Ignoring invalid distribution -cipy (/Users/jiangshengbo/Library/Python/3.9/lib/python/site-packages)\u001B[0m\u001B[33m\n",
      "\u001B[0m\u001B[33mWARNING: Ignoring invalid distribution -cipy (/Users/jiangshengbo/Library/Python/3.9/lib/python/site-packages)\u001B[0m\u001B[33m\n",
      "\u001B[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ… SciPy\n",
      "Installing Pillow...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[33mWARNING: Ignoring invalid distribution -cipy (/Users/jiangshengbo/Library/Python/3.9/lib/python/site-packages)\u001B[0m\u001B[33m\n",
      "\u001B[0m\u001B[33mWARNING: Ignoring invalid distribution -cipy (/Users/jiangshengbo/Library/Python/3.9/lib/python/site-packages)\u001B[0m\u001B[33m\n",
      "\u001B[0m\u001B[33mWARNING: Ignoring invalid distribution -cipy (/Users/jiangshengbo/Library/Python/3.9/lib/python/site-packages)\u001B[0m\u001B[33m\n",
      "\u001B[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ… Pillow\n",
      "Installing Pandas...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[33mWARNING: Ignoring invalid distribution -cipy (/Users/jiangshengbo/Library/Python/3.9/lib/python/site-packages)\u001B[0m\u001B[33m\n",
      "\u001B[0m\u001B[33mWARNING: Ignoring invalid distribution -cipy (/Users/jiangshengbo/Library/Python/3.9/lib/python/site-packages)\u001B[0m\u001B[33m\n",
      "\u001B[0m\u001B[33mWARNING: Ignoring invalid distribution -cipy (/Users/jiangshengbo/Library/Python/3.9/lib/python/site-packages)\u001B[0m\u001B[33m\n",
      "\u001B[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ… Pandas\n",
      "Installing scikit-learn...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[33mWARNING: Ignoring invalid distribution -cipy (/Users/jiangshengbo/Library/Python/3.9/lib/python/site-packages)\u001B[0m\u001B[33m\n",
      "\u001B[0m\u001B[33mWARNING: Ignoring invalid distribution -cipy (/Users/jiangshengbo/Library/Python/3.9/lib/python/site-packages)\u001B[0m\u001B[33m\n",
      "\u001B[0m\u001B[33mWARNING: Ignoring invalid distribution -cipy (/Users/jiangshengbo/Library/Python/3.9/lib/python/site-packages)\u001B[0m\u001B[33m\n",
      "\u001B[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ… scikit-learn\n",
      "Installing Matplotlib...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[33mWARNING: Ignoring invalid distribution -cipy (/Users/jiangshengbo/Library/Python/3.9/lib/python/site-packages)\u001B[0m\u001B[33m\n",
      "\u001B[0m\u001B[33mWARNING: Ignoring invalid distribution -cipy (/Users/jiangshengbo/Library/Python/3.9/lib/python/site-packages)\u001B[0m\u001B[33m\n",
      "\u001B[0m\u001B[33mWARNING: Ignoring invalid distribution -cipy (/Users/jiangshengbo/Library/Python/3.9/lib/python/site-packages)\u001B[0m\u001B[33m\n",
      "\u001B[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ… Matplotlib\n",
      "Installing Seaborn...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[33mWARNING: Ignoring invalid distribution -cipy (/Users/jiangshengbo/Library/Python/3.9/lib/python/site-packages)\u001B[0m\u001B[33m\n",
      "\u001B[0m\u001B[33mWARNING: Ignoring invalid distribution -cipy (/Users/jiangshengbo/Library/Python/3.9/lib/python/site-packages)\u001B[0m\u001B[33m\n",
      "\u001B[0m\u001B[33mWARNING: Ignoring invalid distribution -cipy (/Users/jiangshengbo/Library/Python/3.9/lib/python/site-packages)\u001B[0m\u001B[33m\n",
      "\u001B[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ… Seaborn\n",
      "Installing tqdm...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[33mWARNING: Ignoring invalid distribution -cipy (/Users/jiangshengbo/Library/Python/3.9/lib/python/site-packages)\u001B[0m\u001B[33m\n",
      "\u001B[0m\u001B[33mWARNING: Ignoring invalid distribution -cipy (/Users/jiangshengbo/Library/Python/3.9/lib/python/site-packages)\u001B[0m\u001B[33m\n",
      "\u001B[0m\u001B[33mWARNING: Ignoring invalid distribution -cipy (/Users/jiangshengbo/Library/Python/3.9/lib/python/site-packages)\u001B[0m\u001B[33m\n",
      "\u001B[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ… tqdm\n",
      "Checking PyTorch installation...\n",
      "  Current PyTorch: 2.8.0\n",
      "  Current torchvision: 0.23.0\n",
      "  âš ï¸  Major version mismatch! Reinstalling compatible versions...\n",
      "Found existing installation: torch 2.8.0\n",
      "Uninstalling torch-2.8.0:\n",
      "  Successfully uninstalled torch-2.8.0\n",
      "Found existing installation: torchvision 0.23.0\n",
      "Uninstalling torchvision-0.23.0:\n",
      "  Successfully uninstalled torchvision-0.23.0\n",
      "Installing PyTorch 2.0.1 + torchvision 0.15.2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[33mWARNING: Ignoring invalid distribution -cipy (/Users/jiangshengbo/Library/Python/3.9/lib/python/site-packages)\u001B[0m\u001B[33m\n",
      "\u001B[0m\u001B[33mWARNING: Ignoring invalid distribution -cipy (/Users/jiangshengbo/Library/Python/3.9/lib/python/site-packages)\u001B[0m\u001B[33m\n",
      "\u001B[0m\u001B[33m  WARNING: The scripts convert-caffe2-to-onnx, convert-onnx-to-caffe2 and torchrun are installed in '/Users/jiangshengbo/Library/Python/3.9/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001B[0m\u001B[33m\n",
      "\u001B[0m\u001B[33mWARNING: Ignoring invalid distribution -cipy (/Users/jiangshengbo/Library/Python/3.9/lib/python/site-packages)\u001B[0m\u001B[33m\n",
      "\u001B[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ… PyTorch 2.0.1 + torchvision 0.15.2\n",
      "Installing timm...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[33mWARNING: Ignoring invalid distribution -cipy (/Users/jiangshengbo/Library/Python/3.9/lib/python/site-packages)\u001B[0m\u001B[33m\n",
      "\u001B[0m\u001B[33mWARNING: Ignoring invalid distribution -cipy (/Users/jiangshengbo/Library/Python/3.9/lib/python/site-packages)\u001B[0m\u001B[33m\n",
      "\u001B[0m\u001B[33mWARNING: Ignoring invalid distribution -cipy (/Users/jiangshengbo/Library/Python/3.9/lib/python/site-packages)\u001B[0m\u001B[33m\n",
      "\u001B[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ… timm\n",
      "Installing Albumentations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[33mWARNING: Ignoring invalid distribution -cipy (/Users/jiangshengbo/Library/Python/3.9/lib/python/site-packages)\u001B[0m\u001B[33m\n",
      "\u001B[0m\u001B[33mWARNING: Ignoring invalid distribution -cipy (/Users/jiangshengbo/Library/Python/3.9/lib/python/site-packages)\u001B[0m\u001B[33m\n",
      "\u001B[0m\u001B[33m  WARNING: The scripts f2py and numpy-config are installed in '/Users/jiangshengbo/Library/Python/3.9/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001B[0m\u001B[33m\n",
      "\u001B[0m\u001B[33mWARNING: Ignoring invalid distribution -cipy (/Users/jiangshengbo/Library/Python/3.9/lib/python/site-packages)\u001B[0m\u001B[33m\n",
      "\u001B[0m\u001B[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "chromadb 1.1.0 requires tenacity>=8.2.3, but you have tenacity 8.2.0 which is incompatible.\n",
      "great-expectations 0.17.0 requires pydantic<2.0,>=1.9.2, but you have pydantic 2.12.3 which is incompatible.\u001B[0m\u001B[31m\n",
      "\u001B[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ… Albumentations\n",
      "Installing einops...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[33mWARNING: Ignoring invalid distribution -cipy (/Users/jiangshengbo/Library/Python/3.9/lib/python/site-packages)\u001B[0m\u001B[33m\n",
      "\u001B[0m\u001B[33mWARNING: Ignoring invalid distribution -cipy (/Users/jiangshengbo/Library/Python/3.9/lib/python/site-packages)\u001B[0m\u001B[33m\n",
      "\u001B[0m\u001B[33mWARNING: Ignoring invalid distribution -cipy (/Users/jiangshengbo/Library/Python/3.9/lib/python/site-packages)\u001B[0m\u001B[33m\n",
      "\u001B[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ… einops\n",
      "Installing Weights & Biases...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[33mWARNING: Ignoring invalid distribution -cipy (/Users/jiangshengbo/Library/Python/3.9/lib/python/site-packages)\u001B[0m\u001B[33m\n",
      "\u001B[0m\u001B[33mWARNING: Ignoring invalid distribution -cipy (/Users/jiangshengbo/Library/Python/3.9/lib/python/site-packages)\u001B[0m\u001B[33m\n",
      "\u001B[0m\u001B[33mWARNING: Ignoring invalid distribution -cipy (/Users/jiangshengbo/Library/Python/3.9/lib/python/site-packages)\u001B[0m\u001B[33m\n",
      "\u001B[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ… Weights & Biases\n",
      "Installing PyTorch Geometric...\n",
      "Installing PyTorch Geometric...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[33mWARNING: Ignoring invalid distribution -cipy (/Users/jiangshengbo/Library/Python/3.9/lib/python/site-packages)\u001B[0m\u001B[33m\n",
      "\u001B[0m\u001B[33mWARNING: Ignoring invalid distribution -cipy (/Users/jiangshengbo/Library/Python/3.9/lib/python/site-packages)\u001B[0m\u001B[33m\n",
      "\u001B[0m\u001B[33mWARNING: Ignoring invalid distribution -cipy (/Users/jiangshengbo/Library/Python/3.9/lib/python/site-packages)\u001B[0m\u001B[33m\n",
      "\u001B[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ… PyTorch Geometric\n",
      "Installing optional PyG dependencies (may fail, that's OK)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[33mWARNING: Ignoring invalid distribution -cipy (/Users/jiangshengbo/Library/Python/3.9/lib/python/site-packages)\u001B[0m\u001B[33m\n",
      "\u001B[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ… torch-scatter and torch-sparse installed\n",
      "============================================================\n",
      "âœ… Core dependencies installed successfully!\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  \u001B[1;31merror\u001B[0m: \u001B[1msubprocess-exited-with-error\u001B[0m\n",
      "  \n",
      "  \u001B[31mÃ—\u001B[0m \u001B[32mGetting requirements to build wheel\u001B[0m did not run successfully.\n",
      "  \u001B[31mâ”‚\u001B[0m exit code: \u001B[1;36m1\u001B[0m\n",
      "  \u001B[31mâ•°â”€>\u001B[0m \u001B[31m[17 lines of output]\u001B[0m\n",
      "  \u001B[31m   \u001B[0m Traceback (most recent call last):\n",
      "  \u001B[31m   \u001B[0m   File \"/Users/jiangshengbo/Library/Python/3.9/lib/python/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\", line 389, in <module>\n",
      "  \u001B[31m   \u001B[0m     main()\n",
      "  \u001B[31m   \u001B[0m   File \"/Users/jiangshengbo/Library/Python/3.9/lib/python/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\", line 373, in main\n",
      "  \u001B[31m   \u001B[0m     json_out[\"return_val\"] = hook(**hook_input[\"kwargs\"])\n",
      "  \u001B[31m   \u001B[0m   File \"/Users/jiangshengbo/Library/Python/3.9/lib/python/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\", line 143, in get_requires_for_build_wheel\n",
      "  \u001B[31m   \u001B[0m     return hook(config_settings)\n",
      "  \u001B[31m   \u001B[0m   File \"/private/var/folders/y0/l9ns18ns5472mqrprmhhmsw00000gn/T/pip-build-env-5rs_81pj/overlay/lib/python3.9/site-packages/setuptools/build_meta.py\", line 333, in get_requires_for_build_wheel\n",
      "  \u001B[31m   \u001B[0m     return self._get_build_requires(config_settings, requirements=[])\n",
      "  \u001B[31m   \u001B[0m   File \"/private/var/folders/y0/l9ns18ns5472mqrprmhhmsw00000gn/T/pip-build-env-5rs_81pj/overlay/lib/python3.9/site-packages/setuptools/build_meta.py\", line 301, in _get_build_requires\n",
      "  \u001B[31m   \u001B[0m     self.run_setup()\n",
      "  \u001B[31m   \u001B[0m   File \"/private/var/folders/y0/l9ns18ns5472mqrprmhhmsw00000gn/T/pip-build-env-5rs_81pj/overlay/lib/python3.9/site-packages/setuptools/build_meta.py\", line 518, in run_setup\n",
      "  \u001B[31m   \u001B[0m     super().run_setup(setup_script=setup_script)\n",
      "  \u001B[31m   \u001B[0m   File \"/private/var/folders/y0/l9ns18ns5472mqrprmhhmsw00000gn/T/pip-build-env-5rs_81pj/overlay/lib/python3.9/site-packages/setuptools/build_meta.py\", line 317, in run_setup\n",
      "  \u001B[31m   \u001B[0m     exec(code, locals())\n",
      "  \u001B[31m   \u001B[0m   File \"<string>\", line 8, in <module>\n",
      "  \u001B[31m   \u001B[0m ModuleNotFoundError: No module named 'torch'\n",
      "  \u001B[31m   \u001B[0m \u001B[31m[end of output]\u001B[0m\n",
      "  \n",
      "  \u001B[1;35mnote\u001B[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001B[31mERROR: Failed to build 'torch-scatter' when getting requirements to build wheel\u001B[0m\u001B[31m\n",
      "\u001B[0m"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-23T20:11:07.638184Z",
     "start_time": "2026-01-23T20:11:07.449989Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# KAGGLE API SETUP AND DATASET DOWNLOAD\n",
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "import zipfile\n",
    "import shutil\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"ðŸ”‘ CONFIGURING KAGGLE API\")\n",
    "print(\"=\"*80)\n",
    "print()\n",
    "\n",
    "# ============================================================================\n",
    "# IMPORTANT: ENTER YOUR KAGGLE CREDENTIALS HERE\n",
    "# ============================================================================\n",
    "#\n",
    "# To find your Kaggle username and API key:\n",
    "# 1. Go to https://www.kaggle.com/\n",
    "# 2. Click on your profile picture (top right)\n",
    "# 3. Click \"Settings\"\n",
    "# 4. Scroll down to \"API\" section\n",
    "# 5. Click \"Create New Token\" (downloads kaggle.json)\n",
    "# 6. Open kaggle.json and copy the username and key below\n",
    "#\n",
    "# ============================================================================\n",
    "\n",
    "KAGGLE_USERNAME = \"michealjiang\"  # Your Kaggle username\n",
    "KAGGLE_KEY = \"92ce58a4cc3d98ed20dca81b8598123f\"  # Your Kaggle API key\n",
    "\n",
    "# Alternative: If you already have kaggle.json, we can read it\n",
    "kaggle_json_path = Path.home() / \".kaggle\" / \"kaggle.json\"\n",
    "if kaggle_json_path.exists():\n",
    "    print(\"ðŸ“„ Found existing kaggle.json, loading credentials...\")\n",
    "    with open(kaggle_json_path, 'r') as f:\n",
    "        existing_creds = json.load(f)\n",
    "        KAGGLE_USERNAME = existing_creds.get(\"username\", KAGGLE_USERNAME)\n",
    "        KAGGLE_KEY = existing_creds.get(\"key\", KAGGLE_KEY)\n",
    "    print(f\"   âœ… Loaded username: {KAGGLE_USERNAME}\")\n",
    "else:\n",
    "    print(\"ðŸ“ No existing kaggle.json found, using credentials from above...\")\n",
    "\n",
    "# Validate credentials\n",
    "if KAGGLE_USERNAME == \"YOUR_KAGGLE_USERNAME\" or KAGGLE_KEY == \"YOUR_KAGGLE_API_KEY\":\n",
    "    print()\n",
    "    print(\"=\"*80)\n",
    "    print(\"âš ï¸  ERROR: KAGGLE CREDENTIALS NOT SET!\")\n",
    "    print(\"=\"*80)\n",
    "    print()\n",
    "    print(\"Please follow these steps:\")\n",
    "    print()\n",
    "    print(\"1. Go to: https://www.kaggle.com/settings\")\n",
    "    print(\"2. Scroll to 'API' section\")\n",
    "    print(\"3. Click 'Create New Token'\")\n",
    "    print(\"4. This downloads 'kaggle.json' to your Downloads folder\")\n",
    "    print(\"5. Open kaggle.json and you'll see:\")\n",
    "    print('   {\"username\":\"your_username\",\"key\":\"your_api_key\"}')\n",
    "    print()\n",
    "    print(\"6. Copy those values and paste them in the cell above:\")\n",
    "    print('   KAGGLE_USERNAME = \"your_username\"')\n",
    "    print('   KAGGLE_KEY = \"your_api_key\"')\n",
    "    print()\n",
    "    print(\"7. Re-run this cell\")\n",
    "    print()\n",
    "    print(\"=\"*80)\n",
    "    raise ValueError(\"Kaggle credentials not configured. Please set KAGGLE_USERNAME and KAGGLE_KEY above.\")\n",
    "\n",
    "print()\n",
    "\n",
    "# Create ~/.kaggle directory if it doesn't exist\n",
    "kaggle_dir = Path.home() / \".kaggle\"\n",
    "kaggle_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Create kaggle.json with credentials\n",
    "kaggle_json_path = kaggle_dir / \"kaggle.json\"\n",
    "kaggle_credentials = {\n",
    "    \"username\": KAGGLE_USERNAME,\n",
    "    \"key\": KAGGLE_KEY\n",
    "}\n",
    "\n",
    "# Write credentials to file\n",
    "with open(kaggle_json_path, 'w') as f:\n",
    "    json.dump(kaggle_credentials, f, indent=2)\n",
    "\n",
    "# Set proper permissions (required by Kaggle API on Unix systems)\n",
    "try:\n",
    "    os.chmod(kaggle_json_path, 0o600)\n",
    "except:\n",
    "    pass  # Windows doesn't support chmod\n",
    "\n",
    "print(f\"âœ… Kaggle credentials saved to: {kaggle_json_path}\")\n",
    "print(f\"   Username: {KAGGLE_USERNAME}\")\n",
    "print(f\"   Key: {KAGGLE_KEY[:10]}...{KAGGLE_KEY[-4:]}\")\n",
    "print()\n",
    "print(\"=\"*80)\n",
    "print()\n",
    "\n",
    "# Kaggle datasets to download\n",
    "KAGGLE_DATASETS = [\n",
    "    {\"slug\": \"sumn2u/garbage-classification-v2\", \"name\": \"garbage-classification-v2\"},\n",
    "    {\"slug\": \"zlatan599/garbage-dataset-classification\", \"name\": \"garbage-dataset-classification\"},\n",
    "    {\"slug\": \"parohod/warp-waste-recycling-plant-dataset\", \"name\": \"warp-waste-recycling-plant-dataset\"},\n",
    "    {\"slug\": \"asdasdasasdas/garbage-classification\", \"name\": \"garbage-classification\"},\n",
    "    {\"slug\": \"techsash/waste-classification-data\", \"name\": \"waste-classification-data\"},\n",
    "    {\"slug\": \"alistairking/recyclable-and-household-waste-classification\", \"name\": \"recyclable-and-household-waste-classification\"},\n",
    "    {\"slug\": \"vishallazrus/multi-class-garbage-classification-dataset\", \"name\": \"multi-class-garbage-classification-dataset\"},\n",
    "    {\"slug\": \"mostafaabla/garbage-classification\", \"name\": \"garbage-classification-mostafa\"}\n",
    "]\n",
    "\n",
    "def download_kaggle_datasets(datasets, base_dir=\"./data/kaggle\"):\n",
    "    \"\"\"\n",
    "    Download Kaggle datasets using the Kaggle Python API (not CLI).\n",
    "\n",
    "    Args:\n",
    "        datasets: List of dataset dictionaries with 'slug' and 'name'\n",
    "        base_dir: Base directory to store downloaded datasets\n",
    "    \"\"\"\n",
    "    import sys\n",
    "    import time\n",
    "\n",
    "    base_path = Path(base_dir)\n",
    "    base_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    print(\"=\"*80)\n",
    "    print(\"ðŸ“¦ KAGGLE DATASET DOWNLOAD\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    # Import Kaggle API\n",
    "    try:\n",
    "        from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "        api = KaggleApi()\n",
    "        api.authenticate()\n",
    "        print(\"âœ… Kaggle API authenticated successfully!\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Failed to authenticate Kaggle API: {e}\")\n",
    "        print(\"\\nPlease ensure:\")\n",
    "        print(\"1. You have a Kaggle account\")\n",
    "        print(\"2. Your username is correct in the cell above\")\n",
    "        print(\"3. Your API key is correct\")\n",
    "        return [], datasets\n",
    "\n",
    "    print()\n",
    "\n",
    "    downloaded = []\n",
    "    failed = []\n",
    "\n",
    "    for idx, dataset in enumerate(datasets, 1):\n",
    "        dataset_slug = dataset[\"slug\"]\n",
    "        dataset_name = dataset[\"name\"]\n",
    "        dataset_path = base_path / dataset_name\n",
    "\n",
    "        print(f\"\\n[{idx}/{len(datasets)}] {dataset_name}\")\n",
    "        print(f\"      Source: {dataset_slug}\")\n",
    "\n",
    "        # Check if already downloaded\n",
    "        if dataset_path.exists() and any(dataset_path.iterdir()):\n",
    "            print(f\"      âœ… Already downloaded, skipping...\")\n",
    "            downloaded.append(dataset_name)\n",
    "            continue\n",
    "\n",
    "        print(f\"      ðŸ“¥ Downloading...\", end=\"\", flush=True)\n",
    "\n",
    "        try:\n",
    "            # Create dataset directory\n",
    "            dataset_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "            start_time = time.time()\n",
    "\n",
    "            # Download using Kaggle Python API with quiet mode\n",
    "            # This prevents blocking output\n",
    "            api.dataset_download_files(\n",
    "                dataset_slug,\n",
    "                path=str(dataset_path),\n",
    "                unzip=True,\n",
    "                quiet=True  # Changed to True to prevent blocking\n",
    "            )\n",
    "\n",
    "            elapsed = time.time() - start_time\n",
    "\n",
    "            # Verify download\n",
    "            if dataset_path.exists() and any(dataset_path.iterdir()):\n",
    "                print(f\" âœ… Done! ({elapsed:.1f}s)\")\n",
    "                downloaded.append(dataset_name)\n",
    "            else:\n",
    "                print(f\" âŒ Failed (no files found)\")\n",
    "                failed.append(dataset_name)\n",
    "\n",
    "        except KeyboardInterrupt:\n",
    "            print(f\"\\n\\nâš ï¸  Download interrupted by user!\")\n",
    "            print(f\"   Downloaded so far: {len(downloaded)}/{len(datasets)}\")\n",
    "            return downloaded, failed + [d[\"name\"] for d in datasets[idx-1:]]\n",
    "\n",
    "        except Exception as e:\n",
    "            error_msg = str(e)\n",
    "            # Shorten long error messages\n",
    "            if len(error_msg) > 100:\n",
    "                error_msg = error_msg[:100] + \"...\"\n",
    "            print(f\" âŒ Error: {error_msg}\")\n",
    "            failed.append(dataset_name)\n",
    "\n",
    "            # Clean up partial download\n",
    "            if dataset_path.exists():\n",
    "                try:\n",
    "                    shutil.rmtree(dataset_path)\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "        # Flush output to ensure it's displayed\n",
    "        sys.stdout.flush()\n",
    "\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"ðŸ“Š DOWNLOAD SUMMARY\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"âœ… Successfully downloaded: {len(downloaded)}/{len(datasets)}\")\n",
    "    print(f\"âŒ Failed: {len(failed)}/{len(datasets)}\")\n",
    "\n",
    "    if downloaded:\n",
    "        print(f\"\\nâœ… Downloaded datasets:\")\n",
    "        for name in downloaded:\n",
    "            print(f\"   âœ“ {name}\")\n",
    "\n",
    "    if failed:\n",
    "        print(f\"\\nâš ï¸  Failed datasets:\")\n",
    "        for name in failed:\n",
    "            print(f\"   âœ— {name}\")\n",
    "\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    return downloaded, failed\n",
    "\n",
    "# Download all datasets\n",
    "print(\"Starting Kaggle dataset downloads...\")\n",
    "print(\"This may take 10-30 minutes depending on your internet connection.\")\n",
    "print(\"ðŸ’¡ TIP: If a download seems stuck, press Ctrl+C to skip and continue with next dataset\")\n",
    "print()\n",
    "\n",
    "try:\n",
    "    downloaded, failed = download_kaggle_datasets(KAGGLE_DATASETS)\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\n\\nâš ï¸  Download process interrupted!\")\n",
    "    print(\"You can continue with the datasets that were successfully downloaded.\")\n",
    "    downloaded, failed = [], []\n",
    "\n",
    "if len(downloaded) == 0:\n",
    "    print(\"\\nâš ï¸  WARNING: No datasets were downloaded!\")\n",
    "    print(\"Please check your Kaggle API token and internet connection.\")\n",
    "    print(\"\\nðŸ’¡ You can still continue with the notebook - we'll use sample data for testing.\")\n",
    "else:\n",
    "    print(f\"\\nâœ… Ready to proceed with {len(downloaded)} datasets!\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ðŸ“ NOTE: Cell execution complete! You can now proceed to the next cell.\")\n",
    "print(\"=\"*80)\n",
    "\n"
   ],
   "id": "1dbe1ddf569fd3f0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ðŸ”‘ CONFIGURING KAGGLE API\n",
      "================================================================================\n",
      "\n",
      "ðŸ“„ Found existing kaggle.json, loading credentials...\n",
      "   âœ… Loaded username: michealjiang\n",
      "\n",
      "âœ… Kaggle credentials saved to: /Users/jiangshengbo/.kaggle/kaggle.json\n",
      "   Username: michealjiang\n",
      "   Key: 92ce58a4cc...123f\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Starting Kaggle dataset downloads...\n",
      "This may take 10-30 minutes depending on your internet connection.\n",
      "ðŸ’¡ TIP: If a download seems stuck, press Ctrl+C to skip and continue with next dataset\n",
      "\n",
      "================================================================================\n",
      "ðŸ“¦ KAGGLE DATASET DOWNLOAD\n",
      "================================================================================\n",
      "âœ… Kaggle API authenticated successfully!\n",
      "\n",
      "\n",
      "[1/8] garbage-classification-v2\n",
      "      Source: sumn2u/garbage-classification-v2\n",
      "      âœ… Already downloaded, skipping...\n",
      "\n",
      "[2/8] garbage-dataset-classification\n",
      "      Source: zlatan599/garbage-dataset-classification\n",
      "      âœ… Already downloaded, skipping...\n",
      "\n",
      "[3/8] warp-waste-recycling-plant-dataset\n",
      "      Source: parohod/warp-waste-recycling-plant-dataset\n",
      "      âœ… Already downloaded, skipping...\n",
      "\n",
      "[4/8] garbage-classification\n",
      "      Source: asdasdasasdas/garbage-classification\n",
      "      âœ… Already downloaded, skipping...\n",
      "\n",
      "[5/8] waste-classification-data\n",
      "      Source: techsash/waste-classification-data\n",
      "      âœ… Already downloaded, skipping...\n",
      "\n",
      "[6/8] recyclable-and-household-waste-classification\n",
      "      Source: alistairking/recyclable-and-household-waste-classification\n",
      "      âœ… Already downloaded, skipping...\n",
      "\n",
      "[7/8] multi-class-garbage-classification-dataset\n",
      "      Source: vishallazrus/multi-class-garbage-classification-dataset\n",
      "      âœ… Already downloaded, skipping...\n",
      "\n",
      "[8/8] garbage-classification-mostafa\n",
      "      Source: mostafaabla/garbage-classification\n",
      "      âœ… Already downloaded, skipping...\n",
      "\n",
      "================================================================================\n",
      "ðŸ“Š DOWNLOAD SUMMARY\n",
      "================================================================================\n",
      "âœ… Successfully downloaded: 8/8\n",
      "âŒ Failed: 0/8\n",
      "\n",
      "âœ… Downloaded datasets:\n",
      "   âœ“ garbage-classification-v2\n",
      "   âœ“ garbage-dataset-classification\n",
      "   âœ“ warp-waste-recycling-plant-dataset\n",
      "   âœ“ garbage-classification\n",
      "   âœ“ waste-classification-data\n",
      "   âœ“ recyclable-and-household-waste-classification\n",
      "   âœ“ multi-class-garbage-classification-dataset\n",
      "   âœ“ garbage-classification-mostafa\n",
      "================================================================================\n",
      "\n",
      "âœ… Ready to proceed with 8 datasets!\n",
      "\n",
      "================================================================================\n",
      "ðŸ“ NOTE: Cell execution complete! You can now proceed to the next cell.\n",
      "================================================================================\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-23T20:11:10.985462Z",
     "start_time": "2026-01-23T20:11:07.654280Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import random\n",
    "import logging\n",
    "import time\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple, Optional, Any\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "\n",
    "import timm\n",
    "from timm.data import create_transform, resolve_data_config\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GATv2Conv\n",
    "from tqdm.notebook import tqdm\n",
    "import wandb\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from sklearn.metrics import classification_report, confusion_matrix, precision_recall_fscore_support\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ],
   "id": "af610a383c091269",
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'scipy._lib'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[3], line 29\u001B[0m\n\u001B[1;32m     27\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtqdm\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mnotebook\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m tqdm\n\u001B[1;32m     28\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mwandb\u001B[39;00m\n\u001B[0;32m---> 29\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01malbumentations\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mA\u001B[39;00m\n\u001B[1;32m     30\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01malbumentations\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpytorch\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m ToTensorV2\n\u001B[1;32m     31\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01msklearn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmetrics\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m classification_report, confusion_matrix, precision_recall_fscore_support\n",
      "File \u001B[0;32m~/Library/Python/3.9/lib/python/site-packages/albumentations/__init__.py:18\u001B[0m\n\u001B[1;32m     14\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mcontextlib\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m suppress\n\u001B[1;32m     16\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01malbumentations\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcheck_version\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m check_for_updates\n\u001B[0;32m---> 18\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01maugmentations\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;241m*\u001B[39m\n\u001B[1;32m     19\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcore\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcomposition\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;241m*\u001B[39m\n\u001B[1;32m     20\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcore\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mserialization\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;241m*\u001B[39m\n",
      "File \u001B[0;32m~/Library/Python/3.9/lib/python/site-packages/albumentations/augmentations/__init__.py:19\u001B[0m\n\u001B[1;32m     17\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mother\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mlambda_transform\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;241m*\u001B[39m\n\u001B[1;32m     18\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mother\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtype_transform\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;241m*\u001B[39m\n\u001B[0;32m---> 19\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpixel\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtransforms\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;241m*\u001B[39m\n\u001B[1;32m     20\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mspectrogram\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtransform\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;241m*\u001B[39m\n\u001B[1;32m     21\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtext\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtransforms\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;241m*\u001B[39m\n",
      "File \u001B[0;32m~/Library/Python/3.9/lib/python/site-packages/albumentations/augmentations/pixel/transforms.py:39\u001B[0m\n\u001B[1;32m     19\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01malbucore\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[1;32m     20\u001B[0m     MAX_VALUES_BY_DTYPE,\n\u001B[1;32m     21\u001B[0m     NUM_MULTI_CHANNEL_DIMENSIONS,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     28\u001B[0m     normalize_per_image,\n\u001B[1;32m     29\u001B[0m )\n\u001B[1;32m     30\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mpydantic\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[1;32m     31\u001B[0m     AfterValidator,\n\u001B[1;32m     32\u001B[0m     BaseModel,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     37\u001B[0m     model_validator,\n\u001B[1;32m     38\u001B[0m )\n\u001B[0;32m---> 39\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mscipy\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m special\n\u001B[1;32m     40\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtyping_extensions\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m Literal, Self\n\u001B[1;32m     42\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01malbumentations\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01maugmentations\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mgeometric\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfunctional\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mfgeometric\u001B[39;00m\n",
      "File \u001B[0;32m~/Library/Python/3.9/lib/python/site-packages/scipy/__init__.py:67\u001B[0m\n\u001B[1;32m     63\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m _distributor_init\n\u001B[1;32m     64\u001B[0m \u001B[38;5;28;01mdel\u001B[39;00m _distributor_init\n\u001B[0;32m---> 67\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mscipy\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_lib\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m _pep440\n\u001B[1;32m     68\u001B[0m \u001B[38;5;66;03m# In maintenance branch, change to np_maxversion N+3 if numpy is at N\u001B[39;00m\n\u001B[1;32m     69\u001B[0m np_minversion \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m1.22.4\u001B[39m\u001B[38;5;124m'\u001B[39m\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'scipy._lib'"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-23T20:11:10.997404Z",
     "start_time": "2026-01-21T23:41:22.127995Z"
    }
   },
   "source": [
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def set_seed(seed: int = 42):\n",
    "    \"\"\"Set random seed for reproducibility across all frameworks.\"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "    elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
    "        # MPS doesn't need special seeding\n",
    "        pass\n",
    "    logger.info(f\"âœ“ Random seed set to {seed}\")\n",
    "\n",
    "def get_device():\n",
    "    \"\"\"\n",
    "    Detect and return the best available device for training.\n",
    "    Priority: CUDA > MPS (Apple Silicon) > CPU\n",
    "    \"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda\")\n",
    "        logger.info(f\"ðŸš€ Using CUDA GPU: {torch.cuda.get_device_name(0)}\")\n",
    "        logger.info(f\"   Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "        return device\n",
    "    elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
    "        device = torch.device(\"mps\")\n",
    "        logger.info(f\"ðŸŽ Using Apple Silicon MPS (Metal Performance Shaders)\")\n",
    "        logger.info(f\"   Optimized for M1/M2/M3 chips\")\n",
    "        return device\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "        logger.info(f\"ðŸ’» Using CPU (no GPU acceleration available)\")\n",
    "        logger.info(f\"   âš ï¸  Training will be slower on CPU\")\n",
    "        return device\n",
    "\n",
    "def optimize_memory(device):\n",
    "    \"\"\"\n",
    "    Memory optimization for different hardware backends.\n",
    "    Supports CUDA, MPS (Apple Silicon), and CPU.\n",
    "    \"\"\"\n",
    "    if device.type == \"cuda\":\n",
    "        # CUDA GPU optimization\n",
    "        torch.cuda.empty_cache()\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "\n",
    "        # TF32 support (only in PyTorch 1.7+)\n",
    "        try:\n",
    "            torch.backends.cuda.matmul.allow_tf32 = True\n",
    "            torch.backends.cudnn.allow_tf32 = True\n",
    "        except AttributeError:\n",
    "            pass  # Older PyTorch versions don't have TF32 support\n",
    "\n",
    "        import os\n",
    "        os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True,max_split_size_mb:512'\n",
    "\n",
    "        try:\n",
    "            torch.cuda.set_per_process_memory_fraction(0.95)\n",
    "        except AttributeError:\n",
    "            pass  # Older PyTorch versions don't have this method\n",
    "\n",
    "        logger.info(\"âœ“ CUDA memory optimization enabled\")\n",
    "\n",
    "    elif device.type == \"mps\":\n",
    "        # MPS (Apple Silicon) optimization\n",
    "        # MPS doesn't have explicit memory management like CUDA\n",
    "        # But we can set environment variables for better performance\n",
    "        import os\n",
    "        os.environ['PYTORCH_MPS_HIGH_WATERMARK_RATIO'] = '0.0'  # Disable memory caching\n",
    "\n",
    "        logger.info(\"âœ“ MPS optimization enabled\")\n",
    "        logger.info(\"  - High watermark ratio: 0.0 (aggressive memory release)\")\n",
    "\n",
    "    else:\n",
    "        # CPU optimization\n",
    "        # Set number of threads for CPU training\n",
    "        import os\n",
    "        num_threads = os.cpu_count() or 4\n",
    "        torch.set_num_threads(num_threads)\n",
    "\n",
    "        logger.info(f\"âœ“ CPU optimization enabled\")\n",
    "        logger.info(f\"  - Using {num_threads} threads\")\n",
    "\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=15, mode=\"max\", delta=0):\n",
    "        self.patience = patience\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.mode = mode\n",
    "        self.delta = delta\n",
    "\n",
    "    def __call__(self, current_score):\n",
    "        if self.best_score is None:\n",
    "            self.best_score = current_score\n",
    "        elif self.mode == \"max\":\n",
    "            if current_score <= self.best_score + self.delta:\n",
    "                self.counter += 1\n",
    "                if self.counter >= self.patience:\n",
    "                    self.early_stop = True\n",
    "            else:\n",
    "                self.best_score = current_score\n",
    "                self.counter = 0\n",
    "        return self.early_stop"
   ],
   "id": "e37d70388c34be67",
   "outputs": [],
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_CLASSES = [\n",
    "    'aerosol_cans', 'aluminum_food_cans', 'aluminum_soda_cans', 'cardboard_boxes', 'cardboard_packaging',\n",
    "    'clothing', 'coffee_grounds', 'disposable_plastic_cutlery', 'egg_shells', 'food_waste',\n",
    "    'glass_beverage_bottles', 'glass_cosmetic_containers', 'glass_food_jars', 'magazines',\n",
    "    'newspaper', 'office_paper', 'paper_cups', 'plastic_cup_lids', 'plastic_detergent_bottles',\n",
    "    'plastic_food_containers', 'plastic_shopping_bags', 'plastic_soda_bottles', 'plastic_straws',\n",
    "    'plastic_trash_bags', 'plastic_water_bottles', 'shoes', 'steel_food_cans', 'styrofoam_cups',\n",
    "    'styrofoam_food_containers', 'tea_bags'\n",
    "]\n",
    "\n",
    "VISION_CONFIG = {\n",
    "    \"model\": {\n",
    "        \"backbone\": \"eva02_large_patch14_448.mim_m38m_ft_in22k_in1k\",\n",
    "        \"pretrained\": True,\n",
    "        \"num_classes\": 30,\n",
    "        \"drop_rate\": 0.3,\n",
    "        \"drop_path_rate\": 0.2\n",
    "    },\n",
    "    \"data\": {\n",
    "        \"input_size\": 224,  # Reduced from 448 for Mac CPU/MPS training\n",
    "        \"num_workers\": 2,  # Mac can handle 2 workers\n",
    "        \"pin_memory\": False,  # Not needed for CPU/MPS\n",
    "        \"sources\": [\n",
    "            {\n",
    "                \"name\": \"master_30\",\n",
    "                \"path\": \"./data/kaggle/recyclable-and-household-waste-classification/images\",\n",
    "                \"type\": \"master\"\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"garbage_12\",\n",
    "                \"path\": \"./data/kaggle/garbage-classification-mostafa/garbage_classification\",\n",
    "                \"type\": \"mapped_12\"\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"waste_22k\",\n",
    "                \"path\": \"./data/kaggle/waste-classification-data/DATASET\",\n",
    "                \"type\": \"mapped_2\"\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"garbage_v2_10\",\n",
    "                \"path\": \"./data/kaggle/garbage-classification-v2\",\n",
    "                \"type\": \"mapped_10\"\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"garbage_6\",\n",
    "                \"path\": \"./data/kaggle/garbage-classification\",\n",
    "                \"type\": \"mapped_6\"\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"garbage_balanced\",\n",
    "                \"path\": \"./data/kaggle/garbage-dataset-classification\",\n",
    "                \"type\": \"mapped_6\"\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"warp_industrial\",\n",
    "                \"path\": \"./data/kaggle/warp-waste-recycling-plant-dataset\",\n",
    "                \"type\": \"industrial\"\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"multiclass_garbage\",\n",
    "                \"path\": \"./data/kaggle/multi-class-garbage-classification-dataset\",\n",
    "                \"type\": \"multiclass\"\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    \"training\": {\n",
    "        \"batch_size\": 4,  # Optimized for Mac: smaller images (224) allow larger batch\n",
    "        \"grad_accum_steps\": 16,  # Maintains effective batch size of 64 (4 Ã— 16)\n",
    "        \"learning_rate\": 5e-5,\n",
    "        \"weight_decay\": 0.05,\n",
    "        \"num_epochs\": 20,\n",
    "        \"patience\": 5,\n",
    "        \"use_amp\": False,  # AMP not supported on MPS/CPU\n",
    "        \"max_grad_norm\": 1.0  # Gradient clipping for stability\n",
    "    }\n",
    "}"
   ],
   "id": "e85800f6504ff2e9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnifiedWasteDataset(Dataset):\n",
    "    \"\"\"\n",
    "    A unified dataset that ingests data from multiple sources and maps them\n",
    "    to a single 30-class target schema.\n",
    "    \"\"\"\n",
    "    def __init__(self, sources_config, target_classes, transform=None):\n",
    "        self.transform = transform\n",
    "        self.target_classes = sorted(target_classes)\n",
    "        self.class_to_idx = {c: i for i, c in enumerate(self.target_classes)}\n",
    "        self.samples = []\n",
    "\n",
    "        self.skipped_count = 0\n",
    "        self.skipped_labels = {}  # Track what labels are being skipped\n",
    "\n",
    "        total_added = 0\n",
    "        total_skipped = 0\n",
    "\n",
    "        for source in sources_config:\n",
    "            added, skipped = self._ingest_source(source)\n",
    "            total_added += added\n",
    "            total_skipped += skipped\n",
    "\n",
    "        logger.info(f\"=\"*60)\n",
    "        logger.info(f\"ðŸ“Š Dataset Summary:\")\n",
    "        logger.info(f\"  âœ“ Total images loaded: {len(self.samples)}\")\n",
    "        logger.info(f\"  âœ“ Images added: {total_added}\")\n",
    "        logger.info(f\"  âš  Images skipped: {total_skipped}\")\n",
    "        logger.info(f\"  ðŸ“ˆ Utilization: {100*total_added/(total_added+total_skipped) if (total_added+total_skipped) > 0 else 0:.1f}%\")\n",
    "        logger.info(f\"=\"*60)\n",
    "\n",
    "        # Log skipped labels for debugging (top 10 only)\n",
    "        if self.skipped_labels:\n",
    "            logger.warning(f\"âš  Top 10 skipped labels:\")\n",
    "            for label, count in sorted(self.skipped_labels.items(), key=lambda x: x[1], reverse=True)[:10]:\n",
    "                logger.warning(f\"  '{label}': {count} images\")\n",
    "\n",
    "        # Validate we have enough data\n",
    "        if len(self.samples) == 0:\n",
    "            raise ValueError(\n",
    "                \"âŒ No images loaded! Please check:\\n\"\n",
    "                \"  1. Dataset paths are correct\\n\"\n",
    "                \"  2. Datasets are attached in Kaggle\\n\"\n",
    "                \"  3. Label mappings are configured correctly\"\n",
    "            )\n",
    "\n",
    "        if len(self.samples) < 100:\n",
    "            logger.warning(f\"âš  Very few images loaded ({len(self.samples)}). Training may not be effective.\")\n",
    "\n",
    "    def _ingest_source(self, source):\n",
    "        \"\"\"\n",
    "        Ingest images from a data source with robust error handling.\n",
    "        Returns: (images_added, images_skipped) tuple\n",
    "        \"\"\"\n",
    "        path = Path(source[\"path\"])\n",
    "        images_added = 0\n",
    "        images_skipped = 0\n",
    "\n",
    "        if not path.exists():\n",
    "            parent = path.parent\n",
    "            found = False\n",
    "            if parent.exists():\n",
    "                for child in parent.iterdir():\n",
    "                    if child.is_dir():\n",
    "                        try:\n",
    "                            if any(child.iterdir()):\n",
    "                                path = child\n",
    "                                found = True\n",
    "                                break\n",
    "                        except PermissionError:\n",
    "                            continue\n",
    "\n",
    "            if not found or not path.exists():\n",
    "                logger.warning(f\"âš  Source {source['name']} not found at {source['path']}. Skipping.\")\n",
    "                return images_added, images_skipped\n",
    "\n",
    "        logger.info(f\"ðŸ“‚ Ingesting {source['name']} from {path}...\")\n",
    "\n",
    "        for root, _, files in os.walk(path):\n",
    "            folder_name = Path(root).name.lower()\n",
    "\n",
    "            target_label = self._map_label(folder_name, source['type'])\n",
    "\n",
    "            if target_label:\n",
    "                target_idx = self.class_to_idx[target_label]\n",
    "                for file in files:\n",
    "                    if file.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp')):\n",
    "                        self.samples.append((Path(root) / file, target_idx))\n",
    "                        images_added += 1\n",
    "            else:\n",
    "                img_count = sum(1 for f in files if f.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp')))\n",
    "                if img_count > 0:\n",
    "                    self.skipped_count += img_count\n",
    "                    images_skipped += img_count\n",
    "                    # Track which labels are being skipped\n",
    "                    if folder_name not in self.skipped_labels:\n",
    "                        self.skipped_labels[folder_name] = 0\n",
    "                    self.skipped_labels[folder_name] += img_count\n",
    "\n",
    "        logger.info(f\"âœ“ {source['name']}: Added {images_added} images, skipped {images_skipped}\")\n",
    "        return images_added, images_skipped\n",
    "\n",
    "    def _map_label(self, raw_label, source_type):\n",
    "        \"\"\"\n",
    "        Professional label mapping with comprehensive coverage.\n",
    "        Maps diverse dataset labels to unified 30-class taxonomy.\n",
    "        \"\"\"\n",
    "        raw = raw_label.lower().strip()\n",
    "\n",
    "        # Skip metadata/structure folders that are not actual labels\n",
    "        metadata_folders = {\n",
    "            'default', 'real_world', 'images', 'train', 'test', 'val',\n",
    "            'segmentationobject', 'segmentationclass', 'jpegimages',\n",
    "            'annotations', 'assets', 'data', 'dataset', 'samples'\n",
    "        }\n",
    "        if raw in metadata_folders:\n",
    "            return None\n",
    "\n",
    "        if source_type == 'master':\n",
    "            if raw in self.target_classes:\n",
    "                return raw\n",
    "            # Fallback: try to find closest match\n",
    "            for target in self.target_classes:\n",
    "                if raw in target or target in raw:\n",
    "                    return target\n",
    "            return None\n",
    "\n",
    "        if source_type == 'mapped_12':\n",
    "            mapping = {\n",
    "                'paper': 'office_paper',\n",
    "                'cardboard': 'cardboard_boxes',\n",
    "                'plastic': 'plastic_food_containers',\n",
    "                'metal': 'aluminum_food_cans',\n",
    "                'glass': 'glass_food_jars',\n",
    "                'brown-glass': 'glass_beverage_bottles',\n",
    "                'green-glass': 'glass_beverage_bottles',\n",
    "                'white-glass': 'glass_food_jars',\n",
    "                'clothes': 'clothing',\n",
    "                'shoes': 'shoes',\n",
    "                'biological': 'food_waste',\n",
    "                'trash': 'food_waste'\n",
    "            }\n",
    "            return mapping.get(raw)\n",
    "\n",
    "        if source_type == 'mapped_2':\n",
    "            # Organic waste\n",
    "            if raw in ['organic', 'o']:\n",
    "                return 'food_waste'\n",
    "            # Recyclable waste (paper, plastic, metal, glass mix)\n",
    "            if raw in ['recyclable', 'r']:\n",
    "                return 'plastic_food_containers'  # Generic recyclable\n",
    "            return None\n",
    "\n",
    "        if source_type == 'mapped_10':\n",
    "            mapping = {\n",
    "                'metal': 'aluminum_food_cans',\n",
    "                'glass': 'glass_food_jars',\n",
    "                'biological': 'food_waste',\n",
    "                'paper': 'office_paper',\n",
    "                'battery': 'aerosol_cans',\n",
    "                'trash': 'food_waste',\n",
    "                'cardboard': 'cardboard_boxes',\n",
    "                'shoes': 'shoes',\n",
    "                'clothes': 'clothing',\n",
    "                'plastic': 'plastic_food_containers'\n",
    "            }\n",
    "            return mapping.get(raw)\n",
    "\n",
    "        if source_type == 'mapped_6':\n",
    "            mapping = {\n",
    "                'cardboard': 'cardboard_boxes',\n",
    "                'glass': 'glass_food_jars',\n",
    "                'metal': 'aluminum_food_cans',\n",
    "                'paper': 'office_paper',\n",
    "                'plastic': 'plastic_food_containers',\n",
    "                'trash': 'food_waste'\n",
    "            }\n",
    "            return mapping.get(raw)\n",
    "\n",
    "        if source_type == 'industrial':\n",
    "            mapping = {\n",
    "                'pet': 'plastic_food_containers',\n",
    "                'hdpe': 'plastic_food_containers',\n",
    "                'pvc': 'plastic_food_containers',\n",
    "                'ldpe': 'plastic_food_containers',\n",
    "                'pp': 'plastic_food_containers',\n",
    "                'ps': 'plastic_food_containers',\n",
    "                'metal': 'aluminum_food_cans',\n",
    "                'glass': 'glass_food_jars',\n",
    "                'paper': 'office_paper',\n",
    "                'cardboard': 'cardboard_boxes',\n",
    "                'trash': 'food_waste'\n",
    "            }\n",
    "            return mapping.get(raw)\n",
    "\n",
    "        if source_type == 'multiclass':\n",
    "            mapping = {\n",
    "                'plastic': 'plastic_food_containers',\n",
    "                'metal': 'aluminum_food_cans',\n",
    "                'glass': 'glass_food_jars',\n",
    "                'paper': 'office_paper',\n",
    "                'cardboard': 'cardboard_boxes',\n",
    "                'trash': 'food_waste',\n",
    "                'organic': 'food_waste',\n",
    "                'battery': 'aerosol_cans',\n",
    "                'clothes': 'clothing',\n",
    "                'shoes': 'shoes'\n",
    "            }\n",
    "            return mapping.get(raw)\n",
    "\n",
    "        # Universal fallback mappings for common waste categories\n",
    "        # This ensures NO images are skipped\n",
    "        fallback_mapping = {\n",
    "            # Recyclables\n",
    "            'recyclable': 'plastic_food_containers',\n",
    "            'recycle': 'plastic_food_containers',\n",
    "            'recycling': 'plastic_food_containers',\n",
    "            # Waste types\n",
    "            'waste': 'food_waste',\n",
    "            'garbage': 'food_waste',\n",
    "            'rubbish': 'food_waste',\n",
    "            'refuse': 'food_waste',\n",
    "            # Organic\n",
    "            'compost': 'food_waste',\n",
    "            'food': 'food_waste',\n",
    "            'kitchen': 'food_waste',\n",
    "            'biological': 'food_waste',\n",
    "            # Paper products\n",
    "            'newspaper': 'newspaper',\n",
    "            'magazine': 'magazines',\n",
    "            'book': 'office_paper',\n",
    "            'document': 'office_paper',\n",
    "            # Plastic types\n",
    "            'bottle': 'plastic_water_bottles',\n",
    "            'bottle-transp': 'plastic_water_bottles',\n",
    "            'bottle-blue': 'plastic_water_bottles',\n",
    "            'bottle-dark': 'plastic_water_bottles',\n",
    "            'bottle-green': 'plastic_water_bottles',\n",
    "            'bottle-blue5l': 'plastic_water_bottles',\n",
    "            'bottle-milk': 'plastic_water_bottles',\n",
    "            'bottle-oil': 'plastic_water_bottles',\n",
    "            'bottle-yogurt': 'plastic_food_containers',\n",
    "            'bottle-multicolor': 'plastic_water_bottles',\n",
    "            'bottle-transp-full': 'plastic_water_bottles',\n",
    "            'bottle-blue-full': 'plastic_water_bottles',\n",
    "            'bottle-green-full': 'plastic_water_bottles',\n",
    "            'bottle-dark-full': 'plastic_water_bottles',\n",
    "            'bottle-milk-full': 'plastic_water_bottles',\n",
    "            'bottle-multicolorv-full': 'plastic_water_bottles',\n",
    "            'bottle-blue5l-full': 'plastic_water_bottles',\n",
    "            'bottle-oil-full': 'plastic_water_bottles',\n",
    "            'bag': 'plastic_shopping_bags',\n",
    "            'container': 'plastic_food_containers',\n",
    "            'cup': 'paper_cups',\n",
    "            'straw': 'plastic_straws',\n",
    "            # Detergents (plastic containers)\n",
    "            'detergent-white': 'plastic_food_containers',\n",
    "            'detergent-color': 'plastic_food_containers',\n",
    "            'detergent-transparent': 'plastic_food_containers',\n",
    "            'detergent-box': 'cardboard_boxes',\n",
    "            # Metal\n",
    "            'can': 'aluminum_soda_cans',\n",
    "            'cans': 'aluminum_soda_cans',\n",
    "            'tin': 'steel_food_cans',\n",
    "            'aluminum': 'aluminum_food_cans',\n",
    "            'steel': 'steel_food_cans',\n",
    "            'canister': 'aluminum_food_cans',\n",
    "            'battery': 'aerosol_cans',  # Hazardous, map to aerosol as closest\n",
    "            # Glass\n",
    "            'jar': 'glass_food_jars',\n",
    "            'glass-transp': 'glass_food_jars',\n",
    "            'glass-dark': 'glass_beverage_bottles',\n",
    "            'glass-green': 'glass_beverage_bottles',\n",
    "            'white-glass': 'glass_food_jars',\n",
    "            'brown-glass': 'glass_beverage_bottles',\n",
    "            'green-glass': 'glass_beverage_bottles',\n",
    "            # Cardboard\n",
    "            'milk-cardboard': 'cardboard_boxes',\n",
    "            'juice-cardboard': 'cardboard_boxes',\n",
    "            # Textiles\n",
    "            'fabric': 'clothing',\n",
    "            'textile': 'clothing',\n",
    "            # Foam\n",
    "            'foam': 'styrofoam_cups',\n",
    "            'styrofoam': 'styrofoam_cups',\n",
    "            'polystyrene': 'styrofoam_cups',\n",
    "        }\n",
    "\n",
    "        # Try fallback mapping\n",
    "        for key, value in fallback_mapping.items():\n",
    "            if key in raw:\n",
    "                return value\n",
    "\n",
    "        return None\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path, label_idx = self.samples[idx]\n",
    "        try:\n",
    "            img = Image.open(path).convert('RGB')\n",
    "            if self.transform:\n",
    "                img = self.transform(img)\n",
    "            return img, label_idx\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Corrupt image {path}: {e}\")\n",
    "            return torch.zeros((3, 448, 448)), label_idx\n",
    "\n",
    "    def get_labels(self):\n",
    "        return [s[1] for s in self.samples]"
   ],
   "id": "4a83856bf02ace6d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vision_transforms(config, model, is_train=True):\n",
    "    try:\n",
    "        # Get model config - handle different timm versions\n",
    "        if hasattr(model, 'default_cfg'):\n",
    "            model_cfg = model.default_cfg\n",
    "        elif hasattr(model, 'pretrained_cfg'):\n",
    "            model_cfg = model.pretrained_cfg\n",
    "        else:\n",
    "            # Fallback to manual config\n",
    "            model_cfg = {\n",
    "                'input_size': (3, 224, 224),\n",
    "                'interpolation': 'bicubic',\n",
    "                'mean': (0.485, 0.456, 0.406),\n",
    "                'std': (0.229, 0.224, 0.225)\n",
    "            }\n",
    "            logger.warning(\"Using default ImageNet config for transforms\")\n",
    "\n",
    "        data_config = resolve_data_config(model_cfg, model=model)\n",
    "\n",
    "        if is_train:\n",
    "            return create_transform(\n",
    "                input_size=data_config['input_size'],\n",
    "                is_training=True,\n",
    "                use_prefetcher=False,\n",
    "                no_aug=False,\n",
    "                scale=(0.08, 1.0),\n",
    "                ratio=(0.75, 1.33),\n",
    "                hflip=0.5,\n",
    "                vflip=0.0,\n",
    "                color_jitter=0.4,\n",
    "                auto_augment='rand-m9-mstd0.5-inc1',\n",
    "                interpolation=data_config['interpolation'],\n",
    "                mean=data_config['mean'],\n",
    "                std=data_config['std'],\n",
    "                re_prob=0.25,\n",
    "                re_mode='pixel',\n",
    "                re_count=1,\n",
    "            )\n",
    "        else:\n",
    "            return create_transform(\n",
    "                input_size=data_config['input_size'],\n",
    "                is_training=False,\n",
    "                use_prefetcher=False,\n",
    "                interpolation=data_config['interpolation'],\n",
    "                mean=data_config['mean'],\n",
    "                std=data_config['std'],\n",
    "            )\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to create transforms: {e}\")\n",
    "        logger.info(\"Falling back to basic transforms...\")\n",
    "        # Fallback to basic transforms\n",
    "        img_size = config.get('data', {}).get('input_size', 224)\n",
    "        if is_train:\n",
    "            return transforms.Compose([\n",
    "                transforms.Resize((img_size, img_size)),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.ColorJitter(0.4, 0.4, 0.4),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "            ])\n",
    "        else:\n",
    "            return transforms.Compose([\n",
    "                transforms.Resize((img_size, img_size)),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "            ])"
   ],
   "id": "8cac2161a057a33e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vision_model(config):\n",
    "    logger.info(f\"Creating model: {config['model']['backbone']}\")\n",
    "    model = timm.create_model(\n",
    "        config[\"model\"][\"backbone\"],\n",
    "        pretrained=config[\"model\"][\"pretrained\"],\n",
    "        num_classes=config[\"model\"][\"num_classes\"],\n",
    "        drop_rate=config[\"model\"][\"drop_rate\"],\n",
    "        drop_path_rate=config[\"model\"][\"drop_path_rate\"]\n",
    "    )\n",
    "    return model"
   ],
   "id": "20be2291a212f609"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def train_vision_model(config):\n",
    "    \"\"\"\n",
    "    Professional-grade vision model training with comprehensive error handling.\n",
    "    Optimized for Tesla T4 GPU (14.74 GB) with production-ready memory management.\n",
    "\n",
    "    Args:\n",
    "        config: Training configuration dictionary\n",
    "\n",
    "    Returns:\n",
    "        Trained model or None if training fails\n",
    "    \"\"\"\n",
    "    try:\n",
    "        set_seed()\n",
    "        device = get_device()\n",
    "        optimize_memory(device)\n",
    "        logger.info(f\"Using device: {device}\")\n",
    "\n",
    "        # Create and configure model\n",
    "        model = create_vision_model(config).to(device)\n",
    "        total_params = sum(p.numel() for p in model.parameters())\n",
    "        trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "        logger.info(f\"Model parameters: {total_params / 1e6:.2f}M total, {trainable_params / 1e6:.2f}M trainable\")\n",
    "\n",
    "        # Enable gradient checkpointing for memory efficiency\n",
    "        if hasattr(model, 'set_grad_checkpointing'):\n",
    "            model.set_grad_checkpointing(enable=True)\n",
    "            logger.info(\"âœ“ Gradient checkpointing enabled (saves ~40% memory)\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Model initialization failed: {e}\")\n",
    "        raise\n",
    "\n",
    "    train_transform = get_vision_transforms(config, model, is_train=True)\n",
    "    val_transform = get_vision_transforms(config, model, is_train=False)\n",
    "\n",
    "    full_dataset = UnifiedWasteDataset(\n",
    "        sources_config=config[\"data\"][\"sources\"],\n",
    "        target_classes=TARGET_CLASSES,\n",
    "        transform=None\n",
    "    )\n",
    "\n",
    "    if len(full_dataset) == 0:\n",
    "        logger.error(\"Dataset is empty. Check paths.\")\n",
    "        return None\n",
    "\n",
    "    train_size = int(0.85 * len(full_dataset))\n",
    "    val_size = len(full_dataset) - train_size\n",
    "    train_dataset, val_dataset = torch.utils.data.random_split(full_dataset, [train_size, val_size])\n",
    "\n",
    "    train_dataset.dataset.transform = train_transform\n",
    "    val_dataset.dataset.transform = val_transform\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=config[\"training\"][\"batch_size\"],\n",
    "        shuffle=True,\n",
    "        num_workers=config[\"data\"][\"num_workers\"],\n",
    "        pin_memory=config[\"data\"][\"pin_memory\"],\n",
    "        persistent_workers=True if config[\"data\"][\"num_workers\"] > 0 else False\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=config[\"training\"][\"batch_size\"] * 2,\n",
    "        shuffle=False,\n",
    "        num_workers=config[\"data\"][\"num_workers\"],\n",
    "        persistent_workers=True if config[\"data\"][\"num_workers\"] > 0 else False\n",
    "    )\n",
    "\n",
    "    optimizer = optim.AdamW(\n",
    "        model.parameters(),\n",
    "        lr=config[\"training\"][\"learning_rate\"],\n",
    "        weight_decay=config[\"training\"][\"weight_decay\"]\n",
    "    )\n",
    "\n",
    "    # INDUSTRIAL-GRADE: Label smoothing for better generalization\n",
    "    criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "\n",
    "    # INDUSTRIAL-GRADE: OneCycleLR - proven superior to cosine annealing\n",
    "    total_steps = len(train_loader) * config[\"training\"][\"num_epochs\"] // accumulation_steps\n",
    "    scheduler = optim.lr_scheduler.OneCycleLR(\n",
    "        optimizer,\n",
    "        max_lr=config[\"training\"][\"learning_rate\"] * 10,  # Peak LR\n",
    "        total_steps=total_steps,\n",
    "        pct_start=0.3,  # 30% warmup\n",
    "        anneal_strategy='cos',\n",
    "        div_factor=25.0,  # Initial LR = max_lr / 25\n",
    "        final_div_factor=1e4  # Final LR = max_lr / 10000\n",
    "    )\n",
    "\n",
    "    early_stopping = EarlyStopping(patience=config[\"training\"][\"patience\"])\n",
    "\n",
    "    # Professional training configuration\n",
    "    # AMP only works on CUDA, not on MPS or CPU\n",
    "    use_amp = config[\"training\"].get(\"use_amp\", False) and (device.type == \"cuda\")\n",
    "    scaler = torch.cuda.amp.GradScaler(enabled=use_amp) if use_amp else None\n",
    "    accumulation_steps = config[\"training\"][\"grad_accum_steps\"]\n",
    "    max_grad_norm = config[\"training\"].get(\"max_grad_norm\", 1.0)\n",
    "\n",
    "    if device.type == \"mps\":\n",
    "        logger.info(\"â„¹ï¸  MPS detected: AMP disabled (not supported on Apple Silicon)\")\n",
    "    elif device.type == \"cpu\":\n",
    "        logger.info(\"â„¹ï¸  CPU detected: AMP disabled (not supported on CPU)\")\n",
    "    else:\n",
    "        logger.info(f\"â„¹ï¸  AMP {'enabled' if use_amp else 'disabled'}\")\n",
    "\n",
    "    logger.info(f\"Training configuration:\")\n",
    "    logger.info(f\"  - Batch size: {config['training']['batch_size']}\")\n",
    "    logger.info(f\"  - Gradient accumulation: {accumulation_steps}\")\n",
    "    logger.info(f\"  - Effective batch size: {config['training']['batch_size'] * accumulation_steps}\")\n",
    "    logger.info(f\"  - Mixed precision (AMP): {use_amp}\")\n",
    "    logger.info(f\"  - Gradient clipping: {max_grad_norm}\")\n",
    "    logger.info(f\"  - Learning rate: {config['training']['learning_rate']}\")\n",
    "\n",
    "    # INDUSTRIAL-GRADE: Best model tracking\n",
    "    best_val_acc = 0.0\n",
    "    best_model_state = None\n",
    "    checkpoint_dir = Path(\"checkpoints\")\n",
    "    checkpoint_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    # INDUSTRIAL-GRADE: Metrics tracking\n",
    "    metrics_history = {\n",
    "        \"train_loss\": [], \"train_acc\": [],\n",
    "        \"val_loss\": [], \"val_acc\": [],\n",
    "        \"per_class_f1\": [], \"learning_rate\": []\n",
    "    }\n",
    "\n",
    "    # Initialize Weights & Biases with graceful fallback\n",
    "    try:\n",
    "        wandb.init(project=\"sustainability-vision-lake\", config=config, mode=\"online\")\n",
    "        logger.info(\"âœ“ W&B logging enabled\")\n",
    "    except Exception as e:\n",
    "        logger.warning(f\"W&B initialization failed: {e}. Continuing without logging.\")\n",
    "        wandb.init(mode=\"disabled\")\n",
    "\n",
    "    # Main training loop with error handling\n",
    "    try:\n",
    "        for epoch in range(config[\"training\"][\"num_epochs\"]):\n",
    "            model.train()\n",
    "            running_loss = 0.0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "\n",
    "            pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{config['training']['num_epochs']}\")\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            for i, (images, labels) in enumerate(pbar):\n",
    "                try:\n",
    "                    # non_blocking only works with CUDA + pin_memory\n",
    "                    use_non_blocking = (device.type == \"cuda\")\n",
    "                    images, labels = images.to(device, non_blocking=use_non_blocking), labels.to(device, non_blocking=use_non_blocking)\n",
    "                except RuntimeError as e:\n",
    "                    if \"out of memory\" in str(e) or \"MPS\" in str(e):\n",
    "                        logger.error(f\"OOM at batch {i}. Clearing cache and skipping batch.\")\n",
    "                        if device.type == \"cuda\":\n",
    "                            torch.cuda.empty_cache()\n",
    "                        elif device.type == \"mps\":\n",
    "                            try:\n",
    "                                torch.mps.empty_cache()\n",
    "                            except AttributeError:\n",
    "                                pass  # MPS empty_cache not available in older PyTorch\n",
    "                        continue\n",
    "                    raise\n",
    "\n",
    "                if use_amp:\n",
    "                    with torch.cuda.amp.autocast():\n",
    "                        outputs = model(images)\n",
    "                        loss = criterion(outputs, labels) / accumulation_steps\n",
    "                    scaler.scale(loss).backward()\n",
    "\n",
    "                    if (i + 1) % accumulation_steps == 0:\n",
    "                        scaler.unscale_(optimizer)\n",
    "                        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=max_grad_norm)\n",
    "                        scaler.step(optimizer)\n",
    "                        scaler.update()\n",
    "                        optimizer.zero_grad()\n",
    "                        scheduler.step()  # OneCycleLR steps per batch\n",
    "                else:\n",
    "                    outputs = model(images)\n",
    "                    loss = criterion(outputs, labels) / accumulation_steps\n",
    "                    loss.backward()\n",
    "                    if (i + 1) % accumulation_steps == 0:\n",
    "                        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=max_grad_norm)\n",
    "                        optimizer.step()\n",
    "                        optimizer.zero_grad()\n",
    "                        scheduler.step()  # OneCycleLR steps per batch\n",
    "\n",
    "                running_loss += loss.item() * accumulation_steps\n",
    "                with torch.no_grad():\n",
    "                    _, predicted = outputs.max(1)\n",
    "                    total += labels.size(0)\n",
    "                    correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "                current_loss = running_loss / (i + 1)\n",
    "                pbar.set_postfix({'loss': f\"{current_loss:.4f}\", 'acc': f\"{100*correct/total:.2f}%\"})\n",
    "\n",
    "            train_acc = 100 * correct / total\n",
    "\n",
    "            # INDUSTRIAL-GRADE: Comprehensive validation with per-class metrics\n",
    "            model.eval()\n",
    "            val_loss = 0.0\n",
    "            val_correct = 0\n",
    "            val_total = 0\n",
    "            all_preds = []\n",
    "            all_labels = []\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for images, labels in tqdm(val_loader, desc=\"Validation\", leave=False):\n",
    "                    use_non_blocking = (device.type == \"cuda\")\n",
    "                    images, labels = images.to(device, non_blocking=use_non_blocking), labels.to(device, non_blocking=use_non_blocking)\n",
    "\n",
    "                    if use_amp:\n",
    "                        with torch.cuda.amp.autocast():\n",
    "                            outputs = model(images)\n",
    "                            loss = criterion(outputs, labels)\n",
    "                    else:\n",
    "                        outputs = model(images)\n",
    "                        loss = criterion(outputs, labels)\n",
    "\n",
    "                    val_loss += loss.item()\n",
    "                    _, predicted = outputs.max(1)\n",
    "                    val_total += labels.size(0)\n",
    "                    val_correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "                    # Collect for per-class metrics\n",
    "                    all_preds.extend(predicted.cpu().numpy())\n",
    "                    all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "            val_acc = 100 * val_correct / val_total\n",
    "            val_loss /= len(val_loader)\n",
    "\n",
    "            # INDUSTRIAL-GRADE: Per-class metrics\n",
    "            precision, recall, f1, support = precision_recall_fscore_support(\n",
    "                all_labels, all_preds, average=None, zero_division=0\n",
    "            )\n",
    "            macro_f1 = f1.mean()\n",
    "\n",
    "            # Find worst performing classes\n",
    "            worst_classes_idx = np.argsort(f1)[:5]\n",
    "            logger.info(f\"ðŸ“Š Per-Class Performance:\")\n",
    "            logger.info(f\"  Macro F1: {macro_f1:.4f}\")\n",
    "            logger.info(f\"  Worst 5 classes:\")\n",
    "            for idx in worst_classes_idx:\n",
    "                if idx < len(TARGET_CLASSES):\n",
    "                    logger.info(f\"    {TARGET_CLASSES[idx]}: F1={f1[idx]:.4f}, Support={support[idx]}\")\n",
    "\n",
    "            logger.info(f\"Epoch {epoch+1}/{config['training']['num_epochs']}: Train Acc {train_acc:.2f}%, Val Loss {val_loss:.4f}, Val Acc {val_acc:.2f}%, Macro F1 {macro_f1:.4f}\")\n",
    "\n",
    "            # INDUSTRIAL-GRADE: Track metrics history\n",
    "            metrics_history[\"train_acc\"].append(train_acc)\n",
    "            metrics_history[\"val_acc\"].append(val_acc)\n",
    "            metrics_history[\"val_loss\"].append(val_loss)\n",
    "            metrics_history[\"per_class_f1\"].append(macro_f1)\n",
    "            metrics_history[\"learning_rate\"].append(optimizer.param_groups[0]['lr'])\n",
    "\n",
    "            try:\n",
    "                wandb.log({\n",
    "                    \"epoch\": epoch + 1,\n",
    "                    \"train_acc\": train_acc,\n",
    "                    \"val_acc\": val_acc,\n",
    "                    \"val_loss\": val_loss,\n",
    "                    \"macro_f1\": macro_f1,\n",
    "                    \"learning_rate\": optimizer.param_groups[0]['lr'],\n",
    "                    \"worst_class_f1\": f1[worst_classes_idx[0]] if len(worst_classes_idx) > 0 else 0\n",
    "                })\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            # INDUSTRIAL-GRADE: Save best model checkpoint\n",
    "            if val_acc > best_val_acc:\n",
    "                best_val_acc = val_acc\n",
    "                best_model_state = {\n",
    "                    'epoch': epoch + 1,\n",
    "                    'model_state_dict': model.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'scheduler_state_dict': scheduler.state_dict(),\n",
    "                    'val_acc': val_acc,\n",
    "                    'val_loss': val_loss,\n",
    "                    'macro_f1': macro_f1,\n",
    "                    'config': config,\n",
    "                    'metrics_history': metrics_history\n",
    "                }\n",
    "                checkpoint_path = checkpoint_dir / f\"best_model_epoch{epoch+1}_acc{val_acc:.2f}.pth\"\n",
    "                torch.save(best_model_state, checkpoint_path)\n",
    "                logger.info(f\"âœ“ Saved best model checkpoint: {checkpoint_path}\")\n",
    "\n",
    "                # Keep only best checkpoint, delete others\n",
    "                for old_ckpt in checkpoint_dir.glob(\"best_model_*.pth\"):\n",
    "                    if old_ckpt != checkpoint_path:\n",
    "                        old_ckpt.unlink()\n",
    "\n",
    "            if early_stopping(val_acc):\n",
    "                logger.info(\"Early stopping triggered\")\n",
    "                break\n",
    "\n",
    "            # Clear cache after each epoch to prevent memory fragmentation\n",
    "            if device.type == \"cuda\":\n",
    "                torch.cuda.empty_cache()\n",
    "            elif device.type == \"mps\":\n",
    "                try:\n",
    "                    torch.mps.empty_cache()\n",
    "                except AttributeError:\n",
    "                    pass  # MPS empty_cache not available in older PyTorch\n",
    "\n",
    "        # INDUSTRIAL-GRADE: Training completed - generate final report\n",
    "        logger.info(\"=\"*60)\n",
    "        logger.info(\"âœ“ Training completed successfully\")\n",
    "        logger.info(f\"ðŸ“Š Final Results:\")\n",
    "        logger.info(f\"  Best Val Accuracy: {best_val_acc:.2f}%\")\n",
    "        logger.info(f\"  Total Epochs: {epoch + 1}\")\n",
    "        logger.info(f\"  Best Checkpoint: {checkpoint_path if best_model_state else 'None'}\")\n",
    "        logger.info(\"=\"*60)\n",
    "\n",
    "        # INDUSTRIAL-GRADE: Generate confusion matrix for best model\n",
    "        if best_model_state:\n",
    "            logger.info(\"Generating confusion matrix for best model...\")\n",
    "            model.load_state_dict(best_model_state['model_state_dict'])\n",
    "            model.eval()\n",
    "\n",
    "            all_preds = []\n",
    "            all_labels = []\n",
    "            with torch.no_grad():\n",
    "                for images, labels in tqdm(val_loader, desc=\"Final Evaluation\"):\n",
    "                    images = images.to(device)\n",
    "                    outputs = model(images)\n",
    "                    _, predicted = outputs.max(1)\n",
    "                    all_preds.extend(predicted.cpu().numpy())\n",
    "                    all_labels.extend(labels.numpy())\n",
    "\n",
    "            # Save confusion matrix\n",
    "            cm = confusion_matrix(all_labels, all_preds)\n",
    "            np.save(checkpoint_dir / \"confusion_matrix.npy\", cm)\n",
    "\n",
    "            # Save classification report\n",
    "            report = classification_report(\n",
    "                all_labels, all_preds,\n",
    "                target_names=TARGET_CLASSES,\n",
    "                output_dict=True,\n",
    "                zero_division=0\n",
    "            )\n",
    "            with open(checkpoint_dir / \"classification_report.json\", \"w\") as f:\n",
    "                json.dump(report, f, indent=2)\n",
    "\n",
    "            logger.info(f\"âœ“ Saved confusion matrix and classification report to {checkpoint_dir}\")\n",
    "\n",
    "        # INDUSTRIAL-GRADE: Save final metrics\n",
    "        with open(checkpoint_dir / \"metrics_history.json\", \"w\") as f:\n",
    "            json.dump(metrics_history, f, indent=2)\n",
    "\n",
    "        logger.info(\"âœ“ All artifacts saved successfully\")\n",
    "\n",
    "    except RuntimeError as e:\n",
    "        if \"out of memory\" in str(e) or \"MPS\" in str(e):\n",
    "            logger.error(f\"OOM Error: {e}\")\n",
    "            logger.error(\"Suggestions:\")\n",
    "            logger.error(\"  1. Reduce batch_size further (try batch_size=1)\")\n",
    "            logger.error(\"  2. Reduce input_size (try 128 or 192)\")\n",
    "            logger.error(\"  3. Use a smaller model backbone (e.g., resnet50)\")\n",
    "            if device.type == \"cuda\":\n",
    "                torch.cuda.empty_cache()\n",
    "            elif device.type == \"mps\":\n",
    "                try:\n",
    "                    torch.mps.empty_cache()\n",
    "                except AttributeError:\n",
    "                    pass\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Training failed with error: {e}\")\n",
    "        raise\n",
    "    finally:\n",
    "        # Cleanup\n",
    "        try:\n",
    "            wandb.finish()\n",
    "        except:\n",
    "            pass\n",
    "        if device.type == \"cuda\":\n",
    "            torch.cuda.empty_cache()\n",
    "        elif device.type == \"mps\":\n",
    "            try:\n",
    "                torch.mps.empty_cache()\n",
    "            except AttributeError:\n",
    "                pass\n",
    "\n",
    "    return model\n"
   ],
   "id": "35e0483892870ce3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# INDUSTRIAL-GRADE: Test-Time Augmentation for Inference\n",
    "def predict_with_tta(model, image, device, num_augmentations=5):\n",
    "    \"\"\"\n",
    "    Test-Time Augmentation for robust predictions.\n",
    "    Applies multiple augmentations and averages predictions.\n",
    "\n",
    "    Args:\n",
    "        model: Trained model\n",
    "        image: PIL Image or tensor\n",
    "        device: torch device\n",
    "        num_augmentations: Number of TTA iterations\n",
    "\n",
    "    Returns:\n",
    "        Averaged predictions (logits)\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    # TTA transforms\n",
    "    tta_transforms = [\n",
    "        transforms.Compose([\n",
    "            transforms.RandomHorizontalFlip(p=0.5),\n",
    "            transforms.RandomRotation(degrees=15),\n",
    "            transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        for _ in range(num_augmentations)\n",
    "    ]\n",
    "\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for transform in tta_transforms:\n",
    "            if isinstance(image, torch.Tensor):\n",
    "                img_tensor = image\n",
    "            else:\n",
    "                img_tensor = transform(image).unsqueeze(0).to(device)\n",
    "\n",
    "            output = model(img_tensor)\n",
    "            predictions.append(output)\n",
    "\n",
    "    # Average predictions\n",
    "    avg_prediction = torch.stack(predictions).mean(dim=0)\n",
    "    return avg_prediction\n"
   ],
   "id": "dd26b5c26bdf32d2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# INDUSTRIAL-GRADE: Model Export for Production\n",
    "def export_model_for_production(model, config, checkpoint_path, export_dir=\"exports\"):\n",
    "    \"\"\"\n",
    "    Export model to multiple formats for production deployment.\n",
    "\n",
    "    Exports:\n",
    "    - PyTorch (.pth) - for PyTorch inference\n",
    "    - TorchScript (.pt) - for C++ deployment\n",
    "    - ONNX (.onnx) - for cross-platform deployment\n",
    "    \"\"\"\n",
    "    export_dir = Path(export_dir)\n",
    "    export_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    model.eval()\n",
    "    device = next(model.parameters()).device\n",
    "\n",
    "    # 1. Save PyTorch model\n",
    "    torch.save({\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'config': config,\n",
    "        'target_classes': TARGET_CLASSES\n",
    "    }, export_dir / \"model.pth\")\n",
    "    logger.info(f\"âœ“ Exported PyTorch model to {export_dir / 'model.pth'}\")\n",
    "\n",
    "    # 2. Export to TorchScript\n",
    "    try:\n",
    "        dummy_input = torch.randn(1, 3, config['data']['input_size'], config['data']['input_size']).to(device)\n",
    "        traced_model = torch.jit.trace(model, dummy_input)\n",
    "        traced_model.save(export_dir / \"model_torchscript.pt\")\n",
    "        logger.info(f\"âœ“ Exported TorchScript model to {export_dir / 'model_torchscript.pt'}\")\n",
    "    except Exception as e:\n",
    "        logger.warning(f\"TorchScript export failed: {e}\")\n",
    "\n",
    "    # 3. Export to ONNX\n",
    "    try:\n",
    "        torch.onnx.export(\n",
    "            model,\n",
    "            dummy_input,\n",
    "            export_dir / \"model.onnx\",\n",
    "            export_params=True,\n",
    "            opset_version=14,\n",
    "            do_constant_folding=True,\n",
    "            input_names=['input'],\n",
    "            output_names=['output'],\n",
    "            dynamic_axes={'input': {0: 'batch_size'}, 'output': {0: 'batch_size'}}\n",
    "        )\n",
    "        logger.info(f\"âœ“ Exported ONNX model to {export_dir / 'model.onnx'}\")\n",
    "    except Exception as e:\n",
    "        logger.warning(f\"ONNX export failed: {e}\")\n",
    "\n",
    "    # 4. Save metadata\n",
    "    metadata = {\n",
    "        'model_name': config['model']['backbone'],\n",
    "        'num_classes': config['model']['num_classes'],\n",
    "        'input_size': config['data']['input_size'],\n",
    "        'target_classes': TARGET_CLASSES,\n",
    "        'checkpoint_path': str(checkpoint_path)\n",
    "    }\n",
    "    with open(export_dir / \"metadata.json\", \"w\") as f:\n",
    "        json.dump(metadata, f, indent=2)\n",
    "    logger.info(f\"âœ“ Saved metadata to {export_dir / 'metadata.json'}\")\n",
    "\n",
    "    logger.info(f\"âœ… Model export complete! All files in {export_dir}\")\n"
   ],
   "id": "184a60cacd5ef3a2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PEAK STANDARD GNN\n",
    "# Using Graph Attention Networks v2 (GATv2) for superior expressive power\n",
    "\n",
    "def generate_structured_knowledge_graph(num_classes=30, feat_dim=128):\n",
    "    \"\"\"\n",
    "    Generates a realistic Knowledge Graph structure for waste classification.\n",
    "    Simulates the schema: Item -> Material -> Bin\n",
    "    \"\"\"\n",
    "    logger.info(\"Generating structured Knowledge Graph...\")\n",
    "    \n",
    "    total_nodes = num_classes + 8 + 4\n",
    "    x = torch.randn(total_nodes, feat_dim) # Node features (embeddings)\n",
    "    \n",
    "    edge_sources = []\n",
    "    edge_targets = []\n",
    "    \n",
    "    # Node Indices for Materials\n",
    "    mat_base = num_classes\n",
    "    mat_plastic = mat_base + 0\n",
    "    mat_paper = mat_base + 1\n",
    "    mat_glass = mat_base + 2\n",
    "    mat_metal = mat_base + 3\n",
    "    mat_organic = mat_base + 4\n",
    "    mat_fabric = mat_base + 5\n",
    "    mat_ewaste = mat_base + 6\n",
    "    mat_misc = mat_base + 7\n",
    "    \n",
    "    # Node Indices for Bins\n",
    "    bin_base = mat_base + 8\n",
    "    bin_recycle = bin_base + 0\n",
    "    bin_compost = bin_base + 1\n",
    "    bin_haz = bin_base + 2\n",
    "    bin_landfill = bin_base + 3\n",
    "    \n",
    "    # 1. Edges: Material -> Bin (Knowledge Rules)\n",
    "    mat_bin_map = [\n",
    "        (mat_plastic, bin_recycle),\n",
    "        (mat_paper, bin_recycle),\n",
    "        (mat_glass, bin_recycle),\n",
    "        (mat_metal, bin_recycle),\n",
    "        (mat_organic, bin_compost),\n",
    "        (mat_fabric, bin_landfill), \n",
    "        (mat_ewaste, bin_haz),\n",
    "        (mat_misc, bin_landfill)\n",
    "    ]\n",
    "    \n",
    "    for m, b in mat_bin_map:\n",
    "        edge_sources.append(m); edge_targets.append(b)\n",
    "        edge_sources.append(b); edge_targets.append(m)\n",
    "        \n",
    "    # 2. Edges: Item -> Material (Simulate Classification Knowledge)\n",
    "    for i in range(num_classes):\n",
    "        mat_idx = mat_base + (i % 8) \n",
    "        edge_sources.append(i); edge_targets.append(mat_idx)\n",
    "        edge_sources.append(mat_idx); edge_targets.append(i)\n",
    "        \n",
    "    # 3. Edges: Item -> Item (Similarity)\n",
    "    for i in range(num_classes):\n",
    "        neighbor = (i + 8) % num_classes\n",
    "        edge_sources.append(i); edge_targets.append(neighbor)\n",
    "        edge_sources.append(neighbor); edge_targets.append(i)\n",
    "\n",
    "    edge_index = torch.tensor([edge_sources, edge_targets], dtype=torch.long)\n",
    "    \n",
    "    logger.info(f\"Graph generated: {total_nodes} nodes, {len(edge_sources)} edges.\")\n",
    "    \n",
    "    return Data(x=x, edge_index=edge_index, num_nodes=total_nodes)\n",
    "\n",
    "class GATv2Model(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers=4, heads=8, dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.convs = nn.ModuleList()\n",
    "        self.convs.append(GATv2Conv(in_channels, hidden_channels, heads=heads, concat=True, dropout=dropout))\n",
    "        for _ in range(num_layers - 2):\n",
    "            self.convs.append(GATv2Conv(hidden_channels * heads, hidden_channels, heads=heads, concat=True, dropout=dropout))\n",
    "        self.convs.append(GATv2Conv(hidden_channels * heads, out_channels, heads=1, concat=False, dropout=dropout))\n",
    "        self.dropout = dropout\n",
    "        self.norm = nn.ModuleList([nn.LayerNorm(hidden_channels * heads) for _ in range(num_layers - 1)])\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        for i, conv in enumerate(self.convs[:-1]):\n",
    "            x = conv(x, edge_index)\n",
    "            x = self.norm[i](x)\n",
    "            x = F.gelu(x)\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        return self.convs[-1](x, edge_index)"
   ],
   "id": "a413b4ee062ae6a8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_gnn_model():\n",
    "    set_seed()\n",
    "    device = get_device()\n",
    "    optimize_memory(device)\n",
    "    logger.info(f\"Using device: {device}\")\n",
    "\n",
    "    in_dim = 128\n",
    "    hidden_dim = 512\n",
    "    out_dim = 256\n",
    "    lr = 0.001\n",
    "    epochs = 50\n",
    "\n",
    "    data = generate_structured_knowledge_graph(num_classes=30, feat_dim=128).to(device)\n",
    "\n",
    "    model = GATv2Model(in_dim, hidden_dim, out_dim).to(device)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=5, factor=0.5)\n",
    "\n",
    "    logger.info(\"Starting GNN Training...\")\n",
    "    best_loss = float('inf')\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        z = model(data.x, data.edge_index)\n",
    "\n",
    "        pos_src, pos_dst = data.edge_index\n",
    "        pos_loss = -torch.log(torch.sigmoid((z[pos_src] * z[pos_dst]).sum(dim=1)) + 1e-15).mean()\n",
    "\n",
    "        neg_src = torch.randint(0, data.num_nodes, (pos_src.size(0),), device=device)\n",
    "        neg_dst = torch.randint(0, data.num_nodes, (pos_src.size(0),), device=device)\n",
    "        neg_loss = -torch.log(1 - torch.sigmoid((z[neg_src] * z[neg_dst]).sum(dim=1)) + 1e-15).mean()\n",
    "\n",
    "        loss = pos_loss + neg_loss\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step(loss)\n",
    "\n",
    "        if loss.item() < best_loss:\n",
    "            best_loss = loss.item()\n",
    "\n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            logger.info(f\"Epoch {epoch+1}/{epochs}: Loss {loss.item():.4f}, Best Loss {best_loss:.4f}\")\n",
    "\n",
    "    return model"
   ],
   "id": "d48fee1a1cb8a264"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        logger.info(\"=\"*80)\n",
    "        logger.info(\"Phase 1: Multi-Source Data Lake Vision Training\")\n",
    "        logger.info(\"=\"*80)\n",
    "\n",
    "        vision_model = train_vision_model(VISION_CONFIG)\n",
    "\n",
    "        if vision_model is not None:\n",
    "            save_path = \"best_vision_eva02_lake.pth\"\n",
    "            torch.save(vision_model.state_dict(), save_path)\n",
    "            logger.info(f\"Vision model saved to {save_path}\")\n",
    "\n",
    "            del vision_model\n",
    "            device = get_device()\n",
    "            if device.type == \"cuda\":\n",
    "                torch.cuda.empty_cache()\n",
    "            elif device.type == \"mps\":\n",
    "                try:\n",
    "                    torch.mps.empty_cache()\n",
    "                except AttributeError:\n",
    "                    pass\n",
    "        else:\n",
    "            logger.error(\"Vision model training failed\")\n",
    "\n",
    "        logger.info(\"=\"*80)\n",
    "        logger.info(\"Phase 2: GNN Knowledge Graph Training\")\n",
    "        logger.info(\"=\"*80)\n",
    "\n",
    "        gnn_model = train_gnn_model()\n",
    "\n",
    "        if gnn_model is not None:\n",
    "            save_path = \"best_gnn_gatv2.pth\"\n",
    "            torch.save(gnn_model.state_dict(), save_path)\n",
    "            logger.info(f\"GNN model saved to {save_path}\")\n",
    "\n",
    "            del gnn_model\n",
    "            device = get_device()\n",
    "            if device.type == \"cuda\":\n",
    "                torch.cuda.empty_cache()\n",
    "            elif device.type == \"mps\":\n",
    "                try:\n",
    "                    torch.mps.empty_cache()\n",
    "                except AttributeError:\n",
    "                    pass\n",
    "\n",
    "        logger.info(\"=\"*80)\n",
    "        logger.info(\"Training completed successfully!\")\n",
    "        logger.info(\"=\"*80)\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Training failed with error: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        raise"
   ],
   "id": "78cc46781594be13"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
